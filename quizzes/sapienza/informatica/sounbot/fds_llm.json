[
  {
    "question": "Autoencoders: What is the purpose of the hidden layer in an autoencoder, which typically has a smaller dimensionality than the input layer?",
    "options": [
      {
        "text": "To expand the input data to a higher-dimensional space.",
        "image": ""
      },
      {
        "text": "To learn a compressed and efficient representation of the input data.",
        "image": ""
      },
      {
        "text": "To apply a non-linear transformation to the input.",
        "image": ""
      },
      {
        "text": "To add noise to the input data for robustness.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The smaller hidden layer creates a bottleneck that forces the network to learn a compressed representation of the input data, capturing only the most essential features.",
    "hint": "Think about what happens when you compress information into a smaller space."
  },
  {
    "question": "Autoencoders: According to the source, why is the constraint of a smaller hidden layer important in an autoencoder?",
    "options": [
      {
        "text": "It allows the network to memorize the input.",
        "image": ""
      },
      {
        "text": "It forces the network to learn meaningful patterns and structures.",
        "image": ""
      },
      {
        "text": "It speeds up the training process.",
        "image": ""
      },
      {
        "text": "It prevents overfitting.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The constraint forces the network to extract and preserve the most important patterns since it cannot simply memorize all input information through the bottleneck.",
    "hint": "What happens when you can't pass all information through?"
  },
  {
    "question": "Autoencoders: Which of the following is NOT a typical use case for autoencoders mentioned in the source?",
    "options": [
      {
        "text": "Dimensionality reduction for visualization.",
        "image": ""
      },
      {
        "text": "Data compression.",
        "image": ""
      },
      {
        "text": "Feature learning for downstream tasks.",
        "image": ""
      },
      {
        "text": "Supervised classification with labeled data.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Autoencoders are unsupervised learning models designed to reconstruct inputs from learned representations, not to perform supervised classification with labeled data.",
    "hint": "Consider what type of learning autoencoders are designed for."
  },
  {
    "question": "Autoencoders: What does the source say about using autoencoders with unlabeled data?",
    "options": [
      {
        "text": "They are not suitable for unlabeled data.",
        "image": ""
      },
      {
        "text": "They require labeled data to extract useful patterns.",
        "image": ""
      },
      {
        "text": "They can leverage large amounts of unlabeled data to extract useful patterns.",
        "image": ""
      },
      {
        "text": "They are only useful for supervised learning tasks",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Autoencoders are particularly effective for unsupervised learning, allowing them to extract meaningful patterns from large datasets without requiring labeled examples.",
    "hint": "Remember that autoencoders learn without needing labels."
  },
  {
    "question": "Autoencoders: In a linear autoencoder, what is the relationship between the input data (x) and the reconstructed output (x̂), according to the source?",
    "options": [
      {
        "text": "x̂ = VxU",
        "image": ""
      },
      {
        "text": "x̂ = UVx",
        "image": ""
      },
      {
        "text": "x̂ = x²",
        "image": ""
      },
      {
        "text": "x̂ = x + noise",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In a linear autoencoder, the input x is first encoded through matrix V to produce hidden representation h = Vx, then decoded through matrix U to produce x̂ = Uh = UVx.",
    "hint": "Think about the sequence of matrix multiplications through encoder and decoder."
  },
  {
    "question": "Autoencoders: What is the encoded representation of x in a linear autoencoder?",
    "options": [
      {
        "text": "UVx",
        "image": ""
      },
      {
        "text": "x̂",
        "image": ""
      },
      {
        "text": "Vx",
        "image": ""
      },
      {
        "text": "CCTx",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In a linear autoencoder, the encoded representation (the hidden layer) is computed as z = Vx, where V is the encoding weight matrix. This is the compressed representation of the input x before reconstruction.",
    "hint": "Think about what the 'encoding' step produces in the encoder part of the network."
  },
  {
    "question": "Autoencoders: According to the source, what is the main drawback of a linear autoencoder?",
    "options": [
      {
        "text": "It cannot be used for dimensionality reduction.",
        "image": ""
      },
      {
        "text": "It performs poorly with non-linear data.",
        "image": ""
      },
      {
        "text": "It requires extensive computational resources.",
        "image": ""
      },
      {
        "text": "The mapping is linear, limiting its ability to capture complex non-linear data.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Linear autoencoders can only learn linear representations because both encoder and decoder are linear transformations. This limits their ability to capture complex, non-linear patterns that exist in real-world data.",
    "hint": "Consider what happens when the data itself has non-linear structure."
  },
  {
    "question": "Autoencoders: In the context of the source, what is Principal Component Analysis (PCA) equivalent to?",
    "options": [
      {
        "text": "A deep nonlinear autoencoder.",
        "image": ""
      },
      {
        "text": "A sparse autoencoder.",
        "image": ""
      },
      {
        "text": "A linear autoencoder with a single hidden layer and linear activation functions.",
        "image": ""
      },
      {
        "text": "A denoising autoencoder.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "PCA performs singular value decomposition to find orthogonal directions of maximum variance. A linear autoencoder with a single hidden layer and linear activations learns the same subspace through gradient descent, making them mathematically equivalent.",
    "hint": "Think about the mathematical properties of linear layers and PCA."
  },
  {
    "question": "Autoencoders: What are Eigenfaces, as described in the source?",
    "options": [
      {
        "text": "A specific type of autoencoder architecture.",
        "image": ""
      },
      {
        "text": "Randomly generated facial images.",
        "image": ""
      },
      {
        "text": "The principal components (or eigenvectors) of a large set of facial images.",
        "image": ""
      },
      {
        "text": "Non-linear transformations of facial images.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Eigenfaces are the eigenvectors (principal components) obtained by applying PCA to a large dataset of facial images. Each eigenface represents a principal direction of variation in face images.",
    "hint": "Remember that eigenfaces come from applying PCA to face images."
  },
  {
    "question": "Autoencoders: According to the source, what does the value of the eigenvalues in PCA represent?",
    "options": [
      {
        "text": "The amount of noise present in the image.",
        "image": ""
      },
      {
        "text": "The size of the dataset.",
        "image": ""
      },
      {
        "text": "The amount of variance each eigenface captures.",
        "image": ""
      },
      {
        "text": "The total number of faces in the dataset.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In PCA, eigenvalues quantify how much variance each principal component (eigenface) captures. Larger eigenvalues indicate directions in which the data varies the most.",
    "hint": "Think about what PCA maximizes and what the eigenvalues represent mathematically."
  },
  {
    "question": "Autoencoders: How are the weights (or coefficients) for each eigenface found, according to the source?",
    "options": [
      {
        "text": "By random initialization.",
        "image": ""
      },
      {
        "text": "By applying a non-linear activation function.",
        "image": ""
      },
      {
        "text": "By projecting the original face onto the eigenfaces.",
        "image": ""
      },
      {
        "text": "By calculating the mean of the image.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In eigenface-based face recognition, the weights (coefficients) are computed by projecting the original face image onto each eigenface using dot product, representing the face as a linear combination of eigenfaces.",
    "hint": "Think about how you represent a face as a combination of basis faces."
  },
  {
    "question": "Autoencoders: Which of the following is a limitation of using eigenfaces for face recognition as mentioned in the source?",
    "options": [
      {
        "text": "They are not sensitive to facial expressions.",
        "image": ""
      },
      {
        "text": "They are highly effective with any data set",
        "image": ""
      },
      {
        "text": "They can capture any non-linear variation of a face",
        "image": ""
      },
      {
        "text": "They are sensitive to variations in lighting, pose, and facial expressions.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Eigenfaces capture variations in pixel intensity patterns but are sensitive to external factors like lighting changes, different poses, and facial expressions that alter the pixel values significantly.",
    "hint": "Consider what happens to pixel values when lighting or pose changes."
  },
  {
    "question": "Autoencoders: What distinguishes a deep autoencoder from a linear autoencoder?",
    "options": [
      {
        "text": "A deep autoencoder uses a single hidden layer with linear activation.",
        "image": ""
      },
      {
        "text": "A deep autoencoder projects data onto a non-linear manifold, instead of a subspace.",
        "image": ""
      },
      {
        "text": "A deep autoencoder is only useful for supervised learning tasks",
        "image": ""
      },
      {
        "text": "A deep autoencoder uses only labeled data",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Deep autoencoders with non-linear activation functions can learn non-linear manifolds, whereas linear autoencoders (with linear activation) can only learn linear subspaces, similar to PCA.",
    "hint": "Think about how multiple non-linear layers create more complex representations."
  },
  {
    "question": "Autoencoders: What is the key characteristic of an undercomplete autoencoder?",
    "options": [
      {
        "text": "The hidden layer has more units than the input layer.",
        "image": ""
      },
      {
        "text": "The embedded space has a lower dimensionality than the input space.",
        "image": ""
      },
      {
        "text": "The model overfits to the training data.",
        "image": ""
      },
      {
        "text": "The hidden layer uses non-linear activation.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Undercomplete autoencoders force compression by having a bottleneck (hidden) layer with fewer units than the input, learning a lower-dimensional embedded representation.",
    "hint": "Consider what the prefix 'under-' implies about the bottleneck layer size."
  },
  {
    "question": "Autoencoders: What is the main challenge with overcomplete autoencoders?",
    "options": [
      {
        "text": "They are difficult to train.",
        "image": ""
      },
      {
        "text": "They perform poorly with complex data.",
        "image": ""
      },
      {
        "text": "Without proper constraints, they can overfit by simply copying the input to the output.",
        "image": ""
      },
      {
        "text": "They cannot capture the data's hidden structure.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Overcomplete autoencoders with more hidden units than inputs can learn the identity function, simply copying input to output without learning meaningful features, leading to overfitting.",
    "hint": "Think about what happens when the hidden layer is larger than the input."
  },
  {
    "question": "Autoencoders: What is a stacked autoencoder?",
    "options": [
      {
        "text": "An autoencoder with a very small hidden layer.",
        "image": ""
      },
      {
        "text": "An autoencoder consisting of multiple encoding and decoding layers.",
        "image": ""
      },
      {
        "text": "An autoencoder that can only learn linear features.",
        "image": ""
      },
      {
        "text": "An autoencoder that operates exclusively on labeled data.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Uno stacked autoencoder è un' architettura profonda che utilizza più livelli di codifica e decodifica impilati, permettendo di apprendere rappresentazioni gerarchiche dei dati a diversi livelli di astrazione.",
    "hint": "Il termine 'stacked' indica la presenza di più livelli nell'architettura."
  },
  {
    "question": "Autoencoders: According to the source, what does the layer-wise training of a stacked autoencoder achieve?",
    "options": [
      {
        "text": "It leads to overfitting.",
        "image": ""
      },
      {
        "text": "It makes training more complex.",
        "image": ""
      },
      {
        "text": "It simplifies optimization and ensures meaningful feature learning at each step.",
        "image": ""
      },
      {
        "text": "It eliminates the need for pre-training.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il training layer-wise addestra ogni livello separatamente prima di combinarli, semplificando l'ottimizzazione di una rete profonda e garantendo che ogni livello apprenda feature significative incrementalmente.",
    "hint": "Pensare a come si addestra una rete profonda partendo da livelli più semplici."
  },
  {
    "question": "Autoencoders: What is a denoising autoencoder (DAE) designed to do?",
    "options": [
      {
        "text": "To compress data without loss.",
        "image": ""
      },
      {
        "text": "To learn robust, noise-resistant representations by reconstructing clean data from noisy inputs.",
        "image": ""
      },
      {
        "text": "To reduce the dimensionality of the input data.",
        "image": ""
      },
      {
        "text": "To only use clean data as input.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Un denoising autoencoder apprende rappresentazioni robuste addestrandosi a ricostruire dati puliti da input rumorosi, forcing la rete a apprendere feature che sono invarianti al rumore.",
    "hint": "Il nome stesso suggerisce l'obiettivo principale della rete."
  },
  {
    "question": "Autoencoders: How does a denoising autoencoder achieve noise-resistance?",
    "options": [
      {
        "text": "By reducing the size of the hidden layer.",
        "image": ""
      },
      {
        "text": "By training on noisy data and reconstructing the clean version.",
        "image": ""
      },
      {
        "text": "By adding random noise to the output.",
        "image": ""
      },
      {
        "text": "By adding labels to the input data.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La rete viene addestrata con input a cui è stato aggiunto rumore, ma deve ricostruire l'originale pulito, imparando così feature che rappresentano la struttura sottostante dei dati indipendentemente dal rumore.",
    "hint": "Considera cosa succede quando mostri alla rete dati 'imperfetti'."
  },
  {
    "question": "Autoencoders: What is a key characteristic of a sparse autoencoder?",
    "options": [
      {
        "text": "The hidden layer has fewer units than the input.",
        "image": ""
      },
      {
        "text": "Most hidden units should have zero activation.",
        "image": ""
      },
      {
        "text": "It uses only labeled data.",
        "image": ""
      },
      {
        "text": "It maps the data onto a linear subspace.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Un sparse autoencoder introduce un vincolo di sparsità che force la maggior parte delle unità nascoste ad avere attivazione prossima a zero, permettendo di scoprire feature più informative e specifiche.",
    "hint": "La sparsità riguarda l'attivazione dei neuroni nascosti."
  },
  {
    "question": "Autoencoders: What is the purpose of the sparsity penalty in a sparse autoencoder?",
    "options": [
      {
        "text": "To increase the complexity of the model.",
        "image": ""
      },
      {
        "text": "To encourage most hidden units to be inactive.",
        "image": ""
      },
      {
        "text": "To increase the amount of noise",
        "image": ""
      },
      {
        "text": "To reduce the reconstruction error to zero.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La penalità di sparsità (spesso implementata tramite divergenza KL) incoraggia le unità nascoste ad avere attivazioni medie basse, rendendo la maggior parte di esse inattive. Questo forza la rete a apprendere rappresentazioni più significative e distribuite.",
    "hint": "Pensa a cosa significa letteralmente 'sparso' - pochi elementi attivi su molti possibili."
  },
  {
    "question": "Autoencoders: According to the source, what does the Kullback-Leibler (KL) divergence measure in the context of sparse autoencoders?",
    "options": [
      {
        "text": "The reconstruction error.",
        "image": ""
      },
      {
        "text": "The amount of noise in the input data.",
        "image": ""
      },
      {
        "text": "The difference between the average activation of hidden units and a target sparsity value.",
        "image": ""
      },
      {
        "text": "The dimensionality of the latent space.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La divergenza KL misura la differenza tra la distribuzione di attivazione media delle unità nascoste e un valore di sparsità desiderato (target), penalizzando le deviazioni da tale obiettivo.",
    "hint": "La KL è una misura di divergenza tra due distribuzioni di probabilità."
  },
  {
    "question": "Autoencoders: a) Classify data into predefined categories.",
    "options": [
      {
        "text": "Classify data into predefined categories.",
        "image": ""
      },
      {
        "text": "Reconstruct its input by predicting an approximation.",
        "image": ""
      },
      {
        "text": "Generate new data samples similar to the input.",
        "image": ""
      },
      {
        "text": "Reduce the dimensionality of the data for visualization purposes only.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Gli autoencoder sono modelli di apprendimento non supervisionato che ricostruiscono l'input imparando prima una rappresentazione compressa (spazio latente) e poi decodificandola, con l'obiettivo di minimizzare l'errore di ricostruzione.",
    "hint": "Il nome stesso suggerisce qualcosa che codifica e poi decodifica se stesso."
  },
  {
    "question": "Autoencoders: The 'bottleneck' in an autoencoder architecture refers to:",
    "options": [
      {
        "text": "The activation function used in the output layer.",
        "image": ""
      },
      {
        "text": "The hidden layer with a significantly smaller dimensionality than the input.",
        "image": ""
      },
      {
        "text": "The initial weight matrices of the encoder and decoder.",
        "image": ""
      },
      {
        "text": "The loss function that the network tries to minimize.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il bottleneck è lo strato nascosto centrale con un numero di unità significativamente inferiore rispetto agli strati di input e output. Questa compressione forzata obbliga la rete ad apprendere rappresentazioni efficienti dei dati.",
    "hint": "Il termine 'collo di bottiglia' suggerisce un restringimento nel mezzo della struttura."
  },
  {
    "question": "Autoencoders: What is the primary purpose of the dimensionality constraint in autoencoders?",
    "options": [
      {
        "text": "To increase the computational speed of the network.",
        "image": ""
      },
      {
        "text": "To force the network to learn meaningful patterns and structures in the data instead of memorising the input.",
        "image": ""
      },
      {
        "text": "To allow the network to handle high dimensional input data.",
        "image": ""
      },
      {
        "text": "To reduce the risk of overfitting.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La limitazione dimensionale forza l'autoencoder ad apprendere le caratteristiche più importanti dei dati invece di memorizzarli semplicemente. Senza questa compressione, la rete potrebbe copiare l'input senza estrarre pattern significativi.",
    "hint": "Cosa deve fare la rete per ricostruire l'input se non può memorizzarlo direttamente?"
  },
  {
    "question": "Autoencoders: Which of the following is NOT a typical application of autoencoders?",
    "options": [
      {
        "text": "Data compression.",
        "image": ""
      },
      {
        "text": "Feature learning for downstream tasks.",
        "image": ""
      },
      {
        "text": "Supervised classification with labelled data.",
        "image": ""
      },
      {
        "text": "Dimensionality reduction for visualisation.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Gli autoencoders sono modelli di apprendimento non supervisionato che imparano a comprimere e ricostruire i dati senza utilizzare etichette. Non sono progettati per attività di classificazione supervisionata, che richiedono dati etichettati e un'architettura diversa.",
    "hint": "Ricorda che gli autoencoders imparano rappresentazioni senza dati etichettati - sono non supervisionati."
  },
  {
    "question": "Autoencoders: A linear autoencoder, which uses linear activation functions, is functionally equivalent to:",
    "options": [
      {
        "text": "A deep neural network.",
        "image": ""
      },
      {
        "text": "Principal Component Analysis (PCA).",
        "image": ""
      },
      {
        "text": "A convolutional neural network.",
        "image": ""
      },
      {
        "text": "A recurrent neural network.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Un autoencoder lineare con attivazioni lineari esegue sostanzialmente una riduzione dimensionale lineare, trovando le componenti principali che catturano la maggior parte della varianza - esattamente ciò che fa PCA.",
    "hint": "Pensa a cosa succede quando limiti tutto a essere lineare - ottieni una proiezione lineare come in PCA."
  },
  {
    "question": "Autoencoders: In a linear autoencoder, the reconstruction of the input is computed as a linear transformation expressed as:",
    "options": [
      {
        "text": "x̂ = U + V + x",
        "image": ""
      },
      {
        "text": "x̂ = UVx",
        "image": ""
      },
      {
        "text": "x̂ = U * V * x",
        "image": ""
      },
      {
        "text": "x̂ =  V / U * x",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In un autoencoder lineare, l'encoder mappa l'input x a una rappresentazione nascosta come V*x, e il decoder ricostruisce come U*(V*x), ottenendo U*V*x.",
    "hint": "L'encoder trasforma prima, poi il decoder trasforma il risultato - è una composizione di due trasformazioni lineari."
  },
  {
    "question": "Autoencoders: According to the source, a linear autoencoder learns to choose a subspace that:",
    "options": [
      {
        "text": "Maximises the distance of the data points from the projections.",
        "image": ""
      },
      {
        "text": "Minimises the variance of the projections.",
        "image": ""
      },
      {
        "text": "Minimises the squared distance from the data to the projections and maximises the variance of the projections.",
        "image": ""
      },
      {
        "text": "Is randomly generated each training cycle.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Un autoencoder lineare impara a minimizzare l'errore di ricostruzione (distanza quadratica dai dati alle proiezioni) e contemporaneamente massimizza la varianza delle proiezioni, che è esattamente l'obiettivo di PCA.",
    "hint": "L'obiettivo è bilanciare fedeltà della ricostruzione e compattezza della rappresentazione."
  },
  {
    "question": "Autoencoders: Eigenfaces are:",
    "options": [
      {
        "text": "The result of applying non-linear transformations to faces.",
        "image": ""
      },
      {
        "text": "The principal components (or eigenvectors) of a large set of facial images.",
        "image": ""
      },
      {
        "text": "A set of facial images created by averaging the original dataset.",
        "image": ""
      },
      {
        "text": "A specific type of neural network.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Gli Eigenfaces sono gli autovettori (componenti principali) della matrice di covarianza di un grande insieme di immagini facciali, usati per la rappresentazione e riconoscimento di volti.",
    "hint": "Sono letteralmente le 'facce' ottenute analizzando le componenti principali - come i vettori propri di una matrice di covarianza."
  },
  {
    "question": "Autoencoders: What is the purpose of centering the data (subtracting the mean) before performing PCA on a set of face images?",
    "options": [
      {
        "text": "To increase the variance of the data",
        "image": ""
      },
      {
        "text": "To reduce the noise in the data",
        "image": ""
      },
      {
        "text": "To standardise the range of pixel values",
        "image": ""
      },
      {
        "text": "To ensure that the data is centered around zero",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "PCA computes principal components that maximize variance. When data is centered by subtracting the mean, the first component points in the direction of maximum variance rather than simply toward the mean, ensuring the analysis captures true data patterns.",
    "hint": "Think about what PCA actually maximizes and how the mean affects this calculation."
  },
  {
    "question": "Autoencoders: When recognising faces using eigenfaces, each face is represented as:",
    "options": [
      {
        "text": "A new image composed from a random set of pixels",
        "image": ""
      },
      {
        "text": "A set of binary digits",
        "image": ""
      },
      {
        "text": "A compressed image that has a lower resolution",
        "image": ""
      },
      {
        "text": "A weighted sum of eigenfaces",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Eigenfaces are the eigenvectors (principal components) of the covariance matrix of face images. Any face can be approximated as a linear combination of these eigenfaces, where the weights represent the face's projection onto each eigenface.",
    "hint": "Remember that eigenfaces form a basis set for representing faces."
  },
  {
    "question": "Autoencoders: Which of the following is a limitation of using eigenfaces for facial recognition?",
    "options": [
      {
        "text": "Their high computational complexity.",
        "image": ""
      },
      {
        "text": "Their inability to generalize to different people.",
        "image": ""
      },
      {
        "text": "Their effectiveness is not dependent on the training data quality.",
        "image": ""
      },
      {
        "text": "Their sensitivity to variations in lighting, pose, and facial expressions.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Eigenfaces are based on pixel intensities and linear transformations, making them sensitive to changes in lighting conditions, face pose, and facial expressions. These variations can significantly alter the pixel values and thus the eigenface representation.",
    "hint": "Consider how real-world variations affect the pixel-level representation used by eigenfaces."
  },
  {
    "question": "Autoencoders: Deep autoencoders project the data onto a:",
    "options": [
      {
        "text": "Linear subspace",
        "image": ""
      },
      {
        "text": "Nonlinear manifold",
        "image": ""
      },
      {
        "text": "Randomly generated vector space",
        "image": ""
      },
      {
        "text": "Discrete set of points",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Deep autoencoders use non-linear activation functions (like sigmoid, ReLU) that allow them to learn non-linear manifolds, unlike linear PCA which can only project onto linear subspaces.",
    "hint": "Think about how non-linear activation functions enable more complex representations."
  },
  {
    "question": "Autoencoders: An undercomplete autoencoder is characterized by:",
    "options": [
      {
        "text": "A hidden layer larger than the input layer",
        "image": ""
      },
      {
        "text": "The absence of regularization techniques",
        "image": ""
      },
      {
        "text": "A hidden layer smaller than the input layer",
        "image": ""
      },
      {
        "text": "A tendency to overfit the data.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "An undercomplete autoencoder has a hidden layer with fewer neurons than the input layer, creating a bottleneck that forces the network to learn compressed representations by capturing the most important features.",
    "hint": "Consider what 'undercomplete' means in terms of the hidden layer size relative to the input."
  },
  {
    "question": "Autoencoders: What is the main challenge associated with overcomplete autoencoders?",
    "options": [
      {
        "text": "Difficulty in learning any meaningful features.",
        "image": ""
      },
      {
        "text": "Tendency to underfit the data due to low capacity.",
        "image": ""
      },
      {
        "text": "Overfitting by simply copying the input to the output",
        "image": ""
      },
      {
        "text": "Difficulty with using regularization techniques",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Overcomplete autoencoders have more hidden units than input dimensions, which gives them excessive capacity. Without proper constraints, they can simply learn the identity function by copying inputs directly to outputs, which is a form of overfitting where no useful compression or feature learning occurs.",
    "hint": "Think about what happens when a model has more capacity than needed for the task."
  },
  {
    "question": "Autoencoders: A stacked autoencoder introduces which property to the network?",
    "options": [
      {
        "text": "Linear transformations",
        "image": ""
      },
      {
        "text": "Reduced computational costs",
        "image": ""
      },
      {
        "text": "Hierarchical representations of the input data",
        "image": ""
      },
      {
        "text": "The ability to only use labelled training data",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Stacked autoencoders combine multiple autoencoders in sequence, creating a deep neural network. This architecture enables learning hierarchical representations where each layer learns increasingly abstract features from the previous layer's representations.",
    "hint": "Consider how stacking multiple encoders creates a deep structure with multiple levels of abstraction."
  },
  {
    "question": "Autoencoders: In the simplified training of a stacked autoencoder:",
    "options": [
      {
        "text": "All layers are trained simultaneously",
        "image": ""
      },
      {
        "text": "The layers are only trained with labelled data",
        "image": ""
      },
      {
        "text": "The output of one layer is used as input to train the next",
        "image": ""
      },
      {
        "text": "All layers share the same weight matrices.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Stacked autoencoders use greedy layer-wise training, where each autoencoder is trained independently before adding the next layer. The trained encoder's output becomes the training input for the next layer, building the stack progressively.",
    "hint": "Think about how each layer is trained one at a time, with the previous layer's output feeding into the next."
  },
  {
    "question": "Autoencoders: What is a key feature of denoising autoencoders (DAE)?",
    "options": [
      {
        "text": "They only use labelled training data.",
        "image": ""
      },
      {
        "text": "They are trained to generate new data",
        "image": ""
      },
      {
        "text": "They are trained to directly reconstruct the input without using any noise",
        "image": ""
      },
      {
        "text": "They are trained to reconstruct clean data from noisy inputs",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Denoising autoencoders are trained on corrupted inputs (with added noise) but must reconstruct the original clean data. This forces the model to learn robust features that capture the underlying data structure rather than simply memorizing training examples.",
    "hint": "Consider what the model must learn to recover clean data from corrupted inputs."
  },
  {
    "question": "Autoencoders: Sparse autoencoders enforce sparsity by:",
    "options": [
      {
        "text": "Ensuring that all hidden units have non-zero activation.",
        "image": ""
      },
      {
        "text": "Removing some hidden units during training.",
        "image": ""
      },
      {
        "text": "Reducing the size of the hidden layer.",
        "image": ""
      },
      {
        "text": "Encouraging most hidden units to have zero activation",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Sparse autoencoders impose a sparsity constraint that encourages most hidden units to have zero or near-zero activation. This is typically achieved through regularization techniques like L1 regularization or KL divergence, forcing the network to use only a small subset of neurons for each input.",
    "hint": "Sparsity means most neurons should remain inactive - think about what activation values represent this state."
  },
  {
    "question": "Autoencoders: The Kullback-Leibler (KL) divergence in sparse autoencoders is used to:",
    "options": [
      {
        "text": "Minimise the reconstruction error",
        "image": ""
      },
      {
        "text": "Match the average activation of hidden units to a target sparsity value",
        "image": ""
      },
      {
        "text": "Maximise the number of active hidden units",
        "image": ""
      },
      {
        "text": "Increase the dimensionality of the hidden layer",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The KL divergence term in sparse autoencoders penalizes the difference between the average activation of hidden units and a target sparsity value (typically small). This encourages most hidden units to be inactive, creating a sparse representation.",
    "hint": "Think about what 'sparsity' means - it refers to having few active units, and KL measures the difference between two distributions."
  },
  {
    "question": "Autoencoders: What are the weights in the context of face representation using eigenfaces?",
    "options": [
      {
        "text": "The pixels that represent the image",
        "image": ""
      },
      {
        "text": "The coefficients found by projecting the original face onto the eigenfaces",
        "image": ""
      },
      {
        "text": "The eigenvectors of the faces",
        "image": ""
      },
      {
        "text": "The eigenfaces themselves",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In eigenface representation, weights are the coefficients obtained by projecting the original face image onto the eigenfaces (eigenvectors). These coefficients form the face representation used for recognition.",
    "hint": "Remember that eigenfaces are the basis vectors, and projecting an image onto them gives coordinate coefficients."
  },
  {
    "question": "VAE: According to the source, the joint probability of observed data 'x' and latent variable 'z' in a VAE is expressed as:",
    "options": [
      {
        "text": "p(x,z) = p(x|z) + p(z)",
        "image": ""
      },
      {
        "text": "p(x,z) = p(x|z)p(z)",
        "image": ""
      },
      {
        "text": "p(x,z) = p(z|x)p(x)",
        "image": ""
      },
      {
        "text": "p(x,z) = p(x) / p(z)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "By the chain rule of probability, the joint distribution p(x,z) can be decomposed as p(x|z)p(z), where p(x|z) is the likelihood and p(z) is the prior. This is fundamental to generative models.",
    "hint": "Recall the basic probability rule: p(x,z) = p(x|z) * p(z)."
  },
  {
    "question": "VAE: The term 'p(x|z)' in the VAE framework represents:",
    "options": [
      {
        "text": "The prior distribution of the latent variable.",
        "image": ""
      },
      {
        "text": "The likelihood of observing 'x' given a specific value of 'z'.",
        "image": ""
      },
      {
        "text": "The posterior distribution of 'z' given 'x'.",
        "image": ""
      },
      {
        "text": "The marginal distribution of 'x'.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "p(x|z) represents the likelihood function in the VAE framework - it gives the probability of observing data x given a specific latent code z. This is modeled by the decoder/generative network.",
    "hint": "Think of this as the 'generative' part that creates x from latent z."
  },
  {
    "question": "VAE: In the VAE model, the probability of the observed data 'x' is obtained by:",
    "options": [
      {
        "text": "Maximizing p(x|z) over all possible values of 'z'.",
        "image": ""
      },
      {
        "text": "Integrating p(x|z)p(z) over all possible values of 'z'.",
        "image": ""
      },
      {
        "text": "Calculating the product of p(x|z) and p(z).",
        "image": ""
      },
      {
        "text": "Minimizing the squared difference between 'x' and its reconstruction.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The marginal likelihood p(x) in VAE is obtained by integrating (summing) the joint probability p(x,z) = p(x|z)p(z) over all possible latent values z. This is intractable to compute directly.",
    "hint": "Remember that p(x) = ∫ p(x|z)p(z) dz is the marginal distribution obtained by 'integrating out' z."
  },
  {
    "question": "VAE: According to the source, the encoder in a VAE aims to approximate:",
    "options": [
      {
        "text": "p(x|z)",
        "image": ""
      },
      {
        "text": "p(z|x)",
        "image": ""
      },
      {
        "text": "p(z)",
        "image": ""
      },
      {
        "text": "p(x)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The encoder learns the mapping from input x to the latent space z, approximating the posterior distribution p(z|x) - the probability of latent variables given the observed data.",
    "hint": "Think about what the encoder outputs: it predicts the distribution of latent variables z given the input x."
  },
  {
    "question": "VAE: The decoder network in a VAE is parameterised by:",
    "options": [
      {
        "text": "q(z|x)",
        "image": ""
      },
      {
        "text": "p(x|z)",
        "image": ""
      },
      {
        "text": "p(z)",
        "image": ""
      },
      {
        "text": "p(x)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The decoder parameterizes the likelihood p(x|z), which represents the probability of reconstructing the original input x from a latent representation z.",
    "hint": "The decoder takes a latent code z and produces a reconstruction of the original input."
  },
  {
    "question": "VAE: The encoder in the VAE is denoted as:",
    "options": [
      {
        "text": "p(x|z)",
        "image": ""
      },
      {
        "text": "q(z|x)",
        "image": ""
      },
      {
        "text": "p(z)",
        "image": ""
      },
      {
        "text": "p(x)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In VAE notation, q(z|x) denotes the encoder's approximated posterior, which differs from the true posterior p(z|x). The q distribution is learned to approximate the true posterior.",
    "hint": "Remember that q is used to denote an approximation to the true posterior p."
  },
  {
    "question": "VAE: In a VAE, the Evidence Lower Bound (ELBO) is introduced as a:",
    "options": [
      {
        "text": "Direct computation of the marginal likelihood p(x).",
        "image": ""
      },
      {
        "text": "Tractable approximation to the log-likelihood of the observed data.",
        "image": ""
      },
      {
        "text": "A method to calculate the exact posterior p(z|x).",
        "image": ""
      },
      {
        "text": "A way to eliminate the need for integration over the latent space.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The ELBO provides a tractable lower bound on the log-marginal likelihood log p(x), which is otherwise intractable due to the integration over latent variables.",
    "hint": "Since computing the true marginal likelihood requires intractable integration, we use a lower bound instead."
  },
  {
    "question": "VAE: The ELBO is represented by the expression:",
    "options": [
      {
        "text": "E[log p(x|z)] + D_KL(q(z|x)||p(z))",
        "image": ""
      },
      {
        "text": "E[log p(x|z)] - D_KL(q(z|x)||p(z))",
        "image": ""
      },
      {
        "text": "E[log q(z|x)] - D_KL(p(z|x)||q(z))",
        "image": ""
      },
      {
        "text": "E[log p(z|x)] + D_KL(p(z|x)||p(z))",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The ELBO consists of a reconstruction term E[log p(x|z)] (expected log-likelihood of the data) minus the KL divergence term D_KL(q(z|x)||p(z)), which regularizes the latent space.",
    "hint": "The KL term acts as a regularizer, pulling q(z|x) toward the prior p(z), which is typically a standard Gaussian."
  },
  {
    "question": "VAE: The first term in the ELBO, E[log p(x|z)], represents:",
    "options": [
      {
        "text": "The regularization term of the model.",
        "image": ""
      },
      {
        "text": "The distribution of the latent variables",
        "image": ""
      },
      {
        "text": "The reconstruction accuracy of the decoder.",
        "image": ""
      },
      {
        "text": "The deviation of the posterior from the prior.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "This term computes the expected log-likelihood of the reconstruction, measuring how well the decoder can reconstruct the original input x from the sampled latent variables z. It directly quantifies reconstruction quality.",
    "hint": "Think about what p(x|z) represents - it's the probability of reconstructing x given z."
  },
  {
    "question": "VAE: The second term in the ELBO, D_KL(q(z|x)||p(z)), represents:",
    "options": [
      {
        "text": "The Kullback-Leibler divergence between the approximate posterior and the prior.",
        "image": ""
      },
      {
        "text": "The cross-entropy between the input and output.",
        "image": ""
      },
      {
        "text": "The variance of the latent space.",
        "image": ""
      },
      {
        "text": "The reconstruction accuracy of the encoder.",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "This is literally the definition of the term - it computes the KL divergence between the approximate posterior q(z|x) produced by the encoder and the prior p(z) over latent variables.",
    "hint": "This term compares two probability distributions over the latent space."
  },
  {
    "question": "VAE: What is the purpose of the KL divergence term in the VAE loss function?",
    "options": [
      {
        "text": "To increase the reconstruction error.",
        "image": ""
      },
      {
        "text": "To force the approximate posterior distribution of the latent variables to be close to the prior distribution.",
        "image": ""
      },
      {
        "text": "To make the latent variables deterministic.",
        "image": ""
      },
      {
        "text": "To reduce the computational complexity.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The KL term acts as a regularizer that forces the learned latent distribution to match a prior (usually standard Gaussian), ensuring a well-structured and continuous latent space that enables sampling.",
    "hint": "Consider what 'regularization' means in the context of constraining the latent space."
  },
  {
    "question": "VAE: The source mentions that if q(z|x) is equal to p(z) then:",
    "options": [
      {
        "text": "The model will underfit the data",
        "image": ""
      },
      {
        "text": "The ELBO will be equal to log(p(x))",
        "image": ""
      },
      {
        "text": "The reconstruction of x will have a lot of noise",
        "image": ""
      },
      {
        "text": "The KL-divergence term will be infinite",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "When q(z|x) equals p(z), the encoder ignores the input data entirely and always outputs the same prior distribution, losing all ability to capture data-specific information, which leads to underfitting.",
    "hint": "If the encoder outputs the same distribution regardless of input, what does it learn about the data?"
  },
  {
    "question": "VAE: According to the source, the approximate posterior q(z|x) is often assumed to be a:",
    "options": [
      {
        "text": "Uniform distribution",
        "image": ""
      },
      {
        "text": "Bernoulli distribution",
        "image": ""
      },
      {
        "text": "Gaussian distribution",
        "image": ""
      },
      {
        "text": "Poisson distribution",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The approximate posterior is typically assumed to be a Gaussian with mean and variance predicted by the encoder, enabling the reparameterization trick for backpropagation through sampling.",
    "hint": "Which distribution allows for easy sampling and the reparameterization trick?"
  },
  {
    "question": "VAE: In a VAE, if we assume that q(z|x) is a Gaussian distribution, then what are the two outputs of the encoder network?",
    "options": [
      {
        "text": "The mean and the variance of p(x|z)",
        "image": ""
      },
      {
        "text": "The mean and the variance of p(z)",
        "image": ""
      },
      {
        "text": "The mean and the variance of q(z|x)",
        "image": ""
      },
      {
        "text": "The reconstruction and the original input",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In VAEs, the encoder learns to approximate the posterior distribution q(z|x). When we assume q(z|x) is Gaussian, the encoder outputs the parameters (mean and variance) that fully characterize this distribution.",
    "hint": "Remember that q(z|x) is the approximate posterior learned by the encoder, not the prior or likelihood."
  },
  {
    "question": "VAE: The reparameterisation trick in VAEs allows us to:",
    "options": [
      {
        "text": "Calculate the reconstruction error without using samples from the latent distribution.",
        "image": ""
      },
      {
        "text": "Backpropagate through the sampling process of the latent variable z.",
        "image": ""
      },
      {
        "text": "Directly use the mean and variance of q(z|x) during training.",
        "image": ""
      },
      {
        "text": "Calculate the KL divergence without the need for approximations.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The reparameterization trick moves the randomness to an auxiliary variable ε, making z a deterministic function of parameters. This allows gradients to flow through the sampling operation during backpropagation.",
    "hint": "Think about why sampling normally prevents gradient flow and how we can make it differentiable."
  },
  {
    "question": "VAE: The reparameterisation trick expresses the latent variable ‘z’ as:",
    "options": [
      {
        "text": "z = μ + σ",
        "image": ""
      },
      {
        "text": "z = μ + σ ⊙ ε, where ε ~ N(0,I)",
        "image": ""
      },
      {
        "text": "z = μ * σ * ε",
        "image": ""
      },
      {
        "text": "z = μ / σ + ε",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The reparameterization trick expresses z as z = μ + σ ⊙ ε, where ε is sampled from a standard normal distribution. This separates the stochastic component from the learnable parameters μ and σ.",
    "hint": "The key is to separate randomness from learnable parameters while maintaining the same distribution."
  },
  {
    "question": "VAE: In the reparameterisation trick the random variable ε is drawn from:",
    "options": [
      {
        "text": "A uniform distribution",
        "image": ""
      },
      {
        "text": "A standard normal distribution",
        "image": ""
      },
      {
        "text": "The posterior distribution q(z|x)",
        "image": ""
      },
      {
        "text": "The prior distribution p(z)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In the reparameterization trick, ε is drawn from a standard normal distribution N(0,I), which is then scaled by σ and shifted by μ to produce z.",
    "hint": "We need a simple, fixed distribution that doesn't depend on learnable parameters."
  },
  {
    "question": "Backpropagation: What are the two key requirements for probabilities when using the Softmax classifier?",
    "options": [
      {
        "text": "They must be less than zero and sum to one.",
        "image": ""
      },
      {
        "text": "They must be greater than or equal to zero and not sum to one.",
        "image": ""
      },
      {
        "text": "They must be greater than or equal to zero and sum to greater than one.",
        "image": ""
      },
      {
        "text": "They must be greater than or equal to zero and sum to one",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Softmax naturally produces valid probabilities: exponentials ensure non-negativity, and the normalization term ensures all probabilities sum to exactly one.",
    "hint": "The softmax function is specifically designed to create a valid probability distribution from raw scores."
  },
  {
    "question": "Backpropagation: In the context of training a classifier, what does Maximum Likelihood Estimation aim to do?",
    "options": [
      {
        "text": "To minimise the likelihood of the observed data.",
        "image": ""
      },
      {
        "text": "To choose weights to maximise the likelihood of the observed data.",
        "image": ""
      },
      {
        "text": "To calculate the cross-entropy loss.",
        "image": ""
      },
      {
        "text": "To regularise the model.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Maximum Likelihood Estimation aims to find the model weights that maximize the probability of observing the training data. This is the fundamental principle behind training classifiers - we want weights that make the data most likely under our model.",
    "hint": "Think about what 'maximum likelihood' means - we want to maximize the probability of the data."
  },
  {
    "question": "Backpropagation: Cross-entropy is described as the sum of two components. Which of the following correctly identifies these components?",
    "options": [
      {
        "text": "Entropy and regularisation.",
        "image": ""
      },
      {
        "text": "Entropy and model complexity.",
        "image": ""
      },
      {
        "text": "Entropy and KL-divergence.",
        "image": ""
      },
      {
        "text": "KL-divergence and regularisation.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Cross-entropy can be mathematically decomposed into the sum of entropy and KL-divergence. This relationship comes from information theory and explains why cross-entropy is a natural loss function for probabilistic models.",
    "hint": "Remember that cross-entropy has roots in information theory, specifically relating to entropy and divergence measures."
  },
  {
    "question": "Backpropagation: What is the primary effect of L2 regularization on the weights of a model?",
    "options": [
      {
        "text": "It increases the magnitude of the weights.",
        "image": ""
      },
      {
        "text": "It \"spreads out\" the weights.",
        "image": ""
      },
      {
        "text": "It makes the model more complex.",
        "image": ""
      },
      {
        "text": "It has no effect on the weights.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L2 regularization adds a penalty term (λ||w||²) to the loss that discourages large weights, effectively distributing the weight values more evenly across all parameters. This prevents overfitting by constraining the magnitude of individual weights.",
    "hint": "Think about what adding a squared penalty term does to large vs. small weights."
  },
  {
    "question": "Backpropagation: When using gradient descent to find the best weights (W), what is the relationship between the data loss and the regularization term?",
    "options": [
      {
        "text": "They are independent of each other",
        "image": ""
      },
      {
        "text": "They are used separately, data loss first then regularization",
        "image": ""
      },
      {
        "text": "Data loss is applied only if the regularization loss is too high",
        "image": ""
      },
      {
        "text": "They are combined.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "The data loss and regularization term are combined into a single total loss function: L_total = L_data + λL_regularization. This combined loss is then minimized during gradient descent to balance fitting the data and preventing overfitting.",
    "hint": "Consider how gradient descent operates on a single scalar value - all components must be summed together."
  },
  {
    "question": "Backpropagation: Why is deriving gradients on paper considered a bad idea for complex models?",
    "options": [
      {
        "text": "It's too simple for non-linear functions",
        "image": ""
      },
      {
        "text": "It is very tedious, requires lots of matrix calculus and needs to be re-derived if loss changes.",
        "image": ""
      },
      {
        "text": "It only works for linear score functions.",
        "image": ""
      },
      {
        "text": "It is not possible.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Manual gradient derivation for complex models is extremely tedious, requiring extensive matrix calculus for each layer. Additionally, any change to the model architecture or loss function necessitates completely re-deriving all gradients from scratch.",
    "hint": "Think about why we need automated tools for this process in modern deep learning."
  },
  {
    "question": "Backpropagation: In the context of backpropagation, what are the two gradients that are multiplied using the chain rule?",
    "options": [
      {
        "text": "Upstream and downstream gradients",
        "image": ""
      },
      {
        "text": "Upstream and local gradients.",
        "image": ""
      },
      {
        "text": "Input and output gradients",
        "image": ""
      },
      {
        "text": "Weight and bias gradients",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In backpropagation, the chain rule multiplies the upstream gradient (coming from later layers/forward) by the local gradient (derivative of the operation with respect to that specific variable).",
    "hint": "Think about how error signals propagate from output to input through the network."
  },
  {
    "question": "Backpropagation: In a computational graph, what is the behavior of the \"add gate\" regarding gradients?",
    "options": [
      {
        "text": "It swaps multipliers.",
        "image": ""
      },
      {
        "text": "It adds gradients.",
        "image": ""
      },
      {
        "text": "It distributes gradients.",
        "image": ""
      },
      {
        "text": "It routes gradients.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "For an add gate (z = x + y), the local gradients are both 1, so the upstream gradient is simply passed through to each input equally - it distributes the gradient.",
    "hint": "Consider what happens mathematically when you differentiate z = x + y with respect to x and y."
  },
  {
    "question": "Backpropagation: In a computational graph, what is the behavior of the \"mul gate\" regarding gradients?",
    "options": [
      {
        "text": "It adds gradients.",
        "image": ""
      },
      {
        "text": "It distributes gradients",
        "image": ""
      },
      {
        "text": "It \"swaps multiplier\".",
        "image": ""
      },
      {
        "text": "It routes gradiens",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "For a mul gate (z = x * y), the local gradient for x is y and for y is x, so the upstream gradient gets multiplied by the OTHER input value - this is called 'swapping' the multiplier.",
    "hint": "Derive ∂z/∂x and ∂z/∂y for z = x * y and observe what each gets multiplied by."
  },
  {
    "question": "Backpropagation: In a computational graph, what is the behavior of the \"copy gate\" regarding gradients?",
    "options": [
      {
        "text": "It swaps multipliers.",
        "image": ""
      },
      {
        "text": "It distributes gradients",
        "image": ""
      },
      {
        "text": "It adds gradients.",
        "image": ""
      },
      {
        "text": "It routes gradients.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "A copy gate (where the same input goes to multiple outputs) has multiple backward paths, so the gradients from each output path sum together at the input.",
    "hint": "Think about when the same variable contributes to multiple parts of the computation."
  },
  {
    "question": "Backpropagation: In a computational graph, what is the behaviour of the \"max gate\" regarding gradients?",
    "options": [
      {
        "text": "It swaps multipliers.",
        "image": ""
      },
      {
        "text": "It distributes gradients",
        "image": ""
      },
      {
        "text": "It adds gradients.",
        "image": ""
      },
      {
        "text": "It routes gradients.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "For a max gate (z = max(x, y)), the gradient is 1 for whichever input was larger and 0 for the smaller one - it routes the entire gradient to the 'winner'.",
    "hint": "Only the input that actually determined the output (the max) should receive the gradient."
  },
  {
    "question": "Backpropagation: In a modularized implementation of backpropagation, what is a key function of a gate/node/function object?",
    "options": [
      {
        "text": "To only compute the result of an operation.",
        "image": ""
      },
      {
        "text": "To only calculate upstream gradient",
        "image": ""
      },
      {
        "text": "To cache some values for use in backward pass and multiply upstream and local gradients.",
        "image": ""
      },
      {
        "text": "To apply the chain rule on forward pass.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In un'implementazione modulare di backpropagation, ogni nodo deve sia memorizzare valori necessari per il backward pass (come gli input del forward pass) sia calcolare il gradiente locale moltiplicandolo per il gradiente upstream seguendo la chain rule.",
    "hint": "I gate devono fare sia forward che backward pass, non solo uno dei due."
  },
  {
    "question": "Backpropagation: When dealing with vector derivatives, what is the derivative called when mapping from a vector to a scalar?",
    "options": [
      {
        "text": "Jacobian",
        "image": ""
      },
      {
        "text": "Hessian",
        "image": ""
      },
      {
        "text": "Gradient",
        "image": ""
      },
      {
        "text": "Laplacian",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il gradient è la derivata di una funzione scalare rispetto a un vettore, risultando in un vettore della stessa forma che indica la direzione di massima pendenza.",
    "hint": "È la generalizzazione della derivata per funzioni a più variabili."
  },
  {
    "question": "Backpropagation: When dealing with vector derivatives, what is the derivative called when mapping from a vector to a vector?",
    "options": [
      {
        "text": "Gradient",
        "image": ""
      },
      {
        "text": "Hessian",
        "image": ""
      },
      {
        "text": "Jacobian",
        "image": ""
      },
      {
        "text": "Laplacian",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La Jacobian è la matrice delle derivate parziali di tutti gli output rispetto a tutti gli input, quindi rappresenta il mapping completo da vettore a vettore.",
    "hint": "È una matrice, non un vettore o uno scalare."
  },
  {
    "question": "Backpropagation: In backpropagation with vectors, what is the loss (L) considered to be?",
    "options": [
      {
        "text": "A vector.",
        "image": ""
      },
      {
        "text": "A matrix.",
        "image": ""
      },
      {
        "text": "A tensor.",
        "image": ""
      },
      {
        "text": "A scalar.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La loss function aggrega tutti gli errori in un singolo valore scalare che misura l'errore totale del modello, e la backpropagation propaga i gradienti a partire da questo valore.",
    "hint": "La backpropagation parte da un singolo valore di errore."
  },
  {
    "question": "Backpropagation: In backpropagation with vectors, what is the relationship between the shape of dL/dx and x?",
    "options": [
      {
        "text": "dL/dx is always larger than x.",
        "image": ""
      },
      {
        "text": "dL/dx is always smaller than x.",
        "image": ""
      },
      {
        "text": "dL/dx always has the same shape as x.",
        "image": ""
      },
      {
        "text": "Their shapes are unrelated.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il gradiente dL/dx ha sempre la stessa forma di x perché rappresenta la derivata rispetto a ciascun elemento del vettore, permettendo aggiornamenti parametro per parametro.",
    "hint": "Per applicare la chain rule, le dimensioni devono essere compatibili."
  },
  {
    "question": "Backpropagation: When backpropagating through a matrix multiplication, what is the primary challenge in dealing with Jacobians?",
    "options": [
      {
        "text": "They are difficult to compute",
        "image": ""
      },
      {
        "text": "They are always sparse",
        "image": ""
      },
      {
        "text": "They are always dense",
        "image": ""
      },
      {
        "text": "They take too much memory, so we must work with them implicitly",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Jacobians can be extremely large matrices—for deep networks with millions of parameters, storing the full Jacobian would require billions of elements and gigabytes of memory. We therefore work with them implicitly, computing gradient contributions without materializing the entire matrix.",
    "hint": "Consider the size of a Jacobian for a typical layer with thousands of neurons."
  },
  {
    "question": "Backpropagation: When performing backpropagation with matrices, what does an element of X affect in the output Y (considerando che Y = X x W)?",
    "options": [
      {
        "text": "Only one element of y.",
        "image": ""
      },
      {
        "text": "Only one column of y.",
        "image": ""
      },
      {
        "text": "The whole row of y.",
        "image": ""
      },
      {
        "text": "It doesn't affect y.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In matrix multiplication Y = X × W, each row of X is a vector that multiplies with all columns of W to produce the corresponding row in Y. Therefore, every element in a row of X contributes to all elements in that same row of Y.",
    "hint": "Recall how row-by-column multiplication works in matrix operations."
  },
  {
    "question": "Backpropagation: What is the core principle of backpropagation?",
    "options": [
      {
        "text": "To optimise the loss function directly",
        "image": ""
      },
      {
        "text": "To compute gradients on forward pass",
        "image": ""
      },
      {
        "text": "To recursively apply the chain rule along a computational graph to compute the gradients of all inputs/parameters/intermediates",
        "image": ""
      },
      {
        "text": "To implement forward pass without saving any intermediates",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Backpropagation recursively applies the chain rule from calculus, propagating error gradients backward through the computational graph defined by the network architecture to compute gradients for all parameters and inputs.",
    "hint": "What fundamental calculus rule enables gradient computation through nested functions?"
  },
  {
    "question": "Backpropagation: What are the two essential methods that nodes implement in a modularized backpropagation system?",
    "options": [
      {
        "text": "Train() and Predict()",
        "image": ""
      },
      {
        "text": "Input() and Output()",
        "image": ""
      },
      {
        "text": "Loss() and Regularisation()",
        "image": ""
      },
      {
        "text": "Forward() and Backward()",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "In modular design, each computational node implements forward() to compute outputs and save intermediates, and backward() to apply the chain rule and compute gradients with respect to inputs and parameters.",
    "hint": "What are the two distinct phases of the backpropagation algorithm?"
  },
  {
    "question": "Backpropagation: In a modularized backpropagation system, what is the purpose of the forward() method of a node?",
    "options": [
      {
        "text": "To apply the chain rule",
        "image": ""
      },
      {
        "text": "To compute gradients",
        "image": ""
      },
      {
        "text": "To compute the result of an operation and save any intermediates needed for gradient computation.",
        "image": ""
      },
      {
        "text": "To update parameters.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The forward() method computes the actual output of the operation (e.g., matrix multiplication, ReLU) and stores any intermediate values (activations, pre-activations) that will be needed later by backward() to compute gradients.",
    "hint": "What must be preserved during the forward pass for the backward pass to work?"
  },
  {
    "question": "Backpropagation: In a modularized backpropagation system, what is the purpose of the backward() method of a node?",
    "options": [
      {
        "text": "To compute the result of an operation",
        "image": ""
      },
      {
        "text": "To save intermediates",
        "image": ""
      },
      {
        "text": "To update parameters",
        "image": ""
      },
      {
        "text": "To apply the chain rule to compute the gradient of the loss function with respect to the inputs",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "The backward() method implements the chain rule: it takes the gradient from the upstream (later) layers and multiplies it by the local gradient (derivative of the operation with respect to its inputs) to compute the gradient with respect to the loss.",
    "hint": "Backpropagation propagates error gradients backwards from output to input through the computational graph."
  },
  {
    "question": "Backpropagation: What is the primary difference between a linear classifier and a two-layer neural network?",
    "options": [
      {
        "text": "A neural network does not include a linear score function.",
        "image": ""
      },
      {
        "text": "A neural network has a simpler architecture.",
        "image": ""
      },
      {
        "text": "A neural network is linear.",
        "image": ""
      },
      {
        "text": "A neural network introduces a non-linear transformation with an activation function.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "The key difference is the presence of non-linear activation functions (like ReLU or sigmoid). Without these, stacking multiple linear layers would still result in a single linear transformation, so the network wouldn't be more powerful than a linear classifier.",
    "hint": "What makes a 'network' different from simply multiplying matrices together?"
  },
  {
    "question": "Backpropagation: According to the sources, what is the consequence of building a neural network without an activation function?",
    "options": [
      {
        "text": "It becomes a more powerful non-linear classifier",
        "image": ""
      },
      {
        "text": "It becomes computationally intractable",
        "image": ""
      },
      {
        "text": "It ends up being a linear classifier",
        "image": ""
      },
      {
        "text": "It cannot learn anything",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Without activation functions, the network consists only of linear transformations (matrix multiplications). The composition of linear functions remains linear, so even a deep network with many layers reduces to a single linear transformation.",
    "hint": "What is the result of multiplying multiple matrices together? Is it linear or non-linear?"
  },
  {
    "question": "Backpropagation: What does the Universal Approximation Theorem state in the context of Neural Networks?",
    "options": [
      {
        "text": "Neural networks always find a global minimum",
        "image": ""
      },
      {
        "text": "Neural networks always learn a linear function",
        "image": ""
      },
      {
        "text": "A sufficiently large neural network can approximate any discontinuous function",
        "image": ""
      },
      {
        "text": "A sufficiently large neural network can approximate any continuous function",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "The Universal Approximation Theorem proves that a feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function on compact subsets of R^n, given appropriate weights exist.",
    "hint": "The theorem guarantees existence of approximation, but not that we can actually find the weights."
  },
  {
    "question": "Backpropagation: What does the source say about training of Multi-Layer Perceptrons (MLPs)?",
    "options": [
      {
        "text": "It is convex.",
        "image": ""
      },
      {
        "text": "It is generally easy.",
        "image": ""
      },
      {
        "text": "It is always optimal.",
        "image": ""
      },
      {
        "text": "It is highly non-convex, with multiple local minima.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Training MLPs is highly non-convex due to the non-linear activation functions, resulting in a complex loss landscape with many local minima and saddle points. This makes optimization challenging and explains why initialization and optimization tricks are important.",
    "hint": "Think about the shape of the loss function - how many valleys might there be?"
  },
  {
    "question": "Backpropagation: What does the source state is a good default choice for an activation function?",
    "options": [
      {
        "text": "Sigmoid",
        "image": ""
      },
      {
        "text": "tanh",
        "image": ""
      },
      {
        "text": "ReLU",
        "image": ""
      },
      {
        "text": "ELU",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "ReLU is a good default choice because it's computationally efficient, helps mitigate the vanishing gradient problem, and works well in practice across many deep learning architectures.",
    "hint": "Consider which activation is simple, avoids gradient issues, and is computationally cheap."
  },
  {
    "question": "Backpropagation: What does the source say about using the size of a neural network as a regularizer?",
    "options": [
      {
        "text": "It is the best approach to regularize a network",
        "image": ""
      },
      {
        "text": "It is better to use implicit regularization",
        "image": ""
      },
      {
        "text": "It is always possible",
        "image": ""
      },
      {
        "text": "It is not a good idea; stronger regularization methods are preferred",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Using network size as regularization is not ideal because simply constraining capacity can lead to underfitting; stronger explicit regularization methods like dropout or L2 are more effective.",
    "hint": "Think about whether making a network smaller is the best way to prevent overfitting."
  },
  {
    "question": "Backpropagation: What are the key factors contributing to the advancements in deep learning, according to the provided text?",
    "options": [
      {
        "text": "Only massive parallel compute power",
        "image": ""
      },
      {
        "text": "Only availability of large datasets",
        "image": ""
      },
      {
        "text": "Only advances in machine learning over the years",
        "image": ""
      },
      {
        "text": "Availability of large datasets, massive parallel compute power, and advances in machine learning",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Deep learning advancements require the combination of large datasets, powerful parallel computing (GPUs), and progress in ML algorithms - no single factor is sufficient alone.",
    "hint": "Consider what enables modern deep learning breakthroughs - is it one thing or multiple??"
  },
  {
    "question": "Backpropagation: According to the sources, what is a limitation of hand-crafted features used in traditional machine learning?",
    "options": [
      {
        "text": "They are very efficient to compute",
        "image": ""
      },
      {
        "text": "They are very efficient to train",
        "image": ""
      },
      {
        "text": "They are often task specific",
        "image": ""
      },
      {
        "text": "They might be too general or too specific",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Hand-crafted features are designed by humans and can be either too general (losing important details) or too specific (failing to generalize), limiting their effectiveness.",
    "hint": "Think about the trade-off when humans manually design features for different tasks."
  },
  {
    "question": "Backpropagation: What is a key characteristic of features in deep learning, in contrast to traditional approaches?",
    "options": [
      {
        "text": "They are fixed",
        "image": ""
      },
      {
        "text": "They are hand-crafted",
        "image": ""
      },
      {
        "text": "They are trainable (parameterized)",
        "image": ""
      },
      {
        "text": "They are non-differentiable",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In deep learning, features are learned automatically from data through training (parameterized), unlike traditional approaches where features are fixed and hand-crafted.",
    "hint": "Consider how features are obtained in deep learning versus traditional ML methods."
  },
  {
    "question": "Backpropagation: In deep learning, what does \"end-to-end\" training refer to?",
    "options": [
      {
        "text": "The separation of feature extraction and classification",
        "image": ""
      },
      {
        "text": "Hand-crafting of features",
        "image": ""
      },
      {
        "text": "Training each layer of a network separately",
        "image": ""
      },
      {
        "text": "The joint training of feature extraction and classification as a single pipeline",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "End-to-end training refers to jointly optimizing the entire pipeline—from raw input to final output—as a single differentiable function, rather than pre-training separate components.",
    "hint": "Consider what 'end' means: from the beginning input to the final output."
  },
  {
    "question": "Backpropagation: What does the source emphasize about how complex systems in deep learning are built?",
    "options": [
      {
        "text": "They use extremely complicated individual blocks",
        "image": ""
      },
      {
        "text": "They are built by hand-crafting the individual components",
        "image": ""
      },
      {
        "text": "They require an extraordinary amount of data",
        "image": ""
      },
      {
        "text": "They are built via composition of simple building blocks",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Deep learning systems are built by stacking simple, basic operations (like linear transformations, ReLU, convolutions) to create complex hierarchical representations.",
    "hint": "Think about how neural networks are constructed from fundamental components."
  },
  {
    "question": "ConvNets: In the context of Convolutional Neural Networks, a fully connected layer applied to a 32x32x3 image involves stretching the image into a 3072x1 vector. What is the primary drawback of this approach?",
    "options": [
      {
        "text": "It increases the computational complexity of the network.",
        "image": ""
      },
      {
        "text": "It destroys the spatial structure of the image.",
        "image": ""
      },
      {
        "text": "It requires more memory than convolutional layers.",
        "image": ""
      },
      {
        "text": "It is difficult to implement.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Flattening a 2D image into a 1D vector loses all spatial information about pixel positions and their relationships with neighboring pixels.",
    "hint": "What structural information exists in an image that a flat vector cannot represent?"
  },
  {
    "question": "ConvNets: A convolutional layer processes a 32x32x3 image using a 5x5x3 filter. What does the output of a single filter application produce?",
    "options": [
      {
        "text": "A 32x32x1 activation map.",
        "image": ""
      },
      {
        "text": "A 28x28x1 activation map.",
        "image": ""
      },
      {
        "text": "A single number, representing a dot product of a 5x5x3 chunk of the input with the filter, plus bias",
        "image": ""
      },
      {
        "text": "A 5x5x3 feature map.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "With stride 1 and no padding, output size = (32 - 5 + 1) = 28. Each filter produces one 2D activation map representing the filter's response across the image.",
    "hint": "Apply the output size formula for valid padding: N_out = N_in - F + 1."
  },
  {
    "question": "ConvNets: In a convolutional layer, if you have multiple filters, say six filters, what is the result of applying those filters to a single input image?",
    "options": [
      {
        "text": "A single activation map with increased depth.",
        "image": ""
      },
      {
        "text": "Six activation maps which are then stacked up to get a new image of the same size but with a different depth.",
        "image": ""
      },
      {
        "text": "Six activation maps that are averaged to form a single map.",
        "image": ""
      },
      {
        "text": "Six separate images of the same spatial dimension as the input.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Each filter independently scans the input and produces its own 2D activation map. These maps are stacked along the depth dimension, increasing the depth of the output volume.",
    "hint": "What happens to the depth dimension when you add more filters?"
  },
  {
    "question": "ConvNets: What does it mean for a convolutional filter to \"slide\" over the image during the convolution operation?",
    "options": [
      {
        "text": "The filter moves across the image, changing its weights at each position.",
        "image": ""
      },
      {
        "text": "The filter is applied to different channels of the input volume sequentially.",
        "image": ""
      },
      {
        "text": "The filter computes dot products with small overlapping patches of the image at each location, resulting in an activation map",
        "image": ""
      },
      {
        "text": "The filter moves in a predetermined pattern, similar to a pooling operation.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "During convolution, the filter computes dot products between its weights and small overlapping image patches at each spatial location, producing a 2D activation map that indicates where the filter's pattern is detected.",
    "hint": "Think about what mathematical operation is performed at each position and what the output represents."
  },
  {
    "question": "ConvNets: What is a key difference between a convolutional layer and a fully connected layer in terms of how they process spatial information?",
    "options": [
      {
        "text": "A convolutional layer destroys spatial information, whereas a fully connected layer preserves it.",
        "image": ""
      },
      {
        "text": "A fully connected layer performs dot products between an input vector and a row of weights, while a convolutional layer does not",
        "image": ""
      },
      {
        "text": "A convolutional layer preserves the spatial structure of the input, whereas a fully connected layer stretches the input into a vector.",
        "image": ""
      },
      {
        "text": "A fully connected layer uses filters, whereas convolutional layers do not.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Convolutional layers use local connectivity to preserve the 2D spatial structure of the input, while fully connected layers flatten everything into a 1D vector, losing all positional information.",
    "hint": "Consider what happens to the height and width dimensions in each layer type."
  },
  {
    "question": "ConvNets: What is the consequence of having 6 separate 5x5 filters in a convolutional layer that acts on a 32x32x3 input?",
    "options": [
      {
        "text": "A single 28x28x6 activation map will be obtained.",
        "image": ""
      },
      {
        "text": "Six 28x28x1 activation maps are obtained which are then stacked to get a 28x28x6 \"new image\".",
        "image": ""
      },
      {
        "text": "A 28x28x3 activation map is obtained.",
        "image": ""
      },
      {
        "text": "Six different 32x32x3 images are obtained.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Each 5x5 filter applied to a 32x32x3 input produces one 28x28x1 activation map (output_size = input_size - filter_size + 1). With 6 filters, you get 6 separate maps that are stacked along the depth dimension.",
    "hint": "Remember that the number of filters determines the depth of the output, and each filter produces one feature map."
  },
  {
    "question": "ConvNets: What are the four hyperparameters that a convolutional layer needs?",
    "options": [
      {
        "text": "Filter size, stride, number of pooling layers, and number of fully connected layers",
        "image": ""
      },
      {
        "text": "Filter size, stride, padding, and number of pooling layers.",
        "image": ""
      },
      {
        "text": "Number of filters, the filter size, the stride and the zero padding",
        "image": ""
      },
      {
        "text": "Input size, filter size, stride, and number of output channels.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "These four hyperparameters control the convolution operation: number of filters determines output depth, filter size defines the receptive field, stride controls the step size, and zero padding preserves spatial dimensions.",
    "hint": "Think about what parameters you need to specify to completely define a convolution operation."
  },
  {
    "question": "ConvNets: What are the two primary functions of a pooling layer in a CNN?",
    "options": [
      {
        "text": "It adds learnable parameters and introduces spatial variance.",
        "image": ""
      },
      {
        "text": "It reduces the size of the representation and introduces spatial invariance.",
        "image": ""
      },
      {
        "text": "It increases the depth of the feature maps and makes the network deeper",
        "image": ""
      },
      {
        "text": "It adds non-linearity and performs non-linear combinations of features.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Pooling reduces the spatial dimensions of feature maps through downsampling (making computation more efficient) and introduces spatial invariance by making features robust to small translations and distortions.",
    "hint": "Consider both the effect on size and the effect on feature position sensitivity."
  },
  {
    "question": "ConvNets: How does a max pooling layer with 2x2 filters and a stride of 2 operate?",
    "options": [
      {
        "text": "It averages the values in each 2x2 region.",
        "image": ""
      },
      {
        "text": "It takes the maximum value in each 2x2 region.",
        "image": ""
      },
      {
        "text": "It multiplies the values in each 2x2 region by a scalar",
        "image": ""
      },
      {
        "text": "It applies a learnable function to each 2x2 region.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Max pooling is a downsampling operation that selects the maximum value from each 2x2 non-overlapping region, reducing spatial dimensions while preserving the most salient features.",
    "hint": "Remember that 'max' in max pooling refers to selecting the largest value, not averaging."
  },
  {
    "question": "ConvNets: What is a trend in recent CNN architectures regarding pooling and fully connected layers?",
    "options": [
      {
        "text": "A trend towards more pooling layers and larger fully connected layers",
        "image": ""
      },
      {
        "text": "A trend towards larger filters and wider architectures",
        "image": ""
      },
      {
        "text": "A trend towards smaller filters and deeper architectures",
        "image": ""
      },
      {
        "text": "A trend towards getting rid of pooling and fully connected layers (just CONV layers)",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Modern architectures like ResNet and GoogLeNet favor all-convolutional designs with global average pooling, eliminating traditional pooling and fully connected layers to reduce parameters and prevent overfitting.",
    "hint": "Think about how recent papers emphasize 'fully convolutional' networks and global pooling."
  },
  {
    "question": "ConvNets: According to the source, what is a typical structure of CNN architectures historically, before recent advancements like ResNet/GoogLeNet challenged it?",
    "options": [
      {
        "text": "A sequence of convolutional layers followed by a single fully connected layer",
        "image": ""
      },
      {
        "text": "A sequence of pooling layers followed by a sequence of convolutional layers",
        "image": ""
      },
      {
        "text": "A repeating pattern of (CONV-RELU)N followed by an optional POOL, repeated M times, followed by (FC-RELU)K, and a final SOFTMAX activation.",
        "image": ""
      },
      {
        "text": "A sequence of fully connected layers followed by a sequence of pooling layers.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The classic CNN structure follows a repeating pattern of CONV-RELU blocks, interspersed with pooling for downsampling, ending with FC layers for classification - the traditional LeNet/AlexNet pattern.",
    "hint": "This describes the canonical pattern seen in early deep learning architectures."
  },
  {
    "question": "MoreNN: During the training phase, how does dropout modify the activation of a neuron with a dropout rate of p?",
    "options": [
      {
        "text": "The neuron's activation is scaled by a factor of p.",
        "image": ""
      },
      {
        "text": "The neuron's activation is multiplied by 1-p.",
        "image": ""
      },
      {
        "text": "The neuron's activation is set to zero with a probability of p, otherwise its activation is preserved.",
        "image": ""
      },
      {
        "text": "The neuron's activation is always set to zero.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "During training, dropout randomly sets neuron activations to zero with probability p, forcing the network to learn redundant representations and preventing co-adaptation of neurons.",
    "hint": "Dropout is a regularization technique that temporarily 'drops out' neurons randomly."
  },
  {
    "question": "MoreNN: During inference (testing or validation), what adjustment is typically made to neuron activations in a network that uses dropout?",
    "options": [
      {
        "text": "No adjustments are made; neurons are used as they are.",
        "image": ""
      },
      {
        "text": "Neuron activations are multiplied by the dropout rate p.",
        "image": ""
      },
      {
        "text": "Neuron activations are scaled down by multiplying by (1-p).",
        "image": ""
      },
      {
        "text": "Neuron activations are set to zero.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "At inference time, activations are scaled by (1-p) to compensate for having all neurons active, maintaining the same expected activation magnitude as during training.",
    "hint": "Since all neurons are active during inference, scaling is needed to match training behavior."
  },
  {
    "question": "MoreNN: What is the purpose of scaling the activations by 1-p during inference when using dropout?",
    "options": [
      {
        "text": "To increase the magnitude of neuron activations.",
        "image": ""
      },
      {
        "text": "To compensate for the fact that fewer neurons were active during training.",
        "image": ""
      },
      {
        "text": "To introduce more randomness during the inference phase.",
        "image": ""
      },
      {
        "text": "To ensure the network learns different features during inference.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "During training with dropout, only a fraction (1-p) of neurons are active on average. To maintain the same expected output magnitude at inference time when all neurons are active, we scale activations by (1-p). This ensures the network's behavior is consistent between training and testing phases.",
    "hint": "Think about what happens to the expected value of activations when you randomly zero out neurons during training."
  },
  {
    "question": "MoreNN: In the \"inverse dropout\" formulation, when is the scaling applied to the activations, and what is the key benefit?",
    "options": [
      {
        "text": "Scaling is applied during inference, ensuring faster inference.",
        "image": ""
      },
      {
        "text": "Scaling is applied before training, resulting in faster convergence.",
        "image": ""
      },
      {
        "text": "Scaling is applied during training, ensuring the expected value of the activations remain consistent between training and inference.",
        "image": ""
      },
      {
        "text": "Scaling is applied after the backpropagation, for better generalization.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In inverse (inverted) dropout, scaling by 1/p is applied during training so that no scaling is needed at inference time. This ensures the expected value of activations remains the same during both phases, simplifying deployment.",
    "hint": "Consider where scaling must be applied to make training and inference mathematically equivalent in expectation."
  },
  {
    "question": "MoreNN: What is the \"vanishing gradient\" problem in deep neural networks?",
    "options": [
      {
        "text": "A situation where gradients become very large, causing instability in training.",
        "image": ""
      },
      {
        "text": "The tendency of neurons to deactivate randomly during training.",
        "image": ""
      },
      {
        "text": "A phenomenon where gradients become increasingly small as they propagate backward, making training difficult.",
        "image": ""
      },
      {
        "text": "A problem that only occurs in shallow networks.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The vanishing gradient problem occurs when gradients become exponentially small as they propagate backward through many layers, due to repeated multiplication of derivatives less than 1 (like in sigmoid/tanh activations). This makes early layers train very slowly.",
    "hint": "Think about what happens mathematically when you multiply numbers between 0 and 1 many times in sequence."
  },
  {
    "question": "MoreNN: What is the main purpose of residual connections (skip connections) in ResNets?",
    "options": [
      {
        "text": "To reduce the number of layers needed in a network.",
        "image": ""
      },
      {
        "text": "To add more non-linearity to the network.",
        "image": ""
      },
      {
        "text": "To address the vanishing gradient problem by allowing gradients to flow more easily through the network.",
        "image": ""
      },
      {
        "text": "To speed up training by reducing the number of computations.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Residual connections (skip connections) allow gradients to flow directly from later layers to earlier layers through the identity mapping, bypassing the weight layers. This addresses the vanishing gradient problem in very deep networks.",
    "hint": "Consider how adding the input directly to the output might create a 'highway' for gradient flow."
  },
  {
    "question": "MoreNN: How does a residual connection work mathematically?",
    "options": [
      {
        "text": "It replaces the layer's output with the original input.",
        "image": ""
      },
      {
        "text": "It multiplies the layer's output by the input.",
        "image": ""
      },
      {
        "text": "It adds the layer's input directly to its output h = F(x) + x.",
        "image": ""
      },
      {
        "text": "It subtracts the input from the layer's output.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "A residual connection works by adding the original input x to the transformed output F(x), giving h = F(x) + x. This 'residual' mapping makes it easier for the network to learn the identity function when needed.",
    "hint": "Think about what mathematical operation combines the input with the layer's computed features."
  },
  {
    "question": "MoreNN: What happens if the parameters in a residual unit are set such that F(x) = 0?",
    "options": [
      {
        "text": "The residual unit outputs a zero vector.",
        "image": ""
      },
      {
        "text": "The residual unit's output becomes exponentially large.",
        "image": ""
      },
      {
        "text": "The residual unit passes the input x through unmodified.",
        "image": ""
      },
      {
        "text": "The unit passes through a zero vector.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In a residual unit, the output is h(x) = F(x) + x. When F(x) = 0, the output becomes h(x) = 0 + x = x, so the input passes through unchanged.",
    "hint": "Recall the residual connection formula h(x) = F(x) + x."
  },
  {
    "question": "MoreNN: What is the key advantage of residual connections in backpropagation?",
    "options": [
      {
        "text": "It simplifies the backpropagation process.",
        "image": ""
      },
      {
        "text": "It ensures that the gradients vanish more quickly.",
        "image": ""
      },
      {
        "text": "It means the derivatives don't vanish as ∇ₓ h = ∇ₓ (F(x) + x) = ∂F / ∂x + I.",
        "image": ""
      },
      {
        "text": "It forces the network to learn different features for every layer.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The identity term I in the gradient ∇ₓ h = ∂F/∂x + I ensures that gradients have a direct path during backpropagation, preventing them from vanishing even when the derivative of F is small.",
    "hint": "Think about what the extra identity matrix I contributes to the gradient."
  },
  {
    "question": "MoreNN: What was the impact of Residual Networks (ResNets) on image classification performance on ImageNet?",
    "options": [
      {
        "text": "ResNets reduced the performance of image classification.",
        "image": ""
      },
      {
        "text": "ResNets achieved similar results to previous state-of-the-art models.",
        "image": ""
      },
      {
        "text": "ResNets achieved significantly lower error rates than previous models and even human performance, with a 152-layer ResNet achieving 4.49% top-5 error.",
        "image": ""
      },
      {
        "text": "ResNets could only be trained with a limited number of layers",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "ResNets introduced skip connections that enabled training of very deep networks (152 layers), achieving a 4.49% top-5 error that surpassed previous state-of-the-art and human performance (~5.1%).",
    "hint": "Consider the breakthrough in network depth and accuracy that skip connections made possible."
  },
  {
    "question": "MoreNN: What does \"standard scaling\" aim to achieve when preprocessing data?",
    "options": [
      {
        "text": "It ensures that each feature has a different mean.",
        "image": ""
      },
      {
        "text": "It ensures each feature (column) has zero mean and unit variance.",
        "image": ""
      },
      {
        "text": "It scales the data between 0 and 1.",
        "image": ""
      },
      {
        "text": "It increases the variance of each feature.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Standard scaling (z-score normalization) transforms each feature using the formula (x - μ) / σ, which centers the data to zero mean and scales it to unit variance.",
    "hint": "Think about the z-score formula and its effect on the distribution."
  },
  {
    "question": "MoreNN: In standard scaling, what do μ and σ² represent?",
    "options": [
      {
        "text": "μ is the sum and σ² is the variance of each feature/column.",
        "image": ""
      },
      {
        "text": "μ is the median and σ² is the standard deviation of each feature/column.",
        "image": ""
      },
      {
        "text": "μ is the mean and σ² is the variance of each feature/column.",
        "image": ""
      },
      {
        "text": "μ is the mean and σ² is the standard deviation of each feature/column.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In standard scaling, μ represents the mean and σ² represents the variance of each feature/column in the training data.",
    "hint": "Recall the notation used in the standard scaling formula (x - μ) / σ."
  },
  {
    "question": "MoreNN: What is the main goal of Batch Normalization (BN) in neural networks?",
    "options": [
      {
        "text": "To normalize the input data before training.",
        "image": ""
      },
      {
        "text": "To learn an optimal mean and variance for each unit of the network's layers during training.",
        "image": ""
      },
      {
        "text": "To reduce the number of parameters in the network.",
        "image": ""
      },
      {
        "text": "To simplify backpropagation.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "BN normalizes inputs for each layer by learning optimal mean and variance during training, introducing learnable parameters (gamma and beta) that allow the network to adjust the normalized values as needed.",
    "hint": "BN learns parameters to potentially undo the normalization if needed."
  },
  {
    "question": "MoreNN: How does Batch Normalization (BN) approximate the mean and variance?",
    "options": [
      {
        "text": "By calculating statistics over the entire dataset during each training step.",
        "image": ""
      },
      {
        "text": "By using the data in a mini-batch.",
        "image": ""
      },
      {
        "text": "By using a pre-defined set of values.",
        "image": ""
      },
      {
        "text": "By using the moving average of the previous layer.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "During training, BN uses the statistics (mean and variance) computed from the current mini-batch of data to normalize the inputs.",
    "hint": "The 'batch' in Batch Normalization refers to the mini-batch used during training."
  },
  {
    "question": "MoreNN: During BN training, how is the output H standardized, and what does ε do?",
    "options": [
      {
        "text": "H is standardized by subtracting its mean, and ε adds a small value to prevent division by zero.",
        "image": ""
      },
      {
        "text": "H is standardized by dividing by its variance, and ε increases the variance.",
        "image": ""
      },
      {
        "text": "H is standardized by multiplying by its standard deviation, and ε reduces the mean.",
        "image": ""
      },
      {
        "text": "H is standardized by adding its mean, and ε adjusts the variance.",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "The standardization formula is H_normalized = (H - mean) / sqrt(variance + ε), where ε is a small constant added to prevent division by zero when variance is close to zero.",
    "hint": "ε is purely for numerical stability, not to modify the variance."
  },
  {
    "question": "MoreNN: During BN training, what trainable parameters are introduced to set a new mean and variance for each column j?",
    "options": [
      {
        "text": "Two scalars, α and β.",
        "image": ""
      },
      {
        "text": "Two vectors, μ and σ.",
        "image": ""
      },
      {
        "text": "Two 2d values, αj and βj.",
        "image": ""
      },
      {
        "text": "Two matrices, W and b.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "BN introduces two learnable parameters per feature (typically called gamma and beta or scale and shift) that allow the network to learn the optimal mean and variance after normalization.",
    "hint": "These are per-channel/single values, not matrices or vectors of the same size as the layer."
  },
  {
    "question": "MoreNN: What are two common solutions used during inference to avoid the output depending on the mini-batch when using BN?",
    "options": [
      {
        "text": "Training with larger batch sizes and adjusting learning rates.",
        "image": ""
      },
      {
        "text": "Applying a different set of trainable parameters and using dropout.",
        "image": ""
      },
      {
        "text": "Post-training statistics calculation and moving average of statistics.",
        "image": ""
      },
      {
        "text": "Re-training with the entire dataset and applying a different activation function.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "During inference, BN uses moving averages of batch means and variances computed during training (population statistics) instead of mini-batch statistics to ensure consistent output regardless of input batch size.",
    "hint": "The network needs to use statistics learned during training, not dependent on the current inference input."
  },
  {
    "question": "MoreNN: How does Batch Normalization (BN) work with convolutional outputs that have dimensions (b, h, w, c)?",
    "options": [
      {
        "text": "?",
        "image": ""
      },
      {
        "text": "It normalizes across all dimensions, including the batch size.",
        "image": ""
      },
      {
        "text": "The mean and variance are computed per channel, normalizing independently across spatial dimensions and batch.",
        "image": ""
      },
      {
        "text": "It normalizes only across the batch size.",
        "image": ""
      },
      {
        "text": "It normalizes across spatial dimensions only.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In CNNs, BatchNorm treats each channel as a separate feature. For tensor (b,h,w,c), it computes mean and variance per channel across all b×h×w positions in the batch, then normalizes each spatial location independently for each channel.",
    "hint": "Remember that each filter in a CNN learns a different feature, and BatchNorm normalizes per channel."
  },
  {
    "question": "MoreNN: What is a limitation of Batch Normalization when using small batch sizes?",
    "options": [
      {
        "text": "Batch Normalization becomes more accurate with small batch sizes.",
        "image": ""
      },
      {
        "text": "The variance in the computed mean and variance estimates can become excessively high, leading to unstable training.",
        "image": ""
      },
      {
        "text": "It makes the network simpler to train.",
        "image": ""
      },
      {
        "text": "It decreases the computational overhead.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "BatchNorm estimates population statistics from mini-batch samples. With small batches, these estimates have high variance, making the normalization unreliable and causing training instability.",
    "hint": "Think about statistical reliability - do we trust statistics computed from few samples?"
  },
  {
    "question": "MoreNN: How does Layer Normalization differ from Batch Normalization?",
    "options": [
      {
        "text": "Layer Normalization normalizes across the batch, while Batch Normalization normalizes across features.",
        "image": ""
      },
      {
        "text": "Layer Normalization normalizes across features, while Batch Normalization normalizes across the mini-batch.",
        "image": ""
      },
      {
        "text": "Layer Normalization introduces learnable parameters, whereas Batch Normalization does not.",
        "image": ""
      },
      {
        "text": "Layer Normalization does not require the calculation of mean and variance.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "LayerNorm computes mean and variance across all features for each sample independently (each sample gets its own statistics), while BatchNorm computes statistics across the batch dimension for each feature.",
    "hint": "Consider what 'layer' means in LayerNorm - it normalizes across the feature dimension for one sample at a time."
  },
  {
    "question": "MoreNN: In what type of networks is Layer Normalization commonly used?",
    "options": [
      {
        "text": "CNNs for image classification.",
        "image": ""
      },
      {
        "text": "Forecasting neural networks working with time series and transformers.",
        "image": ""
      },
      {
        "text": "Generative adversarial networks (GANs).",
        "image": ""
      },
      {
        "text": "Recurrent neural networks (RNNs) for language modeling.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "LayerNorm doesn't depend on batch size because it computes statistics per sample, making it ideal for RNNs and Transformers where batch sizes can vary or be 1, especially with variable-length sequences.",
    "hint": "Which normalization works when you have batch size = 1?"
  },
  {
    "question": "MoreNN: What is the primary goal of data augmentation?",
    "options": [
      {
        "text": "To reduce the size of the training dataset.",
        "image": ""
      },
      {
        "text": "To decrease the complexity of the training data.",
        "image": ""
      },
      {
        "text": "To increase the size of the training dataset effectively by applying random transformations.",
        "image": ""
      },
      {
        "text": "To make the training process faster by using simpler examples.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Data augmentation applies random transformations (rotations, flips, crops, etc.) to existing training samples to create new variants, effectively expanding the dataset and improving model generalization.",
    "hint": "How can we create more training examples from the data we already have?"
  },
  {
    "question": "MoreNN: What are the typical transformations used in data augmentation?",
    "options": [
      {
        "text": "Only geometric transformations like flipping, cropping, and rotating.",
        "image": ""
      },
      {
        "text": "Only color and lighting adjustments like brightness, contrast and saturation.",
        "image": ""
      },
      {
        "text": "A combination of geometric transformations, color and lighting adjustments, noise and distortion, cutout/masking, and combination techniques.",
        "image": ""
      },
      {
        "text": "Only noise addition",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Data augmentation employs multiple transformation categories to artificially expand the training dataset and improve model generalization by preventing overfitting to specific patterns.",
    "hint": "Consider that real-world data varies in many ways - position, color, noise, and more."
  },
  {
    "question": "MoreNN: What is the main purpose of using 1D convolutions for time-series data?",
    "options": [
      {
        "text": "To extract global features or patterns that evolve over time.",
        "image": ""
      },
      {
        "text": "To extract local features or patterns that evolve over time.",
        "image": ""
      },
      {
        "text": "To make the time-series data stationary.",
        "image": ""
      },
      {
        "text": "To increase the dimensionality of the input.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "1D convolutions use local kernels (filters) that slide over sequential data to detect temporal patterns at specific time windows, unlike fully connected layers that consider the entire sequence at once.",
    "hint": "Think about what 'local' means in the context of a sliding window operation."
  },
  {
    "question": "MoreNN: How does a 1D convolution capture local dependencies in time series data?",
    "options": [
      {
        "text": "By averaging all time steps.",
        "image": ""
      },
      {
        "text": "By applying a filter of a fixed size that slides over the time series, detecting trends or repeated patterns.",
        "image": ""
      },
      {
        "text": "By only considering the first and last time steps.",
        "image": ""
      },
      {
        "text": "By considering the entire sequence at once.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "A convolution filter of fixed size moves step-by-step across the time series, computing weighted sums of neighboring time steps to detect local trends or recurring patterns.",
    "hint": "The key mechanism involves a sliding window operation across the sequence."
  },
  {
    "question": "MoreNN: What does it mean for a 1D convolution to have parameter sharing?",
    "options": [
      {
        "text": "The parameters change over time, allowing to learn specific behaviour for certain time-steps.",
        "image": ""
      },
      {
        "text": "The same filter is applied across all time steps, reducing the number of parameters and improving generalization.",
        "image": ""
      },
      {
        "text": "Different filters are applied to different time steps.",
        "image": ""
      },
      {
        "text": "The parameters are only used for a specific subset of the input.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Parameter sharing means the same learned filter weights are applied at every time step position, dramatically reducing total parameters compared to fully connected layers while enabling detection of the same pattern anywhere in the sequence.",
    "hint": "Consider what happens when you apply the same weights everywhere versus different weights at each position."
  },
  {
    "question": "MoreNN: What does translation invariance mean in the context of 1D convolutions?",
    "options": [
      {
        "text": "The model is sensitive to shifts in the time domain.",
        "image": ""
      },
      {
        "text": "The model does not consider the time order of the input.",
        "image": ""
      },
      {
        "text": "It helps in identifying features that are present at different time steps, making it robust to shifts in the time domain.",
        "image": ""
      },
      {
        "text": "It means the model can only detect patterns at a fixed time step.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Translation invariance means the model can recognize a pattern regardless of where it appears in the time dimension, making predictions robust to temporal shifts or delays in when events occur.",
    "hint": "Invariance means the output doesn't change when the input is shifted."
  },
  {
    "question": "MoreNN: What is the key characteristic of a causal convolution?",
    "options": [
      {
        "text": "The output at each time step depends on future time steps.",
        "image": ""
      },
      {
        "text": "The output at each time step depends only on the current and previous time steps.",
        "image": ""
      },
      {
        "text": "The output at each time step is independent of other time steps.",
        "image": ""
      },
      {
        "text": "The output at each time step is influenced by future and past time steps",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Causal convolution ensures temporal causality by restricting each output to depend only on the current and past inputs, preventing information leakage from future time steps.",
    "hint": "Think about the meaning of 'causal' in terms of time - it means effect cannot precede cause."
  },
  {
    "question": "MoreNN: In the context of time series forecasting with a causal model, what is one way to train a model?",
    "options": [
      {
        "text": "Pool the output representation H over all time steps and apply a regressor head to predict xn.",
        "image": ""
      },
      {
        "text": "Use a non-causal model to train.",
        "image": ""
      },
      {
        "text": "Pool only the first few steps in the time series.",
        "image": ""
      },
      {
        "text": "Disregard the time dependencies between the series.",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Pooling all hidden representations across time and applying a regressor head allows the model to leverage the entire sequence history to predict the next time step value.",
    "hint": "Consider how to combine all the time-dependent features for a single prediction."
  },
  {
    "question": "MoreNN: What is the difference between how 1D convolution and self-attention model sequences?",
    "options": [
      {
        "text": "1D convolution captures global dependencies, while self-attention captures local dependencies.",
        "image": ""
      },
      {
        "text": "1D convolution has quadratic complexity, while self-attention is more efficient.",
        "image": ""
      },
      {
        "text": "1D convolution captures local patterns using a sliding filter, while self-attention computes interactions between all elements.",
        "image": ""
      },
      {
        "text": "1D convolution uses weights for each pair of inputs, while self-attention shares weights.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "1D convolution processes local windows with a fixed-size filter, while self-attention computes attention scores between every pair of positions to capture global relationships.",
    "hint": "Compare the receptive field of a sliding filter versus direct pairwise comparisons."
  },
  {
    "question": "MoreNN: In self-attention mechanisms, what are the three transformed vectors derived from each token's embedding?",
    "options": [
      {
        "text": "Input, output, and hidden vectors.",
        "image": ""
      },
      {
        "text": "Weight, bias, and activation vectors.",
        "image": ""
      },
      {
        "text": "Query, Key, and Value vectors.",
        "image": ""
      },
      {
        "text": "Gradient, loss, and prediction vectors.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In self-attention, each embedding is transformed into three vectors: Query (what to look for), Key (what to match against), and Value (the actual information to retrieve).",
    "hint": "These three vectors are the core components of the attention mechanism."
  },
  {
    "question": "MoreNN: In the analogy with a web search, what corresponds to the \"Query\" vector in self-attention?",
    "options": [
      {
        "text": "The titles of web pages.",
        "image": ""
      },
      {
        "text": "The content of web pages.",
        "image": ""
      },
      {
        "text": "The search term you type—what you're looking for.",
        "image": ""
      },
      {
        "text": "The search engine algorithm.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The Query vector represents what information the current position is seeking, analogous to a search query that specifies what you're looking for.",
    "hint": "In the search analogy, Query is the question you ask, not the answer."
  },
  {
    "question": "MoreNN: What is the role of \"masking\" in masked self-attention?",
    "options": [
      {
        "text": "To amplify the attention scores of future tokens.",
        "image": ""
      },
      {
        "text": "To ensure the model only focuses on past tokens when predicting the next token.",
        "image": ""
      },
      {
        "text": "To randomize the attention scores to avoid bias.",
        "image": ""
      },
      {
        "text": "To ignore the past tokens and focus only on future tokens.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Masking prevents the model from attending to future tokens by setting their attention scores to negative infinity, ensuring causality in language modeling.",
    "hint": "Think about what the model should NOT see when predicting the next token."
  },
  {
    "question": "MoreNN: What is the purpose of passing the concatenated outputs of multiple self-attention heads through a Multilayer Perceptron (MLP) layer?",
    "options": [
      {
        "text": "To reduce the dimensionality of the output.",
        "image": ""
      },
      {
        "text": "To enhance the model's representational capacity after capturing diverse relationships.",
        "image": ""
      },
      {
        "text": "To compute attention scores.",
        "image": ""
      },
      {
        "text": "To apply positional embeddings.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The MLP processes the combined output from all attention heads to learn more complex, non-linear transformations of the diverse relationships captured.",
    "hint": "After combining multiple perspectives, what happens to enhance representational power?"
  },
  {
    "question": "MoreNN: What is the \"Add\" operation in a Transformer block?",
    "options": [
      {
        "text": "A fully connected layer",
        "image": ""
      },
      {
        "text": "A pooling layer",
        "image": ""
      },
      {
        "text": "A residual connection",
        "image": ""
      },
      {
        "text": "A layer normalization",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The 'Add' operation is a residual connection that adds the input of a sublayer to its output, facilitating gradient flow in deep networks.",
    "hint": "What helps gradients travel through deep networks without vanishing?"
  },
  {
    "question": "MoreNN: What is the \"Norm\" operation in a Transformer block?",
    "options": [
      {
        "text": "A fully connected layer.",
        "image": ""
      },
      {
        "text": "A residual connection",
        "image": ""
      },
      {
        "text": "A Batch Normalization",
        "image": ""
      },
      {
        "text": "A Layer Normalization",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Layer Normalization normalizes across the feature dimension (not batch dimension), standard in Transformers for training stability.",
    "hint": "Which normalization normalizes across features rather than batch samples?"
  },
  {
    "question": "MoreNN: What is the first step in representing text as input for a transformer?",
    "options": [
      {
        "text": "Applying a softmax function to the input text.",
        "image": ""
      },
      {
        "text": "Dividing text into tokens and converting them into numerical vectors called embeddings.",
        "image": ""
      },
      {
        "text": "Normalizing the text using a standard scaler.",
        "image": ""
      },
      {
        "text": "Applying data augmentation techniques to the text.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The first step is tokenization followed by embedding: converting text into discrete tokens and then representing each token as a numerical vector.",
    "hint": "Before applying any mathematical operations, what must first happen to raw text?"
  },
  {
    "question": "MoreNN: What are the main issues with word encoders?",
    "options": [
      {
        "text": "They are difficult to train and implement.",
        "image": ""
      },
      {
        "text": "They require huge computational power to represent words.",
        "image": ""
      },
      {
        "text": "They need to detect boundaries of words and treat different forms of the same word as separate types.",
        "image": ""
      },
      {
        "text": "They don't capture the semantic meaning of the words",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Gli word encoders trattano ogni parola come un token indivisibile, quindi parole morphologicalmente correlate (come 'run', 'running', 'runner') vengono memorizzate separatamente nel vocabolario, aumentando la dimensionalità e la sparsità.",
    "hint": "Pensa a come le variazioni grammaticali di una stessa radice vengono gestite a livello di parola."
  },
  {
    "question": "MoreNN: What are the characteristics of character encoders?",
    "options": [
      {
        "text": "They increase the complexity of the model and are easy to use.",
        "image": ""
      },
      {
        "text": "They reduce the complexity but are almost impossible to use.",
        "image": ""
      },
      {
        "text": "They make the model more robust and efficient.",
        "image": ""
      },
      {
        "text": "They are ideal for most NLP tasks.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Gli encoder a livello di carattere riducono drasticamente la dimensione del vocabolario (solo caratteri ASCII/Unicode), ma producono sequenze molto lunghe che rendono difficile l'apprendimento di rappresentazioni significative e aumentano il costo computazionale.",
    "hint": "Considera il trade-off tra dimensione del vocabolario e lunghezza delle sequenze generate."
  },
  {
    "question": "MoreNN: What is the byte pair encoding (BPE) algorithm used for?",
    "options": [
      {
        "text": "To represent each word as a single byte.",
        "image": ""
      },
      {
        "text": "To represent each character in a text as an integer.",
        "image": ""
      },
      {
        "text": "To create subword tokens by merging frequent character sequences.",
        "image": ""
      },
      {
        "text": "To compress text data into smaller files.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "BPE è un algoritmo di tokenizzazione subword che costruisce iterativamente il vocabolario unendo le coppie di token più frequenti nel corpus, creando token che bilanciano la granularità dei caratteri con il significato delle parole.",
    "hint": "L'algoritmo mergesce sequenze basandosi sulla loro frequenza nel training data."
  },
  {
    "question": "MoreNN: What is the first step in the BPE algorithm?",
    "options": [
      {
        "text": "Count the frequency of each character pair in the data",
        "image": ""
      },
      {
        "text": "Merge the characters into one symbol.",
        "image": ""
      },
      {
        "text": "Form a base vocabulary of all characters that occur in the training data.",
        "image": ""
      },
      {
        "text": "Tokenize the data.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il primo passo di BPE consiste nell'inizializzare il vocabolario con tutti i caratteri unici presenti nel training corpus (inclusi spazi e caratteri speciali), che serviranno come unità base per i successivi merge.",
    "hint": "Prima di poter unire coppie, devi avere le unità atomiche iniziali."
  },
  {
    "question": "MoreNN: What is the purpose of positional encodings in Transformer models?",
    "options": [
      {
        "text": "To reduce the dimensionality of the input.",
        "image": ""
      },
      {
        "text": "To inject order into the model by embedding position-specific information.",
        "image": ""
      },
      {
        "text": "To increase the variance of the input data.",
        "image": ""
      },
      {
        "text": "To prevent the model from overfitting.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "I Transformer usano self-attention che processa tutti i token simultaneamente senza ricorrenza, quindi le informazioni sull'ordine sequenziale devono essere aggiunte esplicitamente tramite positional encodings altrimenti il modello sarebbe invariante all'ordine.",
    "hint": "Il meccanismo di attenzione non ha memoria dell'ordine dei token."
  },
  {
    "question": "MoreNN: Why are positional encodings needed in transformers?",
    "options": [
      {
        "text": "Transformers do not need positional encodings because they can infer the order of the input.",
        "image": ""
      },
      {
        "text": "Because Transformers process all tokens simultaneously, they need positional encodings to be aware of the sequence information.",
        "image": ""
      },
      {
        "text": "Positional encodings are only needed for time-series data.",
        "image": ""
      },
      {
        "text": "Because Transformers can easily capture the order of the sequence.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Transformers use parallel processing to handle all tokens simultaneously, which means they have no inherent understanding of token order. Positional encodings provide the model with information about where each token appears in the sequence, which is essential for capturing sequential relationships.",
    "hint": "Consider how self-attention computes relationships between all tokens equally, regardless of their position in the sequence."
  },
  {
    "question": "MoreNN: How do relative positional embeddings work?",
    "options": [
      {
        "text": "They add information about the absolute position of the tokens.",
        "image": ""
      },
      {
        "text": "They only use static positional information.",
        "image": ""
      },
      {
        "text": "They consider the relative distance between tokens instead of their absolute positions.",
        "image": ""
      },
      {
        "text": "They only encode the first and last positions of the tokens.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Relative positional embeddings encode the distance and direction between pairs of tokens rather than their absolute positions. This approach helps the model generalize to sequences of varying lengths and captures positional relationships more flexibly.",
    "hint": "Think about how knowing the relative distance between two words helps understand their relationship regardless of where they appear in the text."
  },
  {
    "question": "MoreNN: What are the outputs of the transformer block and what are they used for?",
    "options": [
      {
        "text": "Logits, which represent probabilities of the next token, are used to select the most probable token or sample one.",
        "image": ""
      },
      {
        "text": "Embeddings, which are used for classification tasks.",
        "image": ""
      },
      {
        "text": "Attention scores, which are used for image generation.",
        "image": ""
      },
      {
        "text": "Key and value matrices, used for backpropagation",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "The transformer block outputs logits, which are raw scores converted to probabilities via softmax. These probability distributions over the vocabulary are used for next-token prediction, enabling text generation through greedy decoding or sampling.",
    "hint": "Consider what a language model fundamentally needs to decide at each step - selecting the next word from the entire vocabulary."
  },
  {
    "question": "MoreNN: What is the role of the \"temperature\" hyperparameter when generating text from a language model?",
    "options": [
      {
        "text": "The \"temperature\" is used to adjust the learning rate of the model",
        "image": ""
      },
      {
        "text": "It is used to adjust the size of the model",
        "image": ""
      },
      {
        "text": "It is used to control the size of the vocabulary used by the model",
        "image": ""
      },
      {
        "text": "It controls the randomness of the output by sharpening or softening the probability distribution.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Temperature scales the logits before applying softmax, thereby controlling the entropy of the output distribution. A high temperature (>1) produces more diverse/random outputs, while a low temperature (<1) makes the model more deterministic and confident in its predictions.",
    "hint": "Think of it as adjusting how 'bold' or 'conservative' the model's choices are during generation."
  },
  {
    "question": "LR: What is the primary goal of the cost function in linear regression?",
    "options": [
      {
        "text": "To maximize the difference between predicted and actual output values.",
        "image": ""
      },
      {
        "text": "To identify the optimal number of features for a model.",
        "image": ""
      },
      {
        "text": "To minimize the error between the predicted values and the actual target values.",
        "image": ""
      },
      {
        "text": "To determine the correlation between input and output variables.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The cost function in linear regression (typically Mean Squared Error) measures the discrepancy between predicted and actual values. The training process aims to find parameter values that minimize this error, thereby improving the model's predictive accuracy.",
    "hint": "Consider what mathematical quantity we optimize during training to make the line fit the data points better."
  },
  {
    "question": "LR: In the context of gradient descent, which statement accurately describes the effect of the learning rate (α)?",
    "options": [
      {
        "text": "A larger learning rate guarantees faster convergence to the global minimum.",
        "image": ""
      },
      {
        "text": "A smaller learning rate might cause the gradient descent to diverge from the minimum.",
        "image": ""
      },
      {
        "text": "If α is too small, gradient descent will be slow, and if α is too large, gradient descent might overshoot the minimum and even diverge.",
        "image": ""
      },
      {
        "text": "The learning rate should automatically decrease over time as gradient descent approaches a local minimum.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The learning rate controls the step size in parameter space. If α is too small, the algorithm takes tiny steps and converges slowly; if α is too large, the steps may be so big that the algorithm overshoots the minimum or even diverges (oscillates away).",
    "hint": "Think of the learning rate as the length of each step you take downhill."
  },
  {
    "question": "LR: What is the key distinction between \"batch\" gradient descent and stochastic gradient descent (SGD)?",
    "options": [
      {
        "text": "Batch gradient descent is an online method, while SGD is an offline method.",
        "image": ""
      },
      {
        "text": "Batch gradient descent updates parameters after each training example, whereas SGD does it using all training examples.",
        "image": ""
      },
      {
        "text": "Batch gradient descent calculates the gradient using all training examples in each iteration, while SGD uses only a single training example to update the gradient in each iteration.",
        "image": ""
      },
      {
        "text": "SGD is slower and requires more iterations than batch gradient descent.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Batch gradient descent computes the gradient using the entire dataset before each update, while SGD estimates the gradient using only a single training example at a time, leading to faster but noisier updates.",
    "hint": "Consider how many samples are used to calculate each gradient update."
  },
  {
    "question": "LR: Which of the following is NOT a method to calculate simple linear regression?",
    "options": [
      {
        "text": "Gradient Descent",
        "image": ""
      },
      {
        "text": "Normal equation",
        "image": ""
      },
      {
        "text": "Principal Component Analysis",
        "image": ""
      },
      {
        "text": "Software packages, e.g., NumPy polyfit",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Principal Component Analysis (PCA) is a dimensionality reduction technique used for feature extraction and visualization, not a method for finding the relationship between dependent and independent variables in regression.",
    "hint": "Ask yourself which technique is primarily used for supervised vs unsupervised learning."
  },
  {
    "question": "LR: What is the purpose of feature scaling in linear regression, and how is mean normalization typically applied?",
    "options": [
      {
        "text": "To increase the magnitude of the features and make the gradient descent faster.",
        "image": ""
      },
      {
        "text": "Feature scaling ensures that the features are on a similar scale and mean normalization replaces the feature value with *x*<sub>*i*</sub> - *μ*<sub>*i*</sub>, to have approximately zero mean.",
        "image": ""
      },
      {
        "text": "To add random noise to the features in order to prevent overfitting.",
        "image": ""
      },
      {
        "text": "Feature scaling is not required if we are using the normal equation.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Feature scaling brings features to similar ranges so gradient descent converges faster. Mean normalization centers each feature by subtracting its mean, giving features approximately zero mean.",
    "hint": "Consider why having features with very different scales could cause gradient descent to zig-zag."
  },
  {
    "question": "LR: What does the normal equation provide in the context of linear regression?",
    "options": [
      {
        "text": "An iterative approach to find the parameters that minimise the cost function.",
        "image": ""
      },
      {
        "text": "A direct analytical method to compute the parameters (Θ) that minimise the cost function.",
        "image": ""
      },
      {
        "text": "An alternative to gradient descent that is faster regardless of the number of features.",
        "image": ""
      },
      {
        "text": "A way to determine the appropriate learning rate for gradient descent.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The normal equation provides a closed-form solution: θ = (X^T X)^(-1) X^T y, directly computing the optimal parameters without iterative updates like gradient descent.",
    "hint": "Think about the difference between solving an equation analytically versus iteratively."
  },
  {
    "question": "LR: When might the normal equation be computationally inefficient and what might be a workaround?",
    "options": [
      {
        "text": "When the number of training examples is very high, one should use gradient descent instead",
        "image": ""
      },
      {
        "text": "When the number of features is very high, and as a work-around, delete some features or use regularization",
        "image": ""
      },
      {
        "text": "The normal equation is always computationally efficient, irrespective of the number of features",
        "image": ""
      },
      {
        "text": "It is inefficient when there is correlation, therefore it requires an alternative method",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The normal equation requires computing the inverse of (X^T X), which has O(n³) complexity. When the number of features is very high, this matrix inversion becomes computationally expensive and memory-intensive. Regularization (like ridge regression) or feature reduction helps make the matrix invertible and computationally feasible.",
    "hint": "Think about the computational cost of matrix inversion when dimensions are large."
  },
  {
    "question": "LR: According to the sources, what does a Pearson correlation coefficient (r) of -1 signify?",
    "options": [
      {
        "text": "No correlation between the variables",
        "image": ""
      },
      {
        "text": "A moderate positive correlation between the variables",
        "image": ""
      },
      {
        "text": "A maximum negative correlation between the variables",
        "image": ""
      },
      {
        "text": "A maximum positive correlation between the variables",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The Pearson correlation coefficient r ranges from -1 to +1. A value of -1 indicates a perfect negative linear relationship, meaning as one variable increases, the other decreases in a perfectly linear fashion.",
    "hint": "Remember that r = -1 represents the extreme negative end of the correlation scale."
  },
  {
    "question": "LR: What does the coefficient of determination (R²) measure in regression analysis?",
    "options": [
      {
        "text": "The correlation between variables.",
        "image": ""
      },
      {
        "text": "The goodness-of-fit of a line or curve to the data points.",
        "image": ""
      },
      {
        "text": "The slope of the regression line.",
        "image": ""
      },
      {
        "text": "The complexity of the regression model.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "R² represents the proportion of variance in the dependent variable that is explained by the regression model. It indicates how well the regression line or curve fits the observed data points.",
    "hint": "Consider what aspect of 'fit' or 'explanation' R² quantifies in a regression model."
  },
  {
    "question": "LR: What is a key characteristic that distinguishes locally-weighted regression from linear regression?",
    "options": [
      {
        "text": "Locally-weighted regression uses a fixed set of parameters",
        "image": ""
      },
      {
        "text": "Locally-weighted regression parameters grow with the data making it a non-parametric learning algorithm, whilst linear regression uses a fixed set of parameters.",
        "image": ""
      },
      {
        "text": "Locally-weighted regression is faster than linear regression.",
        "image": ""
      },
      {
        "text": "Locally weighted regression uses gradient descent.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Locally-weighted regression (LOESS) is a non-parametric method that retains all training examples and assigns weights to them for each prediction. This means the 'effective' number of parameters grows with the dataset size, unlike linear regression which has a fixed number of parameters.",
    "hint": "Non-parametric methods don't have a fixed set of parameters that are independent of training data size."
  },
  {
    "question": "LR: According to the sources, what is the primary assumption underlying the probabilistic interpretation of least squares?",
    "options": [
      {
        "text": "That the target value y is equal to Θ<sup>T</sup>x plus some random error.",
        "image": ""
      },
      {
        "text": "That the input features are normally distributed.",
        "image": ""
      },
      {
        "text": "That the parameters Θ are fixed and known.",
        "image": ""
      },
      {
        "text": "That the regression line has zero error.",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "The probabilistic interpretation of least squares assumes that the target variable can be expressed as a linear function of the parameters plus random error: y = θ^T x + ε, where ε represents irreducible noise (typically modeled as Gaussian).",
    "hint": "Think about what error term is assumed in the probabilistic model for least squares."
  },
  {
    "question": "LR2: In the context of the normal equation, what does the term 'X' represent?",
    "options": [
      {
        "text": "The vector of predicted values.",
        "image": ""
      },
      {
        "text": "The matrix of target variables.",
        "image": ""
      },
      {
        "text": "The matrix of input features.",
        "image": ""
      },
      {
        "text": "The vector of errors.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In the normal equation θ = (XᵀX)⁻¹Xᵀy, X is the design matrix where each row represents an observation and each column represents a feature. This matrix contains all the input features used to make predictions.",
    "hint": "Consider what matrix gets multiplied by θ to produce the predicted values Xθ."
  },
  {
    "question": "LR2: What does θ represent in the normal equation?",
    "options": [
      {
        "text": "The error term",
        "image": ""
      },
      {
        "text": "The predicted values",
        "image": ""
      },
      {
        "text": "The parameter vector that we aim to find",
        "image": ""
      },
      {
        "text": "The input features",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "θ (theta) is the parameter vector containing the weights for each feature. The normal equation solves for these optimal weights that minimize the cost function.",
    "hint": "Think about what the equation is solving for - it's the unknown we're trying to find."
  },
  {
    "question": "LR2: Given the cost function J(θ) = 1/2 * ||Xθ − y||², which statement correctly describes how the normal equation is derived?",
    "options": [
      {
        "text": "The gradient of J(θ) is set to a non-zero constant to minimise the cost function.",
        "image": ""
      },
      {
        "text": "The cost function is directly minimised by setting its partial derivative to the identity matrix.",
        "image": ""
      },
      {
        "text": "The gradient of J(θ) is set to zero to find the optimal parameter vector.",
        "image": ""
      },
      {
        "text": "The cost function is minimised by setting the second derivative to zero.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "To find the minimum of a function in calculus, we set its derivative (gradient) to zero. For the cost function J(θ), setting ∇J(θ) = 0 gives us the normal equation.",
    "hint": "Remember how you find minima in calculus - it's about setting the derivative to zero."
  },
  {
    "question": "LR2: The normal equation solution θ = (XᵀX)⁻¹Xᵀy can be computed when:",
    "options": [
      {
        "text": "XᵀX is a singular matrix.",
        "image": ""
      },
      {
        "text": "X has more rows than columns",
        "image": ""
      },
      {
        "text": "XᵀX is invertible",
        "image": ""
      },
      {
        "text": "X has linearly dependent columns",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The solution requires computing (XᵀX)⁻¹, the inverse of XᵀX. An inverse only exists for invertible (non-singular) matrices, so XᵀX must be invertible.",
    "hint": "Look at what is being inverted in the normal equation formula."
  },
  {
    "question": "LR2: What is the rank condition for XᵀX to be invertible?",
    "options": [
      {
        "text": "X must have a rank equal to the number of rows.",
        "image": ""
      },
      {
        "text": "X must be a symmetric matrix.",
        "image": ""
      },
      {
        "text": "X must have linearly independent columns which equals the number of features (m).",
        "image": ""
      },
      {
        "text": "X must be a square matrix with a determinant of 1.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "XᵀX is invertible if and only if X has full column rank, meaning all columns are linearly independent. This requires the number of linearly independent columns to equal the number of features (m).",
    "hint": "Consider what condition makes a matrix invertible in terms of its rank."
  },
  {
    "question": "LR2: In the equation for θ, θ = (XᵀX)⁻¹Xᵀy what does the (XᵀX)⁻¹ term represent?",
    "options": [
      {
        "text": "The pseudo-inverse of the feature matrix",
        "image": ""
      },
      {
        "text": "The transpose of the feature matrix",
        "image": ""
      },
      {
        "text": "The inverse of the matrix product X transpose times X.",
        "image": ""
      },
      {
        "text": "The dot product of X with itself.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "(XᵀX)⁻¹ literally represents the mathematical inverse of the matrix product XᵀX. In the normal equation for OLS, this term helps solve the system of normal equations to find optimal weights.",
    "hint": "Remember that the superscript -1 in matrix notation typically denotes the matrix inverse."
  },
  {
    "question": "LR2: If XᵀX is not invertible, what can be inferred about the feature matrix X?",
    "options": [
      {
        "text": "The feature matrix is not real",
        "image": ""
      },
      {
        "text": "The feature matrix contains all zeros",
        "image": ""
      },
      {
        "text": "The feature matrix has linearly dependent columns",
        "image": ""
      },
      {
        "text": "The feature matrix contains no features",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "A matrix is invertible (non-singular) only when its columns are linearly independent. If XᵀX is singular, the original feature matrix X must have linearly dependent (redundant) columns.",
    "hint": "Recall the fundamental condition for matrix invertibility: columns must be linearly independent."
  },
  {
    "question": "LR2: What is a key difference between linear regression and locally weighted regression (LWR)?",
    "options": [
      {
        "text": "Linear regression uses a kernel function, while LWR does not.",
        "image": ""
      },
      {
        "text": "LWR assigns weights to data points based on their proximity to the query point, while linear regression does not.",
        "image": ""
      },
      {
        "text": "Linear regression uses a constant for error calculation while LWR does not.",
        "image": ""
      },
      {
        "text": "LWR computes global parameters, while linear regression computes local parameters.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "LWR is a non-parametric method that fits a separate weighted least squares model for each query point, where weights depend on the distance from that query point. Linear regression fits a single global model with equal weights for all points.",
    "hint": "Think about how LWR treats each prediction differently based on location."
  },
  {
    "question": "LR2: In Locally Weighted Regression (LWR), what is the purpose of the kernel function?",
    "options": [
      {
        "text": "To perform a linear transformation of the input data.",
        "image": ""
      },
      {
        "text": "To reduce the dimensionality of the feature matrix.",
        "image": ""
      },
      {
        "text": "To give higher weights to points closer to the query point and lower weights to points farther away.",
        "image": ""
      },
      {
        "text": "To transform all data into a standard normal distribution.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The kernel function (typically Gaussian) assigns weights w(i) = exp(-||x^(i) - x₀||²/(2τ²)) to each training point based on distance from the query point x₀, giving more influence to nearby points.",
    "hint": "Consider what determines the 'locality' in locally weighted regression."
  },
  {
    "question": "LR2: What does the term 'τ' (tau) represent in the context of the weighting function for Locally Weighted Regression (LWR)?",
    "options": [
      {
        "text": "The weighting parameter",
        "image": ""
      },
      {
        "text": "The inverse of the feature matrix",
        "image": ""
      },
      {
        "text": "The variance of the data",
        "image": ""
      },
      {
        "text": "The bandwidth parameter, controlling the width of the kernel.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "τ (tau) is the bandwidth parameter in the Gaussian kernel that controls how quickly weights decay with distance. Larger τ means a wider kernel (more points influence the local fit), while smaller τ means a narrower kernel.",
    "hint": "Think about what parameter controls the 'width' or 'spread' of a bell curve."
  },
  {
    "question": "LR2: What is an advantage of locally weighted regression compared to standard linear regression?",
    "options": [
      {
        "text": "LWR is always faster to compute than linear regression.",
        "image": ""
      },
      {
        "text": "LWR is not affected by outliers.",
        "image": ""
      },
      {
        "text": "LWR can model non-linear relationships between the input features and the target variable.",
        "image": ""
      },
      {
        "text": "LWR always has a unique solution and no risk of overfitting.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Locally Weighted Regression (LWR) fits a separate weighted least squares at each query point, where points closer to the query have higher weights. This local adaptation allows the model to capture non-linear patterns that a single global linear model cannot represent.",
    "hint": "Consider how LWR adjusts its model locally for each prediction point."
  },
  {
    "question": "LR2: Based on the diagram in the source, which of the following can be described as 'overfitting'?",
    "options": [
      {
        "text": "The model underfits the data.",
        "image": ""
      },
      {
        "text": "The model perfectly fits all data points including the noise in the data.",
        "image": ""
      },
      {
        "text": "The model has very high flexibility and thus it captures the random variations and noise in the training data, not generalising well to unseen data.",
        "image": ""
      },
      {
        "text": "The model gives a completely inaccurate fit to the data.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Overfitting occurs when a model has excessive flexibility, causing it to learn both the true underlying pattern and random noise in the training data, resulting in poor generalization to new data.",
    "hint": "Think about what happens when model complexity exceeds what the data can support."
  },
  {
    "question": "BinaryClass: Given a binary classification scenario, which of the following is the correct interpretation of the notation 'y = 1'?",
    "options": [
      {
        "text": "It represents a negative outcome",
        "image": ""
      },
      {
        "text": "It represents an positive outcome",
        "image": ""
      },
      {
        "text": "It indicates an unknown outcome",
        "image": ""
      },
      {
        "text": "It symbolizes the probability of an event",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In binary classification, the convention is that y=1 represents the positive class (the condition we're detecting), while y=0 represents the negative class.",
    "hint": "Recall the standard convention in binary classification problems."
  },
  {
    "question": "BinaryClass: In the context of logistic regression, what does the notation 'p(y|x; θ)' represent?",
    "options": [
      {
        "text": "The probability of observing feature 'x' given the parameters 'θ'.",
        "image": ""
      },
      {
        "text": "The probability of the parameters 'θ' given the label 'y' and the feature 'x'.",
        "image": ""
      },
      {
        "text": "The probability of label 'y' given feature 'x' and the parameters 'θ' .",
        "image": ""
      },
      {
        "text": "The likelihood of feature 'x' being present",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In probability notation, p(y|x; θ) denotes the conditional probability of y given x, parameterized by θ - this is the fundamental prediction in logistic regression.",
    "hint": "Remember that the vertical bar means 'given' and semicolon means 'parameterized by'."
  },
  {
    "question": "BinaryClass: Based on the notes, what is the primary purpose of the sigmoid function, denoted as 'g(z)'?",
    "options": [
      {
        "text": "To directly predict the class label.",
        "image": ""
      },
      {
        "text": "To map the output of a linear combination of features to a probability between 0 and 1.",
        "image": ""
      },
      {
        "text": "To calculate the error in the classification.",
        "image": ""
      },
      {
        "text": "To optimize the parameters 'θ'",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The sigmoid function g(z) = 1/(1+e^-z) squashes any real-valued input z into the (0,1) range, transforming linear combinations into valid probabilities.",
    "hint": "Consider what type of output logistic regression needs to produce."
  },
  {
    "question": "BinaryClass: According to the notes, how is the decision boundary determined in the context of binary classification using a linear model?",
    "options": [
      {
        "text": "By maximizing the probability p(y|x;θ)",
        "image": ""
      },
      {
        "text": "By setting the sigmoid function g(z) to 0",
        "image": ""
      },
      {
        "text": "By finding the line where g(z) = 0.5 which occurs when θ₀ + θ₁x₁ + θ₂x₂ = 0",
        "image": ""
      },
      {
        "text": "By minimizing the cost function J(θ)",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nella regressione logistica, il decision boundary è definito come il luogo dove la funzione sigmoidale restituisce 0.5, cioè dove z = 0. Questo corrisponde alla linea θ₀ + θ₁x₁ + θ₂x₂ = 0 che separa le due classi.",
    "hint": "Il decision boundary è il punto esatto dove la probabilità di appartenere a una classe è uguale all'altra."
  },
  {
    "question": "BinaryClass: In the provided material, what does the notation 'J(θ)' represent?",
    "options": [
      {
        "text": "The probability of observing the features given the parameters",
        "image": ""
      },
      {
        "text": "The cost function used to evaluate the model's performance",
        "image": ""
      },
      {
        "text": "The gradient of the model's parameters",
        "image": ""
      },
      {
        "text": "The model's prediction",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "J(θ) rappresenta la funzione di costo (cost function) che quantifica l'errore tra le predizioni del modello e i valori reali. Viene utilizzata per valutare quanto bene il modello si adatta ai dati di training.",
    "hint": "È la funzione che viene ottimizzata durante l'addestramento per trovare i migliori parametri."
  },
  {
    "question": "BinaryClass: What is the primary goal of the optimization process with respect to J(θ)?",
    "options": [
      {
        "text": "To maximize J(θ)",
        "image": ""
      },
      {
        "text": "To calculate the Hessian matrix",
        "image": ""
      },
      {
        "text": "To minimize J(θ)",
        "image": ""
      },
      {
        "text": "To find the gradient of J(θ)",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'obiettivo dell'ottimizzazione è minimizzare J(θ) per trovare i parametri θ che producono le predizioni più accurate possibili. Il gradient descent è l'algoritmo comunemente usato per trovare il minimo.",
    "hint": "L'ottimizzazione cerca di ridurre l'errore del modello, non di aumentarlo."
  },
  {
    "question": "BinaryClass: According to the notes, what is the significance of the term 'yi' in the cost function J(θ)?",
    "options": [
      {
        "text": "It represents the predicted label",
        "image": ""
      },
      {
        "text": "It is a feature value",
        "image": ""
      },
      {
        "text": "It is the learning rate",
        "image": ""
      },
      {
        "text": "It represents the true label",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "yi rappresenta l'etichetta vera (true label) dei dati di training, cioè il valore che vogliamo che il modello predica correttamente. È il termine noto nella funzione di costo.",
    "hint": "È il valore che conosciamo già e che il modello deve imparare a predire."
  },
  {
    "question": "BinaryClass: Which of the following best describes the update rule for θ using gradient descent, as per the source?",
    "options": [
      {
        "text": "θ = θ + α∇J(θ)",
        "image": ""
      },
      {
        "text": "θ = θ - α∇J(θ)",
        "image": ""
      },
      {
        "text": "θ = α∇J(θ)",
        "image": ""
      },
      {
        "text": "θ = ∇J(θ)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La regola di aggiornamento del gradient descent sottrae il gradiente moltiplicato per il learning rate α dai parametri attuali: θ = θ - α∇J(θ). Questo sposta i parametri nella direzione di discesa più ripida della funzione di costo.",
    "hint": "Il segno meno indica che ci muoviamo nella direzione opposta al gradiente per raggiungere il minimo."
  },
  {
    "question": "BinaryClass: In the context of the provided notes, what is the purpose of the expression (sigmoid(z(i)) − y(i)) in the gradient calculation?",
    "options": [
      {
        "text": "To calculate the total number of training examples",
        "image": ""
      },
      {
        "text": "To represent the regularization term",
        "image": ""
      },
      {
        "text": "To measure the difference between the predicted probability and the true label",
        "image": ""
      },
      {
        "text": "To compute the Hessian matrix",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "This term represents the error or residual in logistic regression, measuring how far the predicted probability (sigmoid output) deviates from the actual binary label, which drives the gradient descent optimization.",
    "hint": "Think about what this subtraction represents in the context of supervised learning error computation."
  },
  {
    "question": "BinaryClass: According to the provided material, what does the Newton-Raphson method aim to accomplish?",
    "options": [
      {
        "text": "It uses the gradient to reach an optimum.",
        "image": ""
      },
      {
        "text": "It finds the minimum by directly inverting the Hessian",
        "image": ""
      },
      {
        "text": "It is used to find the roots of a function by updating the parameters using the Hessian matrix",
        "image": ""
      },
      {
        "text": "It is used to calculate the gradient of the cost function",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Newton-Raphson is fundamentally a root-finding algorithm that uses both first and second derivatives (gradient and Hessian) to iteratively find where a function equals zero, which in optimization corresponds to finding a stationary point.",
    "hint": "Remember it solves for where f(x)=0, not directly for optimization minimum."
  },
  {
    "question": "BinaryClass: What does the term H in the update equation θ := θ − H⁻¹∇J(θ) refer to (Newton method)?",
    "options": [
      {
        "text": "?",
        "image": ""
      },
      {
        "text": "The gradient of the cost function",
        "image": ""
      },
      {
        "text": "The learning rate",
        "image": ""
      },
      {
        "text": "The Hessian matrix of the cost function",
        "image": ""
      },
      {
        "text": "The sigmoid function",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In the Newton-Raphson formula θ := θ − H⁻¹∇J(θ), H represents the Hessian matrix containing second-order partial derivatives of the cost function, which provides information about curvature.",
    "hint": "Think about what matrix appears in the denominator of the Newton update formula."
  },
  {
    "question": "BinaryClass: What is a key drawback mentioned in the notes regarding the Newton-Raphson method?",
    "options": [
      {
        "text": "It converges very slowly.",
        "image": ""
      },
      {
        "text": "It always finds the global minimum.",
        "image": ""
      },
      {
        "text": "It requires the calculation of the inverse of the Hessian matrix which is expensive to compute",
        "image": ""
      },
      {
        "text": "It only works for linear models.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The main computational limitation of Newton-Raphson is that computing the inverse of the Hessian matrix has O(n³) complexity, making it prohibitively expensive for high-dimensional problems.",
    "hint": "Consider the computational cost of matrix operations, especially inversion."
  },
  {
    "question": "BinaryClass: According to the material, what algorithm is suggested as a practical alternative to Newton's method?",
    "options": [
      {
        "text": "Stochastic gradient descent.",
        "image": ""
      },
      {
        "text": "BFGS (Broyden-Fletcher-Goldfarb-Shanno algorithm)",
        "image": ""
      },
      {
        "text": "Linear Regression.",
        "image": ""
      },
      {
        "text": "The conjugate gradient method.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "BFGS is a quasi-Newton method that approximates the Hessian matrix iteratively without computing it directly, making it computationally more efficient while still achieving fast convergence.",
    "hint": "Think of methods that avoid explicit Hessian computation while retaining quadratic convergence benefits."
  },
  {
    "question": "BinaryClass: What is the relationship between the gradient and the direction of steepest ascent of a function J(θ)?",
    "options": [
      {
        "text": "The gradient points in the direction of the steepest decrease",
        "image": ""
      },
      {
        "text": "The gradient points in the direction of the steepest increase",
        "image": ""
      },
      {
        "text": "The gradient is orthogonal to the direction of the steepest ascent",
        "image": ""
      },
      {
        "text": "The gradient provides no information about the direction of the steepest ascent",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The gradient points in the direction of steepest ascent because it gives the direction of maximum positive rate of change of the function. This is a fundamental property from multivariate calculus.",
    "hint": "Remember that gradient points in the direction of greatest increase, while negative gradient points to greatest decrease."
  },
  {
    "question": "BinaryClass2: According to the source, what does \"Log Loss\" or \"Negative Log Likelihood\" (NLL) measure in the context of classification?",
    "options": [
      {
        "text": "The accuracy of the model’s predictions",
        "image": ""
      },
      {
        "text": "The sum of squared errors.",
        "image": ""
      },
      {
        "text": "The difference between predicted probabilities and true labels",
        "image": ""
      },
      {
        "text": "The margin of separation between classes.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Log Loss measures the discrepancy between the predicted class probabilities and the true one-hot encoded labels. It penalizes confident wrong predictions more heavily.",
    "hint": "Think about what happens when a model predicts high probability for the wrong class."
  },
  {
    "question": "BinaryClass2: What does the term 'logits' refer to in the document?",
    "options": [
      {
        "text": "The output of the Softmax function.",
        "image": ""
      },
      {
        "text": "The predicted probabilities of each class",
        "image": ""
      },
      {
        "text": "The raw, unnormalized scores that are input to the Softmax",
        "image": ""
      },
      {
        "text": "The loss calculated during backpropagation.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Logits are the raw output values from the neural network before any normalization is applied. They represent the unnormalized scores that get fed into the softmax function.",
    "hint": "What comes before the probabilities are calculated in a classification network?"
  },
  {
    "question": "BinaryClass2: According to the source, what is the effect of the exponential function within Softmax?",
    "options": [
      {
        "text": "To normalize values between 0 and 1.",
        "image": ""
      },
      {
        "text": "To produce a weighted average of the inputs.",
        "image": ""
      },
      {
        "text": "To ensure that all scores are positive",
        "image": ""
      },
      {
        "text": "To amplify the differences between the raw scores",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "The exponential function in softmax amplifies differences because exp(x) grows rapidly - larger input scores get disproportionately larger exponentials, making the resulting probabilities more distinct.",
    "hint": "Consider how the exponential function transforms numerical values and what happens to large vs small inputs."
  },
  {
    "question": "BinaryClass2: In the context of the provided document, what is the significance of the term \"cross-entropy\"?",
    "options": [
      {
        "text": "It measures the complexity of the model.",
        "image": ""
      },
      {
        "text": "It measures the average number of bits needed to encode data.",
        "image": ""
      },
      {
        "text": "It measures the difference between probability distributions",
        "image": ""
      },
      {
        "text": "It quantifies the uncertainty of predictions for multiple classes",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Cross-entropy quantifies the uncertainty or 'surprise' in predictions when comparing predicted probability distributions to true distributions. It's particularly useful for multi-class classification problems.",
    "hint": "Think about what cross-entropy measures in terms of information theory and probability distributions."
  },
  {
    "question": "BinaryClass2: What does the diagram with the red, green and blue points with decision boundaries represent?",
    "options": [
      {
        "text": "The training of a linear regression model.",
        "image": ""
      },
      {
        "text": "The concept of bias, variance and underfitting and overfitting.",
        "image": ""
      },
      {
        "text": "The function of gradient descent",
        "image": ""
      },
      {
        "text": "A graphical representation of the Softmax function",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "This diagram illustrates the bias-variance tradeoff, showing three scenarios: underfitting (high bias, low variance), good fit, and overfitting (low bias, high variance) with decision boundaries.",
    "hint": "Consider what concepts are typically demonstrated with visual representations of different model fits to the same data."
  },
  {
    "question": "BinaryClass2: Based on the document, what is the effect of \"overfitting\" on the model?",
    "options": [
      {
        "text": "The model generalizes well to new, unseen data.",
        "image": ""
      },
      {
        "text": "The model memorizes the training data instead of learning the underlying patterns",
        "image": ""
      },
      {
        "text": "The model is too simple to capture the complexity of the data.",
        "image": ""
      },
      {
        "text": "The model has a high bias.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Overfitting happens when a model becomes too complex and learns the noise/specific details of training data rather than generalizable patterns, failing to generalize to new data.",
    "hint": "Think about what happens when a model is overly complex relative to the amount and complexity of the training data."
  },
  {
    "question": "BinaryClass2: What does 'bias' in the context of model training refer to in the document?",
    "options": [
      {
        "text": "The model's tendency to consistently make incorrect assumptions",
        "image": ""
      },
      {
        "text": "The variability in the model’s predictions.",
        "image": ""
      },
      {
        "text": "The amount of training data used.",
        "image": ""
      },
      {
        "text": "The complexity of the model architecture.",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Bias in model training refers to systematic errors caused by incorrect assumptions in the model - a high-bias model oversimplifies and consistently misses patterns in the data.",
    "hint": "Consider what type of error results from a model that is too simple to capture the true relationship in data."
  },
  {
    "question": "BinaryClass2: According to the document, what does 'variance' in the context of model training refer to?",
    "options": [
      {
        "text": "The model's ability to make consistent predictions.",
        "image": ""
      },
      {
        "text": "The model’s sensitivity to changes in the training data.",
        "image": ""
      },
      {
        "text": "The model's tendency to make consistent errors.",
        "image": ""
      },
      {
        "text": "The bias in the model's assumptions.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Variance measures how much a model's predictions fluctuate with different training data - high variance means small changes in training data lead to large changes in predictions.",
    "hint": "Think about what happens to predictions when you train the same model on different subsets of data."
  },
  {
    "question": "BinaryClass2: What does the source suggest about the relationship between model complexity and bias and variance?",
    "options": [
      {
        "text": "Increasing model complexity always reduces bias and variance.",
        "image": ""
      },
      {
        "text": "Increasing model complexity may reduce bias but increase variance.",
        "image": ""
      },
      {
        "text": "Decreasing model complexity always reduces both bias and variance.",
        "image": ""
      },
      {
        "text": "Bias and variance are not affected by the model complexity.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "This describes the bias-variance tradeoff: more complex models can reduce bias (better fit) but tend to have higher variance (less stable across different datasets).",
    "hint": "Recall the fundamental tradeoff: as you reduce one error type, the other typically increases."
  },
  {
    "question": "BinaryClass2: What do the dashed lines in the model representation diagrams indicate?",
    "options": [
      {
        "text": "Hyperplanes that separate the classes.",
        "image": ""
      },
      {
        "text": "The decision boundaries of an overfitted model.",
        "image": ""
      },
      {
        "text": "The margin of separation between classes.",
        "image": ""
      },
      {
        "text": "Areas of underfitting.",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "In binary classification diagrams (like SVMs), dashed lines represent the hyperplanes that divide the feature space into regions corresponding to different classes. This is the standard way to visualize decision boundaries.",
    "hint": "Think about what physically separates the different class regions in a classification diagram."
  },
  {
    "question": "BinaryClass2: What does the concept of 'Expected Error' (E(Err)) in the context of the document represent?",
    "options": [
      {
        "text": "The bias of the model.",
        "image": ""
      },
      {
        "text": "The variance of the model.",
        "image": ""
      },
      {
        "text": "The sum of Bias and Variance.",
        "image": ""
      },
      {
        "text": "The irreducible error of the data.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Expected error in the bias-variance decomposition framework represents the combination of bias and variance components. The total expected prediction error is decomposed into these two main components plus irreducible error.",
    "hint": "Recall the bias-variance tradeoff decomposition formula and what terms it contains."
  },
  {
    "question": "BiasVariance: In the context of bias-variance tradeoff, what does \"high variance\" typically indicate about a machine learning model?",
    "options": [
      {
        "text": "The model is too simple and underfits the training data.",
        "image": ""
      },
      {
        "text": "The model is too complex and overfits the training data.",
        "image": ""
      },
      {
        "text": "The model has a strong bias towards a specific class.",
        "image": ""
      },
      {
        "text": "The model has low statistical efficiency.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "High variance means the model is too complex and has essentially memorized the training data, capturing noise rather than true patterns. This leads to overfitting where performance varies greatly with different training sets.",
    "hint": "Consider what happens when a model learns too many details from training data instead of general patterns."
  },
  {
    "question": "BiasVariance: What is the primary purpose of regularization in machine learning?",
    "options": [
      {
        "text": "To increase the model's complexity and reduce bias.",
        "image": ""
      },
      {
        "text": "To reduce the model's complexity and prevent overfitting.",
        "image": ""
      },
      {
        "text": "To improve the model's performance on the training data.",
        "image": ""
      },
      {
        "text": "To increase the model's variance.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Regularization adds a penalty term (like L1 or L2) to the loss function that constrains model parameters, effectively reducing model complexity and preventing the model from fitting too closely to training data.",
    "hint": "Think about what constraints are imposed to prevent models from becoming too flexible."
  },
  {
    "question": "BiasVariance: Why is choosing hyperparameters based solely on the training data considered a bad practice?",
    "options": [
      {
        "text": "It can lead to a decrease in the model's variance.",
        "image": ""
      },
      {
        "text": "It does not provide information about how the algorithm will perform on new, unseen data.",
        "image": ""
      },
      {
        "text": "It will always choose the least complex model.",
        "image": ""
      },
      {
        "text": "It would always lead to choosing the most complex model.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Training data performance does not indicate how the model will generalize to new, unseen data. Hyperparameters must be validated on held-out data to ensure the model will perform well on future observations.",
    "hint": "Consider what the fundamental goal of machine learning is regarding new, unseen data."
  },
  {
    "question": "BiasVariance: What is the primary advantage of using k-fold cross-validation, compared to a single hold-out validation set?",
    "options": [
      {
        "text": "It is less computationally expensive.",
        "image": ""
      },
      {
        "text": "It is better suited for large datasets.",
        "image": ""
      },
      {
        "text": "It makes better use of small datasets.",
        "image": ""
      },
      {
        "text": "It always chooses the most complex model.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "K-fold cross-validation splits data into k subsets and trains/kwtests the model k times, using each subset as validation once. This maximizes the use of limited data since all observations contribute to both training and validation across folds.",
    "hint": "Consider how k-fold differs from a single split in terms of data utilization across all folds."
  },
  {
    "question": "BiasVariance: According to the sources, which of the following represents the correct sequence of steps when using a hold-out cross validation method?",
    "options": [
      {
        "text": "Train each model on Sdev, choose the model with lowest error on Strain, optionally evaluate on Stest.",
        "image": ""
      },
      {
        "text": "Split S into Strain, Sdev and Stest, train each model on Strain, choose model with lowest error on Sdev, optionally evaluate on Stest.",
        "image": ""
      },
      {
        "text": "Choose hyperparameters that work best on the test data.",
        "image": ""
      },
      {
        "text": "Split the data into train and test, and choose hyperparameters on the test data.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The proper sequence is: split data into train/dev/test sets, train models on training set only, select the best model using development set error, and optionally evaluate final performance on the held-out test set.",
    "hint": "Remember that model selection should never use the test set - it's only for final evaluation."
  },
  {
    "question": "BiasVariance: What does the term \"empirical risk\" refer to in the context of machine learning?",
    "options": [
      {
        "text": "The risk associated with the variance of a model.",
        "image": ""
      },
      {
        "text": "The risk associated with the bias of a model.",
        "image": ""
      },
      {
        "text": "The error of the model on the training data.",
        "image": ""
      },
      {
        "text": "The generalization performance of the model on new, unseen data.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Empirical risk is the average loss computed on the training data, representing the model's performance on observed examples rather than theoretical expected performance on unseen data.",
    "hint": "The word 'empirical' refers to what can be observed/measured from actual data."
  },
  {
    "question": "BiasVariance: According to the sources, what is the relationship between model complexity and error?",
    "options": [
      {
        "text": "As model complexity increases, error always decreases.",
        "image": ""
      },
      {
        "text": "As model complexity decreases, error always decreases.",
        "image": ""
      },
      {
        "text": "There is an optimal level of model complexity that results in the lowest error, typically, increasing complexity will initially decrease error and then will increase it.",
        "image": ""
      },
      {
        "text": "Model complexity does not affect error.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "This describes the bias-variance tradeoff: underfitting occurs with too-simple models (high bias), overfitting with too-complex models (high variance), and optimal complexity minimizes total error.",
    "hint": "Think about what happens to training and validation error as you move from very simple to very complex models."
  },
  {
    "question": "PCA: What is a manifold in the context of PCA?",
    "options": [
      {
        "text": "A high-dimensional space where data points are randomly scattered.",
        "image": ""
      },
      {
        "text": "A topological space that locally resembles Euclidean space, where data may reside.",
        "image": ""
      },
      {
        "text": "A set of basis vectors used for representing data points.",
        "image": ""
      },
      {
        "text": "A non-linear transformation applied to the data.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In dimensionality reduction, a manifold is a lower-dimensional structure embedded in higher-dimensional space that locally behaves like Euclidean space, which PCA aims to discover and project data onto.",
    "hint": "Think about the mathematical property of being locally similar to Euclidean space."
  },
  {
    "question": "PCA: What is a 'chart' in the context of manifolds?",
    "options": [
      {
        "text": "A visual representation of data in a scatter plot.",
        "image": ""
      },
      {
        "text": "A function that provides a one-to-one correspondence between open regions of a surface and subsets of Euclidean space.",
        "image": ""
      },
      {
        "text": "A method for reducing the dimensionality of the data.",
        "image": ""
      },
      {
        "text": "A way to visualize the principal components of a dataset.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In differential geometry, a chart is a local coordinate system that maps an open subset of a manifold to a subset of Euclidean space, establishing a one-to-one correspondence essential for defining differentiable structures.",
    "hint": "Think about how coordinates work on curved surfaces like a sphere."
  },
  {
    "question": "PCA: What is the key property of a chart mapping (ϕ)?",
    "options": [
      {
        "text": "It must be non-invertible.",
        "image": ""
      },
      {
        "text": "It must be discontinuous.",
        "image": ""
      },
      {
        "text": "It must be smooth and invertible (a diffeomorphism).",
        "image": ""
      },
      {
        "text": "It can be any arbitrary mapping.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "For a chart to define a smooth structure on a manifold, the mapping must be a diffeomorphism—smooth, continuous, and invertible with a smooth inverse.",
    "hint": "Consider what mathematical properties ensure we can do calculus on curved spaces."
  },
  {
    "question": "PCA: In the context of unsupervised learning, what is the primary goal?",
    "options": [
      {
        "text": "To predict labels for input data.",
        "image": ""
      },
      {
        "text": "To uncover meaningful structures or representations within the data.",
        "image": ""
      },
      {
        "text": "To train a model with labeled outputs.",
        "image": ""
      },
      {
        "text": "To use a supervised learning approach.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Unsupervised learning aims to discover hidden patterns, clusters, or structures in data without any labeled responses, unlike supervised learning which uses known outputs.",
    "hint": "Think about what distinguishes learning 'without answers' from learning 'with answers'."
  },
  {
    "question": "PCA: What is a basis in the context of vector spaces?",
    "options": [
      {
        "text": "A set of random vectors used for representing points.",
        "image": ""
      },
      {
        "text": "A set of linearly independent vectors that can be used to reconstruct any point in the space.",
        "image": ""
      },
      {
        "text": "A single vector that captures the variance of the data.",
        "image": ""
      },
      {
        "text": "A set of vectors that overlap and point in similar directions.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "A basis is the minimal set of linearly independent vectors that spans the entire vector space, allowing any vector to be expressed as a unique linear combination.",
    "hint": "Consider what makes a set of vectors sufficient to represent all points in a space."
  },
  {
    "question": "PCA: What is the implication of mean-centering a dataset before applying PCA?",
    "options": [
      {
        "text": "It increases the variance of the data.",
        "image": ""
      },
      {
        "text": "It shifts the data away from the origin.",
        "image": ""
      },
      {
        "text": "It ensures the data is centered at the origin, simplifying calculations.",
        "image": ""
      },
      {
        "text": "It makes the data more noisy.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Mean-centering shifts the data so that the mean of each variable becomes zero, placing the data cloud at the origin and simplifying covariance computations in PCA.",
    "hint": "Think about what happens to the covariance matrix when data is centered at the origin."
  },
  {
    "question": "PCA: Why must basis vectors be linearly independent?",
    "options": [
      {
        "text": "To make computations easier.",
        "image": ""
      },
      {
        "text": "To ensure the basis vectors point in similar directions.",
        "image": ""
      },
      {
        "text": "To ensure they span the entire space and can reconstruct any point in the space without overlap or redundancy.",
        "image": ""
      },
      {
        "text": "Linear dependence is required in PCA.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Linear independence ensures the basis vectors span the entire space without redundancy, allowing unique reconstruction of any point. If dependent, some vectors would contribute no new directional information.",
    "hint": "Think about what redundant vectors would mean for the dimensionality of the span."
  },
  {
    "question": "PCA: In a standard basis, what is unique about the weights when representing a data point?",
    "options": [
      {
        "text": "The weights must be numerically solved for.",
        "image": ""
      },
      {
        "text": "The weights are zero for every dimension.",
        "image": ""
      },
      {
        "text": "The weights are simply the values of the data point itself.",
        "image": ""
      },
      {
        "text": "They require complex mathematical functions for computation.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In a standard basis, the basis vectors are simply the coordinate axes (e.g., [1,0,0], [0,1,0]), so the weights needed to reconstruct a point are exactly the point's coordinate values themselves.",
    "hint": "What are the vectors in a standard/identity basis?"
  },
  {
    "question": "PCA: What is the significance of an orthonormal basis in the context of PCA?",
    "options": [
      {
        "text": "It requires more complex calculations to find the weights.",
        "image": ""
      },
      {
        "text": "It makes the representation of a point more complicated.",
        "image": ""
      },
      {
        "text": "It simplifies the calculation of the weight vector; it can be expressed directly in terms of the spanning set and the data itself.",
        "image": ""
      },
      {
        "text": "It provides a non-unique basis for representing the data.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "An orthonormal basis (vectors orthogonal with unit length) allows direct computation of weights via dot product: w = U^T x. No matrix inversion or equation solving required.",
    "hint": "What does orthonormal imply about the relationship between basis vectors?"
  },
  {
    "question": "PCA: What is the role of the operation CC^T (where C is the basis matrix) in the context of an orthonormal basis?",
    "options": [
      {
        "text": "It is a non-linear transformation.",
        "image": ""
      },
      {
        "text": "It scales the data.",
        "image": ""
      },
      {
        "text": "It acts as a projection matrix, ensuring data is represented by the orthonormal basis.",
        "image": ""
      },
      {
        "text": "It adds noise to the data.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "CC^T is a projection matrix that projects data onto the subspace spanned by C. For orthonormal C, this matrix is idempotent (P^2 = P) and represents the reconstruction in the new basis.",
    "hint": "What happens when you project data onto a subspace and then project again?"
  },
  {
    "question": "PCA: What happens when the number of spanning vectors (K) is less than the dimensionality of the data space (D)?",
    "options": [
      {
        "text": "All points can still be perfectly represented.",
        "image": ""
      },
      {
        "text": "The data becomes more accurate.",
        "image": ""
      },
      {
        "text": "Points can only be approximated but not perfectly represented in the subspace.",
        "image": ""
      },
      {
        "text": "The spanning vectors become linearly dependent.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "When K < D, the K-dimensional subspace cannot capture all D-dimensional information. Data points can only be approximated (lossy compression), not perfectly reconstructed.",
    "hint": "What information is lost when you reduce dimensionality?"
  },
  {
    "question": "PCA: What does the projection of a data point onto a subspace represent?",
    "options": [
      {
        "text": "A random transformation of the original data point.",
        "image": ""
      },
      {
        "text": "The 'dropping' of the data point perpendicularly onto the subspace defined by the basis vectors.",
        "image": ""
      },
      {
        "text": "A transformation that moves the data point away from the subspace.",
        "image": ""
      },
      {
        "text": "An increase in the dimensionality of the data.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In PCA, projection onto a subspace means finding the closest point in that subspace to the original data point, which geometrically corresponds to dropping the point perpendicularly onto the subspace defined by the principal component basis vectors.",
    "hint": "Think about the geometric meaning of 'projection' in linear algebra and orthogonal decomposition."
  },
  {
    "question": "PCA: What is learned in Principal Component Analysis (PCA) besides weights?",
    "options": [
      {
        "text": "Only the weights are learned.",
        "image": ""
      },
      {
        "text": "An appropriate basis (principal components) is also learned alongside the weights.",
        "image": ""
      },
      {
        "text": "Non-linear transformations of the input data.",
        "image": ""
      },
      {
        "text": "The eigenvalues of the data matrix are minimized.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "PCA learns both the weights (how to represent each data point in the new basis) and the principal components themselves (the orthonormal basis vectors pointing in the directions of maximum variance).",
    "hint": "Remember that PCA optimizes the transformation matrix to find meaningful directions."
  },
  {
    "question": "PCA: What is the relationship between the PCA least squares cost function and the autoencoder?",
    "options": [
      {
        "text": "They are unrelated mathematical concepts.",
        "image": ""
      },
      {
        "text": "The simplified PCA least squares cost function under orthogonality constraint is known as the autoencoder.",
        "image": ""
      },
      {
        "text": "The autoencoder is only used for supervised learning.",
        "image": ""
      },
      {
        "text": "The cost function is always minimized by using non-orthogonal matrices.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "A linear autoencoder with orthogonality constraints on its weights minimizes the same reconstruction error as PCA's least squares cost function, making them mathematically equivalent for linear dimensionality reduction.",
    "hint": "Consider what happens when you constrain a neural network to perform linear dimensionality reduction."
  },
  {
    "question": "PCA: What are principal components?",
    "options": [
      {
        "text": "Randomly chosen vectors that span the data space.",
        "image": ""
      },
      {
        "text": "The elements of the orthonormal basis that point in the directions of the greatest variance in the dataset.",
        "image": ""
      },
      {
        "text": "The weight vectors used to represent each point.",
        "image": ""
      },
      {
        "text": "The eigenvalues of the data covariance matrix.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Principal components are the eigenvectors of the data's covariance matrix that correspond to the largest eigenvalues, forming an orthonormal basis that points in the directions where the data varies the most.",
    "hint": "They are derived from the eigenvalue decomposition of the covariance matrix."
  },
  {
    "question": "PCA: How are principal components computed?",
    "options": [
      {
        "text": "By random selection from the dataset.",
        "image": ""
      },
      {
        "text": "As the eigenvectors of the data's correlation matrix (or covariance matrix).",
        "image": ""
      },
      {
        "text": "By a complex non-linear optimization process.",
        "image": ""
      },
      {
        "text": "Using only the standard basis.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Principal components are computed by performing eigenvalue decomposition (or singular value decomposition) on the data's covariance or correlation matrix; the eigenvectors represent the principal component directions.",
    "hint": "Think about what mathematical operation gives you the directions of maximum variance."
  },
  {
    "question": "Clustering: In the context of decision trees, what is the primary purpose of a 'splitting variable'?",
    "options": [
      {
        "text": "To randomly select a subset of the data to be classified.",
        "image": ""
      },
      {
        "text": "To reduce the number of neighbours in the k-NN algorithm",
        "image": ""
      },
      {
        "text": "To divide the feature space into mutually exclusive regions",
        "image": ""
      },
      {
        "text": "To assign weights to all the samples according to their importance.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In un albero decisionale, lo splitting variable è la variabile utilizzata per suddividere lo spazio delle feature in regioni reciprocamente esclusive. Questo processo di partizione ricorsiva è il meccanismo fondamentale che consente all'albero di creare regioni omogenee rispetto alla variabile target.",
    "hint": "Pensa a come un albero decisionale suddivide lo spazio delle feature in regioni sempre più piccole e omogenee."
  },
  {
    "question": "Clustering: What is the role of the 'misclassification rate' in the context of building a decision tree?",
    "options": [
      {
        "text": "It helps to reduce the data dimensionality.",
        "image": ""
      },
      {
        "text": "It determines the appropriate number of nearest neighbors in a k-NN.",
        "image": ""
      },
      {
        "text": "It quantifies the performance of a given split",
        "image": ""
      },
      {
        "text": "It evaluates the overall performance of the trained model",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il misclassification rate misura la proporzione di osservazioni classificate erroneamente in un dato nodo. Questo criterio viene utilizzato per valutare la qualità di uno split候选 e selezionare la variabile che massimizza la purezza dei nodi figli.",
    "hint": "Ricorda che gli alberi decisionali scelgono gli split ottimizzando un criterio di purezza o errore."
  },
  {
    "question": "Clustering: What is the primary distinction between 'Tree-based methods' and 'Linear regression models' as described in the text?",
    "options": [
      {
        "text": "Tree-based methods use Euclidean distance, while linear regression does not.",
        "image": ""
      },
      {
        "text": "Linear regression models are more robust to outliers.",
        "image": ""
      },
      {
        "text": "Tree-based methods partition the input space into rectangles whilst linear regression creates a single partitioning",
        "image": ""
      },
      {
        "text": "Linear regression models are more computationally efficient.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "I metodi tree-based creano partizioni discrete dello spazio di input in regioni rettangolari (box), mentre la regressione lineare produce una singola superficie di regressione globale. Quest'ultima utilizza una combinazione lineare delle variabili per predire l'output.",
    "hint": "Confronta come le due metodologie approcciano la relazione tra variabili indipendenti e dipendenti."
  },
  {
    "question": "Clustering: In the context of bagging, what is 'bootstrapping'?",
    "options": [
      {
        "text": "The random division of the data into training and test sets.",
        "image": ""
      },
      {
        "text": "The technique used to visualize the decision boundaries in tree-based methods",
        "image": ""
      },
      {
        "text": "A method of randomly sampling with replacement from the original dataset",
        "image": ""
      },
      {
        "text": "A process of feature selection that reduces the complexity of the model.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il bootstrapping è una tecnica di campionamento che estrae casualmente osservazioni dal dataset originale con replacement, permettendo che alcune osservazioni appaiano più volte. Questo processo genera dataset diversi per addestrare ciascun modello nella procedura di bagging.",
    "hint": "È una tecnica di campionamento che permette di riutilizzare le stesse osservazioni più volte."
  },
  {
    "question": "Clustering: How does 'random forest' method build individual trees that are less correlated?",
    "options": [
      {
        "text": "By using only a subset of the input samples for the training.",
        "image": ""
      },
      {
        "text": "By pruning the trees to reduce their complexity.",
        "image": ""
      },
      {
        "text": "By randomly choosing a subset of the features at each split",
        "image": ""
      },
      {
        "text": "By weighting the importance of the features.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In random forest, ad ogni split l'albero può utilizzare solo un sottoinsieme casuale delle feature disponibili (feature bagging). Questa随机izzazione riduce la correlazione tra gli alberi poiché impedisce alle feature più dominanti di apparire sempre alla radice.",
    "hint": "È una forma di bagging applicata alle feature invece che ai campioni."
  },
  {
    "question": "Clustering: What is the fundamental idea behind 'Boosting' as described in the text?",
    "options": [
      {
        "text": "To average the predictions of multiple decision trees.",
        "image": ""
      },
      {
        "text": "To make every tree independent from other trees.",
        "image": ""
      },
      {
        "text": "To build an ensemble of models, where each model corrects the errors of its predecessor",
        "image": ""
      },
      {
        "text": "To select the best performing features among all available ones.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Boosting creates a sequential ensemble where each new model (weak learner) focuses on correcting the mistakes made by the previous models, combining them into a strong predictor.",
    "hint": "Think about how each subsequent model improves upon previous errors."
  },
  {
    "question": "Clustering: In the context of boosting, how are the weights of the training samples adjusted after each boosting step?",
    "options": [
      {
        "text": "Weights are assigned to the samples based on their Euclidean distance from the decision boundary.",
        "image": ""
      },
      {
        "text": "The weights are randomly re-distributed to ensure variety in the training data.",
        "image": ""
      },
      {
        "text": "Weights are adjusted to increase the importance of misclassified samples",
        "image": ""
      },
      {
        "text": "The weights of the training samples remain unchanged throughout the boosting process.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In boosting, after each iteration, samples that were misclassified receive higher weights so that subsequent learners focus more on these difficult cases.",
    "hint": "Consider what the next weak learner needs to learn from the previous one's mistakes."
  },
  {
    "question": "Clustering: What is the objective function that is being optimized when fitting a single tree in a boosting model?",
    "options": [
      {
        "text": "The misclassification rate.",
        "image": ""
      },
      {
        "text": "A sum of weights of the misclassified examples",
        "image": ""
      },
      {
        "text": "The entropy",
        "image": ""
      },
      {
        "text": "The variance of the labels.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Each tree in boosting is trained to minimize the weighted misclassification error, where the weights come from the previous boosting iterations.",
    "hint": "Recall that boosting assigns importance weights to training samples."
  },
  {
    "question": "Clustering: In the context of gradient boosting, what does the ‘gradient’ refer to?",
    "options": [
      {
        "text": "The direction of maximum increase of the loss function",
        "image": ""
      },
      {
        "text": "The set of all training samples.",
        "image": ""
      },
      {
        "text": "The change in the feature space",
        "image": ""
      },
      {
        "text": "The number of nodes in the decision tree.",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Gradient boosting uses gradient descent to minimize the loss function; each new tree fits the negative gradient (residuals) of the loss.",
    "hint": "Think about how gradient descent moves in the direction of steepest ascent."
  },
  {
    "question": "Clustering: Which of the following best describes the core idea behind the k-Nearest Neighbour (k-NN) algorithm as presented in the source?",
    "options": [
      {
        "text": "It partitions the feature space into rectangles.",
        "image": ""
      },
      {
        "text": "It determines class membership by identifying the k-nearest data points to a given instance.",
        "image": ""
      },
      {
        "text": "It applies boosting techniques to improve accuracy.",
        "image": ""
      },
      {
        "text": "It uses a linear combination of basis functions.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "k-NN is an instance-based learning method that classifies a new point by majority vote of its k closest neighbors in the feature space.",
    "hint": "Consider what 'nearest' means in the context of feature similarity."
  },
  {
    "question": "Clustering: In the context of tree-based methods, which of the following is NOT a typical criterion for splitting nodes?",
    "options": [
      {
        "text": "Maximizing information gain.",
        "image": ""
      },
      {
        "text": "Minimising impurity.",
        "image": ""
      },
      {
        "text": "Maximising the number of features.",
        "image": ""
      },
      {
        "text": "Minimizing the weighted average impurity of child nodes",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In tree-based methods like decision trees, splits are determined by impurity measures (Gini, entropy) to maximize information gain or minimize node impurity. The number of features used is a hyperparameter setting, not a splitting criterion.",
    "hint": "Think about what makes a 'good' split in a decision tree - it's about node purity, not feature count."
  },
  {
    "question": "Clustering: What is the purpose of the 'margin' in the context of support vector machines as described in the source?",
    "options": [
      {
        "text": "To ensure each data point is correctly classified.",
        "image": ""
      },
      {
        "text": "To find a decision boundary that minimizes the number of misclassifications.",
        "image": ""
      },
      {
        "text": "To minimize the computational complexity.",
        "image": ""
      },
      {
        "text": "To maximize the separation between classes.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "In SVM, the margin is the distance between the decision boundary (hyperplane) and the closest data points (support vectors). The algorithm maximizes this margin to achieve better generalization.",
    "hint": "Remember that 'support vectors' are the points that 'support' or define the margin."
  },
  {
    "question": "Clustering: The source mentions that the decision rule for k-NN is updated based on which aspect of the k neighbours?",
    "options": [
      {
        "text": "Their distances to the decision boundary.",
        "image": ""
      },
      {
        "text": "Their feature values.",
        "image": ""
      },
      {
        "text": "Their class labels.",
        "image": ""
      },
      {
        "text": "Their position in feature space.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "k-NN uses majority voting among the k nearest neighbors, where each neighbor contributes its class label to determine the prediction for the query point.",
    "hint": "k-NN is based on 'voting' - think about what the neighbors are voting for."
  },
  {
    "question": "Clustering: What is the primary focus of 'Boosting' algorithms, according to the source?",
    "options": [
      {
        "text": "To independently fit many decision trees.",
        "image": ""
      },
      {
        "text": "To iteratively fit weak learners while focusing on misclassified instances from previous iterations.",
        "image": ""
      },
      {
        "text": "To linearly separate data into different classes.",
        "image": ""
      },
      {
        "text": "To find the optimal decision boundary using a kernel trick.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Boosting works by sequentially training weak learners, where each subsequent learner gives more weight to instances misclassified by previous learners, building an ensemble that corrects errors.",
    "hint": "The key word is 'iteratively' - boosting builds on the mistakes of previous models."
  },
  {
    "question": "Clustering: In the context of boosting, what is meant by “reweighting” training data?",
    "options": [
      {
        "text": "It’s where the values of features are adjusted.",
        "image": ""
      },
      {
        "text": "It is the process of re-assigning training samples to different classes.",
        "image": ""
      },
      {
        "text": "It’s adjusting the weights of the linear function.",
        "image": ""
      },
      {
        "text": "It means increasing the weight of instances that are harder to classify.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "In boosting algorithms like AdaBoost, training instances that are misclassified receive higher weights in the next iteration, so subsequent weak learners focus more on difficult-to-classify examples.",
    "hint": "Think about what gets 'boosted' - it's the attention paid to harder cases."
  },
  {
    "question": "Clustering: According to the source, what is a 'weak learner' in the context of boosting algorithms?",
    "options": [
      {
        "text": "A model that achieves very low training error.",
        "image": ""
      },
      {
        "text": "A model that performs slightly better than random guessing.",
        "image": ""
      },
      {
        "text": "A complex model with high capacity.",
        "image": ""
      },
      {
        "text": "A model that is prone to overfitting.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In boosting, a weak learner (or weak classifier) is defined as a model whose performance is only slightly better than random guessing - typically with accuracy just above 50% for binary classification. The boosting algorithm then combines many such weak learners to form a strong ensemble.",
    "hint": "Think about what 'weak' means in terms of performance relative to random chance, not model complexity."
  },
  {
    "question": "Clustering: What is the main objective of the 'objective function' mentioned in the section about boosting?",
    "options": [
      {
        "text": "To minimise the number of training samples.",
        "image": ""
      },
      {
        "text": "To maximize the margin between classes.",
        "image": ""
      },
      {
        "text": "To minimise the empirical risk (loss) based on the training data.",
        "image": ""
      },
      {
        "text": "To maximize the number of iterations.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The objective function in boosting algorithms is designed to minimize the empirical risk, which measures the average loss (error) on the training data. This is the fundamental principle of empirical risk minimization (ERM).",
    "hint": "The objective function typically quantifies how well the model fits the training data through a loss measure."
  },
  {
    "question": "Clustering: According to the source, what is the rationale behind 'regularization' when building the objective function in boosting?",
    "options": [
      {
        "text": "To speed up training time.",
        "image": ""
      },
      {
        "text": "To simplify the data.",
        "image": ""
      },
      {
        "text": "To avoid overfitting.",
        "image": ""
      },
      {
        "text": "To convert linear to non-linear problems.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Regularization in boosting adds penalty terms to the objective function to constrain model complexity and prevent overfitting. This helps the model generalize better to unseen data rather than just memorizing training examples.",
    "hint": "Consider what happens when models become too complex relative to the amount of available training data."
  },
  {
    "question": "An image is defined as:",
    "options": [
      {
        "text": "A collection of coloured dots.",
        "image": ""
      },
      {
        "text": "A two-dimensional array of numerical values.",
        "image": ""
      },
      {
        "text": "A function that maps locations to pixels.",
        "image": ""
      },
      {
        "text": "A visual representation of objects.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Mathematically, an image is defined as a two-dimensional function f(x, y) that maps each spatial location (coordinates) to a pixel value representing intensity or color. This functional representation is fundamental to image processing.",
    "hint": "Think about the formal mathematical definition rather than informal descriptions."
  },
  {
    "question": "How many colour combinations are possible for a single pixel in an RGB image, where each colour channel (Red, Green, Blue) has values ranging from 0 to 255?",
    "options": [
      {
        "text": "256",
        "image": ""
      },
      {
        "text": "65,536",
        "image": ""
      },
      {
        "text": "16,777,216",
        "image": ""
      },
      {
        "text": "1,048,576",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Each RGB channel has 256 possible values (0-255, which is 2^8). With three independent color channels, the total number of combinations is 256^3 = 16,777,216 (approximately 16.8 million colors).",
    "hint": "Calculate 256 × 256 × 256, considering 8 bits per channel."
  },
  {
    "question": "What is the primary function of image filtering?",
    "options": [
      {
        "text": "To change the colour palette of an image.",
        "image": ""
      },
      {
        "text": "To alter the pixel locations within an image.",
        "image": ""
      },
      {
        "text": "To apply a function to the pixels of an image, without changing their positions.",
        "image": ""
      },
      {
        "text": "To compress the size of an image.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Image filtering applies a mathematical operation (kernel/filter) to each pixel based on its neighborhood, modifying pixel values without altering their spatial positions.",
    "hint": "Filtering changes HOW pixels look, not WHERE they are located in the image."
  },
  {
    "question": "Which of the following is NOT a typical application of image filtering?",
    "options": [
      {
        "text": "Image deblurring.",
        "image": ""
      },
      {
        "text": "Improving contrast.",
        "image": ""
      },
      {
        "text": "Noise reduction.",
        "image": ""
      },
      {
        "text": "Increasing image resolution.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Image filtering modifies existing pixel values for deblurring, contrast enhancement, and noise reduction. Increasing resolution requires adding new pixels through interpolation, which is not a filtering operation.",
    "hint": "Think about whether the operation changes pixel values or the number of pixels."
  },
  {
    "question": "What is the mathematical operation at the core of 2D convolutions?",
    "options": [
      {
        "text": "Subtraction and division.",
        "image": ""
      },
      {
        "text": "Element-wise matrix multiplication and summation.",
        "image": ""
      },
      {
        "text": "Vector dot product.",
        "image": ""
      },
      {
        "text": "Matrix inversion.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "2D convolution slides a kernel over the image, performing element-wise multiplication between kernel values and image patch values, then summing all products to produce one output pixel.",
    "hint": "This is like a sliding dot product where you multiply corresponding elements and add them up."
  },
  {
    "question": "If the kernel was not flipped in a 2D convolution, the operation would be a:",
    "options": [
      {
        "text": "Matrix transpose.",
        "image": ""
      },
      {
        "text": "Cross-correlation.",
        "image": ""
      },
      {
        "text": "Dot product.",
        "image": ""
      },
      {
        "text": "Linear transformation.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Cross-correlation is the same operation as convolution but without flipping the kernel (180-degree rotation). True convolution requires the kernel to be flipped before the sliding operation.",
    "hint": "The difference lies in whether the kernel is rotated before sliding or not."
  },
  {
    "question": "What is the purpose of padding in 2D convolutions?",
    "options": [
      {
        "text": "To reduce the computational cost of the convolution.",
        "image": ""
      },
      {
        "text": "To maintain the same output dimensions as the input.",
        "image": ""
      },
      {
        "text": "To sharpen the image.",
        "image": ""
      },
      {
        "text": "To blur the image.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Padding adds extra border pixels (typically zeros) around the input image so that the kernel can fully cover the edges, preserving spatial dimensions in the output when using 'same' padding.",
    "hint": "Without padding, the output shrinks because the kernel can't fully operate at the image borders."
  },
  {
    "question": "An identity kernel in image filtering will:",
    "options": [
      {
        "text": "Sharpen the edges of an image.",
        "image": ""
      },
      {
        "text": "Leave the image unchanged.",
        "image": ""
      },
      {
        "text": "Blur the image significantly.",
        "image": ""
      },
      {
        "text": "Invert the colours of the image.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The identity kernel contains a 1 at the center and 0 everywhere else, so when convolved with an image it simply copies each pixel's original value without any modification.",
    "hint": "Think about what values a kernel would need to simply pass through the original pixel values."
  },
  {
    "question": "A mean blur kernel works by:",
    "options": [
      {
        "text": "Multiplying the pixel value by a constant.",
        "image": ""
      },
      {
        "text": "Amplifying the difference between a pixel and its neighbors.",
        "image": ""
      },
      {
        "text": "Averaging a pixel with its surrounding neighbours.",
        "image": ""
      },
      {
        "text": "Giving greater weight to the centre pixel.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The mean blur kernel assigns equal weights to all pixels in the neighborhood and computes their arithmetic average, which smooths the image by reducing local variations.",
    "hint": "Consider what the word 'mean' implies in terms of mathematical operation on pixel values."
  },
  {
    "question": "Which filter is known for weighting nearby pixels more heavily than distant ones, leading to a more natural-looking blur?",
    "options": [
      {
        "text": "Mean blur filter.",
        "image": ""
      },
      {
        "text": "Sharpening kernel.",
        "image": ""
      },
      {
        "text": "Identity kernel.",
        "image": ""
      },
      {
        "text": "Gaussian blur filter.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "The Gaussian blur uses a Gaussian (bell curve) function that gives higher weights to pixels closer to the center, creating a natural-looking blur that preserves edges better than uniform averaging.",
    "hint": "Which filter is based on the Gaussian distribution that decays with distance?"
  },
  {
    "question": "Which of the following is a property of a Gaussian filter?",
    "options": [
      {
        "text": "Non-rotational symmetry.",
        "image": ""
      },
      {
        "text": "It weights distant pixels more than nearby ones.",
        "image": ""
      },
      {
        "text": "Rotational symmetry.",
        "image": ""
      },
      {
        "text": "It enhances the noise in an image.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The 2D Gaussian function is circularly symmetric around its center, meaning the filter has the same response in all directions regardless of orientation.",
    "hint": "Imagine the 2D Gaussian shape - does it look the same when rotated?"
  },
  {
    "question": "What is the separable property of a filter?",
    "options": [
      {
        "text": "Applying the filter only to certain parts of the image.",
        "image": ""
      },
      {
        "text": "First convolving rows with a 1D filter, then columns with a 1D filter.",
        "image": ""
      },
      {
        "text": "Applying different filters to different image channels.",
        "image": ""
      },
      {
        "text": "Convolution with multiple kernels",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "A separable filter can be decomposed into two 1D filters applied sequentially: first convolve all rows with a 1D kernel, then convolve all columns with the same or different 1D kernel.",
    "hint": "Think about breaking down a 2D convolution into two sequential 1D operations."
  },
  {
    "question": "In the context of a Gaussian pyramid, what is the first step after starting with the original image?",
    "options": [
      {
        "text": "Downsampling the image.",
        "image": ""
      },
      {
        "text": "Applying a Gaussian blur.",
        "image": ""
      },
      {
        "text": "Upsampling the image.",
        "image": ""
      },
      {
        "text": "Applying a sharpening filter.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "The Gaussian pyramid first applies a blur operation to the original image before any sampling change. This smoothing is essential to reduce high-frequency details that would cause artifacts when the image is later downsampled.",
    "hint": "Consider what preparation is needed before reducing image dimensions to maintain quality."
  },
  {
    "question": "How does downsampling change the image size in each level of a Gaussian pyramid?",
    "options": [
      {
        "text": "Reduces the size by a factor of 2.",
        "image": ""
      },
      {
        "text": "Reduces the size by a factor of 3.",
        "image": ""
      },
      {
        "text": "Reduces the size by a factor of 4.",
        "image": ""
      },
      {
        "text": "Reduces the size by a factor of 8.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Standard Gaussian pyramid downsampling reduces both width and height by a factor of 2 at each level, resulting in 1/4 of the original pixel count per level.",
    "hint": "Think about halving both dimensions simultaneously."
  },
  {
    "question": "What is the primary reason for applying a Gaussian blur before downsampling in a Gaussian pyramid?",
    "options": [
      {
        "text": "To increase the resolution of the image.",
        "image": ""
      },
      {
        "text": "To sharpen the image before resizing.",
        "image": ""
      },
      {
        "text": "To act as a low-pass filter and prevent aliasing.",
        "image": ""
      },
      {
        "text": "To make the image more colourful.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Gaussian blur acts as a low-pass filter that removes high-frequency components (edges and fine details) before reducing resolution, preventing aliasing artifacts in the downsampled image.",
    "hint": "Consider what happens to high-frequency information when resolution decreases."
  },
  {
    "question": "What is aliasing, as discussed in the context of image downsampling?",
    "options": [
      {
        "text": "The effect of making the image sharper.",
        "image": ""
      },
      {
        "text": "Distortions in the downsampled image caused by undersampling high-frequency components.",
        "image": ""
      },
      {
        "text": "The effect of applying a blur.",
        "image": ""
      },
      {
        "text": "A form of image compression.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Aliasing is a distortion that occurs when high-frequency components in an image exceed the sampling rate after downsampling, causing visual artifacts like moiré patterns or jagged edges.",
    "hint": "Think about what happens when signal frequency exceeds the sampling limit."
  },
  {
    "question": "CV Basics: Which of the following best describes the fundamental concept of computer vision, as presented in the material?",
    "options": [
      {
        "text": "Generating arrays of numbers that resemble real-world objects, like fruits.",
        "image": ""
      },
      {
        "text": "Solving the 'inverse graphics' problem by inferring the structure of the world from visual cues.",
        "image": ""
      },
      {
        "text": "Creating digital images using a pinhole camera model and digitizers.",
        "image": ""
      },
      {
        "text": "Recognising objects by matching 2D image fragments and their configurations.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Computer vision fundamentally addresses the 'inverse graphics' problem - inferring the 3D structure, objects, and properties of the world from 2D images, essentially reversing the image formation process.",
    "hint": "Consider what 'inverse' means - we're working backwards from image to scene."
  },
  {
    "question": "CV Basics: The 'trompe l’oeil' examples in the text primarily illustrate which aspect of computer vision?",
    "options": [
      {
        "text": "The challenges of object recognition in cluttered scenes.",
        "image": ""
      },
      {
        "text": "The use of color and shading to create realistic images.",
        "image": ""
      },
      {
        "text": "The exploitation of depth-perception cues and their mathematical modeling.",
        "image": ""
      },
      {
        "text": "The importance of prior expectations in image interpretation.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Trompe l'oeil works by exploiting depth-perception cues like perspective, shading, and texture gradients to create convincing optical illusions. In computer vision, understanding these cues is essential for modeling how 2D images represent 3D structures mathematically.",
    "hint": "Consider what visual cues trick our brain into perceiving depth in flat images."
  },
  {
    "question": "CV Basics: According to the provided text, what is a key characteristic of 'basic level categories' in object recognition?",
    "options": [
      {
        "text": "They represent the most detailed classification of objects.",
        "image": ""
      },
      {
        "text": "They are the categories that are most difficult for humans to identify quickly.",
        "image": ""
      },
      {
        "text": "They are culturally dependent without any consistency.",
        "image": ""
      },
      {
        "text": "They represent the highest level at which category members have similar perceived shapes and are easily recognized by humans.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Basic level categories represent the optimal balance in object categorization - they are the most general level at which objects share similar shapes (like 'chair' vs. 'office chair' or 'furniture'), making them quickly and easily recognizable by humans.",
    "hint": "Think about what level of categorization allows us to recognize objects fastest - not too specific, not too general."
  },
  {
    "question": "CV Basics: What is the primary purpose of image filtering, as described in the material?",
    "options": [
      {
        "text": "To increase the amount of noise in an image to make edges more apparent.",
        "image": ""
      },
      {
        "text": "To create 3D models of objects from 2D images.",
        "image": ""
      },
      {
        "text": "To enhance image quality, extract features, and reduce noise.",
        "image": ""
      },
      {
        "text": "To generate new images using the principles of graphics.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Image filtering is a fundamental preprocessing operation that modifies pixel values based on local neighborhoods to achieve various goals like smoothing noise, enhancing edges, or detecting specific features.",
    "hint": "Consider what basic operations we need to perform on images before analyzing their content."
  },
  {
    "question": "CV Basics: In the context of 2D convolution, which of the following steps is essential?",
    "options": [
      {
        "text": "Rotating the filter kernel by 90 degrees.",
        "image": ""
      },
      {
        "text": "Mirroring the filter kernel before applying it to the image.",
        "image": ""
      },
      {
        "text": "Applying a non-linear function to the local image patch.",
        "image": ""
      },
      {
        "text": "Only summing the values without multiplication.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In 2D convolution, the kernel must be mirrored (flipped both horizontally and vertically) before being applied to the image. This is mathematically distinct from cross-correlation and is essential for proper convolution operations.",
    "hint": "Remember the mathematical definition of convolution versus correlation - the flip operation is key."
  },
  {
    "question": "CV Basics: What does the text say about linear systems in the context of image processing?",
    "options": [
      {
        "text": "They are used only for non-linear filtering.",
        "image": ""
      },
      {
        "text": "They are characterized by a lack of superposition.",
        "image": ""
      },
      {
        "text": "They exhibit properties such as homogeneity, additivity, and superposition.",
        "image": ""
      },
      {
        "text": "They cannot be represented by matrix operations.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Linear systems are defined by two fundamental properties: homogeneity (scaling an input scales the output proportionally) and additivity (the response to combined inputs equals the sum of individual responses). Superposition combines both.",
    "hint": "Think about what makes a system 'linear' - it's about how the system handles scaling and addition of inputs."
  },
  {
    "question": "CV Basics: According to the source material, why is Gaussian averaging preferred over a simple box filter for smoothing?",
    "options": [
      {
        "text": "Because box filters are computationally more expensive.",
        "image": ""
      },
      {
        "text": "Because box filters do not reduce noise effectively.",
        "image": ""
      },
      {
        "text": "Because Gaussian averaging gives more weight to nearby pixels, modelling probabilistic inference.",
        "image": ""
      },
      {
        "text": "Because box filters are not separable and therefore cannot be implemented efficiently.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il filtro Gaussiano assegna pesi maggiori ai pixel vicini al centro e pesi decrescenti ai pixel più lontani, modellando un'inferenza probabilistica dove la probabilità di appartenenza diminuisce con la distanza, a differenza del box filter che tratta tutti i pixel equally.",
    "hint": "Considera come la distribuzione Gaussiana assegna le probabilità in base alla distanza dal centro."
  },
  {
    "question": "CV Basics: What is the main problem caused by subsampling without average filtering, according to the text?",
    "options": [
      {
        "text": "It makes the image smoother.",
        "image": ""
      },
      {
        "text": "It increases the resolution of the image.",
        "image": ""
      },
      {
        "text": "It leads to aliasing, introducing artifacts in the image.",
        "image": ""
      },
      {
        "text": "It preserves high-frequency information more accurately.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il subsampling senza filtering viola il teorema del campionamento di Nyquist: campionando a una frequenza inferiore a quella richiesta, le componenti ad alta frequenza si ripetono nello spettro causing aliasing artifacts.",
    "hint": "Ricorda il teorema del campionamento di Nyquist e cosa succede quando campioni sotto la frequenza di Nyquist."
  },
  {
    "question": "CV Basics: What is the significance of the 'derivative of Gaussian' in edge detection, according to the source?",
    "options": [
      {
        "text": "It is used to enhance noise and amplify variations in the image.",
        "image": ""
      },
      {
        "text": "It directly extracts lines and edges without the need for smoothing.",
        "image": ""
      },
      {
        "text": "It is an approximation of the optimal edge detector under certain assumptions (linear filtering and additive Gaussian noise).",
        "image": ""
      },
      {
        "text": "It is a simplified method used to avoid complex calculations in edge detection.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La derivata del Gaussian è considerata l'approssimazione dell'edge detector ottimale secondo l'analisi di Canny, che dimostra come, sotto le assunzioni di filtraggio lineare e rumore Gaussiano additivo, questo operatore massimizza il rapporto segnale-rumore e localizza correttamente gli edge.",
    "hint": "Pensa al fundamenti teorici dell'edge detector di Canny."
  },
  {
    "question": "CV Basics: In the context of edge detection, what is the role of \"non-maximum suppression\"?",
    "options": [
      {
        "text": "To amplify the noise near edges.",
        "image": ""
      },
      {
        "text": "To smooth out the detected edges.",
        "image": ""
      },
      {
        "text": "To thin edges by choosing the largest gradient magnitude along the gradient direction.",
        "image": ""
      },
      {
        "text": "To detect edges at different scales and combine them into a single map.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La non-maximum suppression assottiglia gli edge mantenendo solo i pixel con massima magnitudine del gradiente nella direzione perpendicolare all'edge, creando edge sottili di un solo pixel di larghezza.",
    "hint": "Il termine 'non-maximum' indica che vengono mantenute solo le risposte massime."
  },
  {
    "question": "CV Basics: What is the Laplacian operator, as presented in the text, and what is it used for?",
    "options": [
      {
        "text": "It is a filter that calculates the gradient magnitude of an image.",
        "image": ""
      },
      {
        "text": "It is a smoothing filter that reduces high-frequency information.",
        "image": ""
      },
      {
        "text": "It is a linear filter used to detect edges by identifying zero-crossings of the second derivative.",
        "image": ""
      },
      {
        "text": "It is a filter that is used for color histogram generation.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il Laplaciano è un operatore lineare che calcola la derivata seconda dell'immagine e viene usato per la detecttion degli edge attraverso gli zero-crossings, ovvero i punti dove la derivata seconda è zero, indicando una transizione di intensità.",
    "hint": "Il Laplaciano si basa sulle derivate seconde, non sulle prime come il gradiente."
  },
  {
    "question": "CV Basics: What is a primary motivation for using color histograms for object recognition?",
    "options": [
      {
        "text": "They are sensitive to geometric transformations.",
        "image": ""
      },
      {
        "text": "They require perfect segmentation of objects.",
        "image": ""
      },
      {
        "text": "They are computationally expensive, however, this is offset by the quality of recognition they provide.",
        "image": ""
      },
      {
        "text": "They are relatively invariant to object translations, image rotations, and partial occlusions.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Color histograms capture global color distribution statistics rather than spatial arrangement, making them naturally robust to geometric transformations and partial occlusions since the overall color composition remains similar.",
    "hint": "Think about what information histograms represent and how that relates to spatial changes."
  },
  {
    "question": "CV Basics: According to the source, what is a limitation of using color histograms for object recognition?",
    "options": [
      {
        "text": "They cannot be used for deformable objects such as pullovers.",
        "image": ""
      },
      {
        "text": "They require a large number of training views per object.",
        "image": ""
      },
      {
        "text": "They can be sensitive to changes in illumination conditions.",
        "image": ""
      },
      {
        "text": "They perform poorly when objects are partially occluded.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Color histograms depend on pixel intensity values, which are directly affected by lighting. Changes in illumination can significantly alter the observed colors in an image.",
    "hint": "Consider how different lighting conditions affect the colors you see in a photo."
  },
  {
    "question": "CV Basics: Which of the following statements accurately describes the 'Intersection' method for comparing histograms?",
    "options": [
      {
        "text": "It calculates the differences between corresponding histogram cells.",
        "image": ""
      },
      {
        "text": "It gives a higher score when there is minimal overlap between histograms.",
        "image": ""
      },
      {
        "text": "It measures the common part of both histograms, with a range between 0 and 1.",
        "image": ""
      },
      {
        "text": "It weights all histogram cells equally regardless of their significance.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Histogram intersection computes the minimum value for each corresponding bin between two histograms and sums these values, giving a similarity measure that ranges from 0 (no overlap) to 1 (identical histograms).",
    "hint": "Think about what 'intersection' means mathematically - it's about finding commonality."
  },
  {
    "question": "CV Basics: In the context of performance evaluation, what does a confusion matrix help to determine?",
    "options": [
      {
        "text": "The optimal parameters for an image filtering algorithm.",
        "image": ""
      },
      {
        "text": "The best method for comparing color histograms.",
        "image": ""
      },
      {
        "text": "The number of true positives, true negatives, false positives, and false negatives for a given classifier and threshold.",
        "image": ""
      },
      {
        "text": "The area under the ROC curve for a specific model.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "A confusion matrix is a table that tabulates correct and incorrect predictions, organizing them into the four categories: true positives, true negatives, false positives, and false negatives.",
    "hint": "Consider what the rows and columns of a confusion matrix typically represent."
  },
  {
    "question": "CV Basics: What does the term \"recall\" measure in the context of performance evaluation?",
    "options": [
      {
        "text": "The proportion of correctly identified negative cases.",
        "image": ""
      },
      {
        "text": "The proportion of actual positives that are correctly identified.",
        "image": ""
      },
      {
        "text": "The overall accuracy of the classification model.",
        "image": ""
      },
      {
        "text": "The proportion of false alarms in the classification process.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Recall (also called sensitivity or true positive rate) measures how many of the actual positive cases the classifier correctly identifies, calculated as TP/(TP+FN).",
    "hint": "Recall answers: 'Of all the positive cases, how many did we find?'"
  },
  {
    "question": "CV Basics: In the context of ROC curves, what does the True Positive Rate (TPR) represent?",
    "options": [
      {
        "text": "The rate of false alarms for a given threshold.",
        "image": ""
      },
      {
        "text": "The proportion of correctly identified negative cases.",
        "image": ""
      },
      {
        "text": "The proportion of actual positives that are correctly identified.",
        "image": ""
      },
      {
        "text": "The overall accuracy of the classification model.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "TPR (True Positive Rate), also known as sensitivity or recall, measures the fraction of actual positive samples that are correctly classified as positive. It is the y-axis of the ROC curve and directly answers: 'Of all the positives, how many did we catch?'",
    "hint": "Focus on the word 'positive' in both parts - what does it mean for a positive to be correctly identified?"
  },
  {
    "question": "CV Basics: What is the significance of the Area Under the ROC Curve (AUROC)?",
    "options": [
      {
        "text": "It represents the trade-off between precision and recall for a classification model.",
        "image": ""
      },
      {
        "text": "It indicates how well a classifier distinguishes between two classes, with a higher AUROC suggesting better performance.",
        "image": ""
      },
      {
        "text": "It helps choose the best comparison method for color histograms.",
        "image": ""
      },
      {
        "text": "It is used to determine the optimal threshold for object detection algorithms.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "AUROC summarizes the ROC curve into a single value representing the classifier's ability to rank positive samples higher than negative ones. A value of 0.5 means random guessing, while 1.0 means perfect separation between classes.",
    "hint": "Think about what it means for a classifier to 'distinguish' between two classes - how well can it separate them?"
  },
  {
    "question": "CV Basics: According to the material, why is the precision-recall curve preferred for detection tasks?",
    "options": [
      {
        "text": "Because it does not require any threshold.",
        "image": ""
      },
      {
        "text": "Because it is less sensitive to noise than other performance metrics.",
        "image": ""
      },
      {
        "text": "Because it is better suited when the number of true negatives is not well-defined, such as in detection tasks.",
        "image": ""
      },
      {
        "text": "Because it gives more importance to the true negative rate.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In detection tasks like object detection, the concept of 'true negative' is problematic because there are infinitely many possible locations that are not the object. Precision-recall curve focuses only on positives and doesn't require counting true negatives.",
    "hint": "Consider what constitutes a 'negative' in detection - is it well-defined like in classification?"
  },
  {
    "question": "CV Basics: Leonardo da Vinci's observations about the camera obscura, as described in the text, highlight which fundamental principle of image formation?",
    "options": [
      {
        "text": "The principle of digital image processing.",
        "image": ""
      },
      {
        "text": "The formation of a reversed and reduced image through a small aperture.",
        "image": ""
      },
      {
        "text": "The concept of linear filtering in image enhancement.",
        "image": ""
      },
      {
        "text": "The use of color histograms for object recognition.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Da Vinci's observations described how light passing through a tiny aperture projects an inverted image onto the opposite surface. This demonstrates the pinhole camera principle where the small hole acts as a lens, creating a reduced and reversed projection.",
    "hint": "What happens to light when it passes through a very small opening? Think about projection and inversion."
  },
  {
    "question": "CV Basics: The text refers to computer vision as the problem of 'inverse graphics'. What does this imply about the goals of computer vision?",
    "options": [
      {
        "text": "Computer vision aims to generate images that are indistinguishable from real-world scenes.",
        "image": ""
      },
      {
        "text": "Computer vision seeks to create digital images by using the pinhole camera model.",
        "image": ""
      },
      {
        "text": "Computer vision tries to infer the properties of the world from images, reversing the process of graphics which creates images from the world.",
        "image": ""
      },
      {
        "text": "Computer vision focuses on the analysis of color histograms for object identification.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Inverse graphics means working backwards from the 2D image to infer the 3D world properties that produced it. Graphics takes world parameters (objects, lighting, camera) and generates images; vision does the opposite by extracting those parameters from images.",
    "hint": "Consider the direction of inference - are we going from world to image, or image to world?"
  },
  {
    "question": "CV Basics: According to the text, what is the significance of the 'pictorial structure' model in object recognition?",
    "options": [
      {
        "text": "It only uses 3D models for object recognition.",
        "image": ""
      },
      {
        "text": "It relies on color histograms to identify objects.",
        "image": ""
      },
      {
        "text": "It represents objects as combinations of 2D image fragments and their configurations.",
        "image": ""
      },
      {
        "text": "It is a simple method that can overcome all complexities of object recognition.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The pictorial structure model represents objects as combinations of 2D image fragments (parts) and their spatial configurations. This approach is significant because it provides a way to model object appearance while accounting for viewpoint variations and part-based deformations, forming a foundational concept in part-based recognition.",
    "hint": "Think about how this model breaks down objects into parts and their arrangements rather than using full 3D models."
  },
  {
    "question": "CV Basics: What does the material say about the challenges of visual categorization?",
    "options": [
      {
        "text": "They are limited to problems with occlusions.",
        "image": ""
      },
      {
        "text": "They are not affected by multi-scale, multi-view variations.",
        "image": ""
      },
      {
        "text": "They include issues such as multi-scale, multi-view, multi-class, varying illumination, occlusion, cluttered backgrounds, articulation, and high intraclass variance/low interclass variance.",
        "image": ""
      },
      {
        "text": "They are easily solved by basic linear filtering techniques.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Visual categorization faces numerous challenges including variations in scale, viewpoint, illumination, occlusion, background clutter, articulation, and the difficulty of distinguishing between classes with high intra-class variance and low inter-class variance. These factors make visual recognition a complex task that cannot be solved by simple linear methods.",
    "hint": "Consider the wide range of factors that can change how an object appears in an image."
  },
  {
    "question": "CV Basics: What is the role of a 'filter kernel' in the context of image filtering?",
    "options": [
      {
        "text": "It is used to digitize analog images.",
        "image": ""
      },
      {
        "text": "It is only useful for non-linear operations.",
        "image": ""
      },
      {
        "text": "It is a small matrix that is used to apply some function to a local image patch during convolution.",
        "image": ""
      },
      {
        "text": "It represents the output image, after applying the convolution.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "A filter kernel is a small matrix (e.g., 3x3, 5x5) that is slid across the image and used to compute a new pixel value based on a local neighborhood during convolution. This is the fundamental mechanism behind linear image filtering for tasks like smoothing and edge detection.",
    "hint": "Think about what \"slides\" across the image during the filtering process."
  },
  {
    "question": "CV Basics: According to the source material, what is the primary goal of using linear filtering for smoothing an image?",
    "options": [
      {
        "text": "To enhance the edges and details in an image.",
        "image": ""
      },
      {
        "text": "To create a sharper version of the image.",
        "image": ""
      },
      {
        "text": "To reduce noise and fill in missing information.",
        "image": ""
      },
      {
        "text": "To perform non-linear operations on an image.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Linear filtering for smoothing primarily aims to reduce noise by averaging out random variations in pixel values, which also has the effect of slightly blurring the image. This is achieved through convolution with a smoothing kernel like Gaussian, which attenuates high-frequency noise.",
    "hint": "Consider what happens to high-frequency noise when you average neighboring pixels."
  },
  {
    "question": "CV Basics: Why is the concept of 'separability' important in the context of Gaussian filtering?",
    "options": [
      {
        "text": "Because it makes the filter non-linear.",
        "image": ""
      },
      {
        "text": "Because it allows for efficient implementation of the filtering operation by applying 1D filters sequentially.",
        "image": ""
      },
      {
        "text": "Because it increases the smoothing effect on an image.",
        "image": ""
      },
      {
        "text": "Because it reduces the computational cost of applying a box filter.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Separability in Gaussian filtering allows a 2D Gaussian filter to be decomposed into two 1D Gaussian filters applied sequentially (first horizontal, then vertical). This reduces computational complexity from O(n²) to O(n), making the filtering operation much more efficient for practical applications.",
    "hint": "Think about how applying two 1D filters could be faster than one 2D filter."
  },
  {
    "question": "CV Basics: What is the main idea behind using a Gaussian pyramid for multi-scale image representation?",
    "options": [
      {
        "text": "To reduce the resolution of images for easier processing.",
        "image": ""
      },
      {
        "text": "To apply linear filtering in a single scale.",
        "image": ""
      },
      {
        "text": "To represent an image at different scales by repeated smoothing and subsampling.",
        "image": ""
      },
      {
        "text": "To compute the 2nd derivative of an image.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The Gaussian pyramid creates multi-scale representations by repeatedly applying Gaussian smoothing (to blur/smooth the image) followed by subsampling (reducing resolution by half), creating a hierarchy of images at different scales.",
    "hint": "Think about what 'pyramid' means - multiple levels at progressively lower resolutions."
  },
  {
    "question": "CV Basics: In the context of edge detection, why is smoothing an image prior to computing derivatives beneficial?",
    "options": [
      {
        "text": "It enhances the noise, to see edges more clearly.",
        "image": ""
      },
      {
        "text": "It ensures edges are not affected by lighting changes.",
        "image": ""
      },
      {
        "text": "It reduces the impact of noise and small variations, which can interfere with detecting true edges.",
        "image": ""
      },
      {
        "text": "It makes the edges thicker and more visible.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Smoothing with a Gaussian filter before computing derivatives reduces high-frequency noise that can cause false edges, allowing the derivative operations to detect only significant intensity changes.",
    "hint": "Derivatives amplify noise; consider what preprocessing can mitigate this."
  },
  {
    "question": "CV Basics: According to the text, what does the magnitude of the gradient measure in edge detection?",
    "options": [
      {
        "text": "The direction of the edge.",
        "image": ""
      },
      {
        "text": "The noise level around an edge.",
        "image": ""
      },
      {
        "text": "The strength of an edge.",
        "image": ""
      },
      {
        "text": "The scale of the image where edges are more evident.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Gradient magnitude measures the rate of intensity change - higher magnitude means stronger edge (steeper transition), while lower magnitude indicates weaker or gradual transitions.",
    "hint": "Magnitude answers 'how much' the intensity changes, not 'where' it changes."
  },
  {
    "question": "CV Basics: What is the main advantage of using the Canny edge detector over other edge detection methods, according to the text?",
    "options": [
      {
        "text": "It is faster and less computationally intensive than other methods.",
        "image": ""
      },
      {
        "text": "It is an approximation of the optimal edge detector under the assumptions of linear filtering and additive Gaussian noise, offering a good trade-off between detection and localization.",
        "image": ""
      },
      {
        "text": "It does not require any parameter tuning for different images.",
        "image": ""
      },
      {
        "text": "It is simpler to implement and more robust in noisy conditions.",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Canny's detector is theoretically optimal under the criteria of good detection, good localization, and minimal responses under assumptions of linear filtering with additive Gaussian noise.",
    "hint": "Consider what 'optimal' means in terms of mathematical assumptions about the image formation process."
  },
  {
    "question": "CV Basics: In the context of edge detection using the Laplacian, what are 'zero-crossings' and what do they indicate?",
    "options": [
      {
        "text": "They indicate the location of the maximum gradient value.",
        "image": ""
      },
      {
        "text": "They indicate the strength of an edge in an image.",
        "image": ""
      },
      {
        "text": "They are used to calculate color histograms in an image.",
        "image": ""
      },
      {
        "text": "They represent points where the second derivative changes sign, which indicates the location of edges.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Zero-crossings occur where the second derivative (Laplacian) changes sign, corresponding to points of maximum change in the first derivative, which correspond to edge locations in the original image.",
    "hint": "Think about inflection points in calculus - they occur where the second derivative is zero and changes sign."
  },
  {
    "question": "CV Basics: According to the text, what is a key characteristic of appearance-based object identification/recognition?",
    "options": [
      {
        "text": "It relies on explicit 3D models of objects.",
        "image": ""
      },
      {
        "text": "It requires perfect segmentation of the object in the image.",
        "image": ""
      },
      {
        "text": "It represents objects by a collection of 2D images without the need for a 3D model, and it is sufficient to compare the 2D appearances.",
        "image": ""
      },
      {
        "text": "It is invariant to changes in the viewing angle.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Appearance-based methods use multiple 2D views (templates) of an object for recognition, avoiding the need to construct explicit 3D models. The object is recognized by matching its current 2D appearance against the stored collection of 2D views.",
    "hint": "Think about what 'appearance-based' implies - does it focus on how things look or their underlying structure?"
  },
  {
    "question": "CV Basics: What does the material say about the use of color in object recognition?",
    "options": [
      {
        "text": "Color changes under geometric transformations and therefore is not a reliable feature.",
        "image": ""
      },
      {
        "text": "Color is a global feature that is robust to occlusions.",
        "image": ""
      },
      {
        "text": "Color is a local feature that remains relatively constant under geometric transformations and is robust to partial occlusions.",
        "image": ""
      },
      {
        "text": "Color cannot be used for recognition because it is very sensitive to light variations.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Color is a local feature computed at each image point, remains relatively constant under geometric transformations (rotation, scale), and partial occlusions don't completely prevent recognition since visible color information can still be matched.",
    "hint": "Consider what makes a feature 'local' and how color behaves under transformations versus other features like edges."
  },
  {
    "question": "CV Basics: What does a 3D (joint) color histogram represent?",
    "options": [
      {
        "text": "The 1D count of pixels of individual R, G, B colors, and luminance.",
        "image": ""
      },
      {
        "text": "The color normalized by intensity.",
        "image": ""
      },
      {
        "text": "The count of pixels for each combination of RGB values.",
        "image": ""
      },
      {
        "text": "A 2D representation of color, for example, using two parameters, r and g.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "A 3D joint color histogram counts the number of pixels for each possible combination of R, G, and B values simultaneously, treating them as a single 3-dimensional distribution rather than three separate 1D histograms.",
    "hint": "The word 'joint' in statistics means considering variables together, not individually."
  },
  {
    "question": "CV Basics: According to the text, what is the significance of using a 'chromatic representation' of color?",
    "options": [
      {
        "text": "It ensures that the color histograms do not change under rotation.",
        "image": ""
      },
      {
        "text": "It guarantees that the color histogram is robust to occlusion.",
        "image": ""
      },
      {
        "text": "It normalizes colors by intensity, focusing on the color itself rather than its brightness.",
        "image": ""
      },
      {
        "text": "It generates an intensity image that is later used to extract color information.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Chromatic representation normalizes color by intensity (r = R/(R+G+B), g = G/(R+G+B)), separating the intrinsic color from brightness. This makes color matching invariant to lighting conditions since it focuses on hue/saturation rather than overall intensity.",
    "hint": "Chromaticity refers to the pure quality of color apart from its intensity or brightness."
  },
  {
    "question": "CV Basics: What does the Euclidean distance measure in the context of histogram comparison?",
    "options": [
      {
        "text": "It measures the differences between the histograms, weighting each cell equally.",
        "image": ""
      },
      {
        "text": "It measures the common part of both histograms.",
        "image": ""
      },
      {
        "text": "It measures if two distributions are statistically different, with a focus on outliers.",
        "image": ""
      },
      {
        "text": "It only measures the distance between the central cells of two histograms.",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Euclidean distance computes the straight-line distance between two histogram vectors in N-dimensional space, treating each histogram bin equally without any special weighting or normalization.",
    "hint": "Think about the standard formula for distance between two points in space."
  },
  {
    "question": "CV Basics: In the context of histogram comparison, what does the Chi-square measure primarily aim to test?",
    "options": [
      {
        "text": "The overlap between the histograms of known objects and a test image.",
        "image": ""
      },
      {
        "text": "The distances between the centers of two histograms.",
        "image": ""
      },
      {
        "text": "Whether two distributions are statistically different.",
        "image": ""
      },
      {
        "text": "If the two images can be considered the same object.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "The Chi-square test is a statistical hypothesis test that measures the difference between observed and expected frequencies, determining whether two distributions are statistically different from each other.",
    "hint": "Think about what statistical tests do - they determine if there's a significant difference between distributions."
  },
  {
    "question": "CV Basics: What is the 'nearest-neighbor' strategy for object recognition using histograms, as described in the text?",
    "options": [
      {
        "text": "It measures the distance between objects using the Euclidean distance.",
        "image": ""
      },
      {
        "text": "It focuses on the differences between histograms using a Chi-squared measure.",
        "image": ""
      },
      {
        "text": "It looks for the perfect overlap of two histograms.",
        "image": ""
      },
      {
        "text": "It compares a test histogram to a set of known object histograms and selects the one with the best matching score.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Nearest-neighbor is a classification method that compares a test histogram against a database of known object histograms and assigns the label of the most similar one based on a matching score.",
    "hint": "Consider how classification works when you have a database of labeled examples."
  },
  {
    "question": "CV Basics: According to the material, what is the 'color constancy problem' that affects color histograms?",
    "options": [
      {
        "text": "It refers to the fact that colors cannot be used in image recognition.",
        "image": ""
      },
      {
        "text": "It describes a scenario where objects have the same color distribution.",
        "image": ""
      },
      {
        "text": "It is the problem of pixel colors changing due to the illumination conditions.",
        "image": ""
      },
      {
        "text": "It is a problem of color histograms that arises because not all objects can be identified by their color distribution.",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Color constancy is the ability to perceive colors consistently under different illumination. The problem refers to how pixel colors change depending on lighting conditions, affecting histogram-based recognition.",
    "hint": "Think about how the same object looks different under sunlight versus fluorescent light."
  }
]