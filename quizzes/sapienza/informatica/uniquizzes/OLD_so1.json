[
  {
    "question": "Quale delle seguenti affermazioni sulle directory di un file system è vera?",
    "options": [
      {
        "text": "È sempre necessario identificare un file di un file system fornendone il path assoluto",
        "image": ""
      },
      {
        "text": "È sempre necessario identificare un file di un file system fornendone il path relativo alla directory corrente",
        "image": ""
      },
      {
        "text": "È sempre possibile dare lo stesso nome a file diversi",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "A e B sono false perché è possibile identificare un file sia con path assoluto che relativo (non è sempre necessario solo uno dei due). C è falsa perché nella stessa directory non si possono avere due file con lo stesso nome (il file system non saprebbe quale aprire).",
    "hint": "Ricorda che un file può essere identificato in modi diversi e che i nomi devono essere univoci all'interno di una stessa directory."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla concorrenza tra processi o thread è falsa?",
    "options": [
      {
        "text": "La disabilitazione delle interruzioni impedisce la creazione di nuove interruzioni",
        "image": ""
      },
      {
        "text": "L'abuso della disabilitazione delle interruzioni fa diminuire la multiprogrammazione, a parità di numero di processi",
        "image": ""
      },
      {
        "text": "Se un processo può disabilitare le interruzioni tramite un'istruzione macchina dedicata, allora può far diminuire l'uso del processore",
        "image": ""
      },
      {
        "text": "La disabilitazione delle interruzioni non funziona su sistemi con più processori o più core",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La disabilitazione delle interruzioni funziona anche su sistemi multi-core, ma solo sul core che esegue l'istruzione. Ogni core ha il proprio registro di controllo delle interruzioni indipendente.",
    "hint": "Su multi-core, la disabilitazione delle interruzioni protegge solo il core corrente, non gli altri."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni è vera? ",
    "options": [
      {
        "text": "Lo scheduler ha, tra i suoi obiettivi, quello di minimizzare il numero di processi che rispettano la propria deadline",
        "image": ""
      },
      {
        "text": "Lo scheduler ha, tra i suoi obiettivi, quello di minimizzare il volume di lavoro nel tempo",
        "image": ""
      },
      {
        "text": "Lo scheduler ha, tra i suoi obiettivi, quello di massimizzare il tempo di risposta",
        "image": ""
      },
      {
        "text": "Lo scheduler ha, tra i suoi obiettivi, quello di minimizzare il tempo di inattività del processore",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il throughput (volume di lavoro nel tempo) è un obiettivo classico dello scheduler. A è falso perché si cerca di massimizzare (non minimizzare) i processi che rispettano le deadline. C è falso perché si cerca di minimizzare il tempo di risposta. D è sbagliato perché il tempo di inattività è già minimo in un sistema correttamente dimensionato.",
    "hint": "Il throughput misura quanti lavori completati nell'unità di tempo, ed è un indicatore fondamentale dell'efficienza dello scheduler."
  },
  {
    "question": "Quale delle seguenti affermazioni sul modello dei processi in UNIX SVR4 System V Release 4 è falsa?",
    "options": [
      {
        "text": "Se un processo è Zombie, allora è terminato ma il suo process control block è ancora in memoria",
        "image": ""
      },
      {
        "text": "Asleep in Memory coincide con Blocked",
        "image": ""
      },
      {
        "text": "Ha anche uno stato Zombie: serve per tutti i processi che sono terminati",
        "image": ""
      },
      {
        "text": "Ha 9 stati (10 con Exit)",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Non tutti i processi terminati diventano Zombie: lo stato Zombie serve specificamente per i processi terminati il cui genitore non ha ancora letto lo stato di terminazione (tramite wait/waitpid). I processi che vengono immediatamente raccolti dal genitore non diventano Zombie.",
    "hint": "Lo stato Zombie è transitorio: esiste solo finché il padre non legge lo stato di terminazione del figlio."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla memoria virtuale con paginazione è falsa? ",
    "options": [
      {
        "text": "Quando un indirizzo non viene trovato nel translation lookaside buffer, è necessario consultare la normale tabella delle pagine",
        "image": ""
      },
      {
        "text": "Il translation lookaside buffer è una particolare cache, ma non è completamente trasparente al sistema operativo",
        "image": ""
      },
      {
        "text": "Il translation lookaside buffer permette di accedere direttamente al contenuto degli indirizzi di memoria virtuali usati più di recente",
        "image": ""
      },
      {
        "text": "In assenza di translation lookaside buffer, l'accesso ad un indirizzo virtuale può richiedere almeno 2 accessi in memoria",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il TLB è una cache hardware completamente trasparente al sistema operativo: il SO non gestisce direttamente il suo funzionamento, non sa quali entry sono presenti e non interviene nelle hit/miss del TLB.",
    "hint": "Il TLB è gestito interamente dall'hardware per velocizzare la traduzione degli indirizzi virtuali in fisici."
  },
  {
    "question": "Quale delle seguenti affermazioni sugli obiettivi di sicurezza di un sistema operativo è vera?",
    "options": [
      {
        "text": "Per \"disponibilità\"dell'hardware si intende la garanzia che le workstation restino sempre fisse in un posto",
        "image": ""
      },
      {
        "text": "Per \"confidenzialità\"dei dati si intende la garanzia che essi non possano essere generati automaticamente",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Per \"integrità\"dei dati si intende la garanzia che essi non vengano mai modificati",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Le definizioni di disponibilità, confidenzialità e integrità sono tutte errate. La disponibilità riguarda l'accesso alle risorse quando richiesto, non la posizione fisica; la confidenzialità riguarda l'accesso autorizzato ai dati, non la loro generazione; l'integrità riguarda la protezione da modifiche non autorizzate, non l'impossibilità di modifiche in generale.",
    "hint": "Ricorda le tre proprietà fondamentali della sicurezza: CIA triad (Confidentiality, Integrity, Availability)."
  },
  {
    "question": "Quale delle seguenti affermazioni sul buffering dell'I/O è vera? ",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Avviene direttamente su disco, altrimenti si rischia il deadlock per interferenze con il DMA",
        "image": ""
      },
      {
        "text": "Nel caso ci siano più buffer, vanno gestiti come nel problema dei lettori/scrittori",
        "image": ""
      },
      {
        "text": "Può consistere nel completare un'istruzione di output I (è una i) dopo che alcune istruzioni successive ad I siano state eseguite ",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Questa è la tecnica del write-behind buffering o output buffering: l'operazione di output viene completata prima delle istruzioni successive, permettendo al programma di continuare mentre l'I/O avviene in background.",
    "hint": "Il buffering può essere di input o output; pensa a come il SO nasconde la latenza dell'I/O al processore."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla gerarchia della memoria è vera?",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Andando dall'alto in basso, cresce il costo",
        "image": ""
      },
      {
        "text": "Andando dall'alto in basso, diminuisce la capacità",
        "image": ""
      },
      {
        "text": "Andando dall'alto in basso, diminuisce la frequenza di accesso alla memoria da parte del processore",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La gerarchia della memoria segue il principio di località: i livelli superiori (cache L1, L2) sono più veloci e piccoli, quindi il processore li usa più frequentemente, mentre quelli inferiori (RAM, disco) hanno accessi meno frequenti.",
    "hint": "Ricorda il compromesso velocità-costo-capacità: più è veloce, meno costa per byte e minore è la capacità."
  },
  {
    "question": "Quale dei seguenti elementi non fa parte del process control block?",
    "options": [
      {
        "text": "Il puntatore alla tabella delle pagine",
        "image": ""
      },
      {
        "text": "L’identificatore del thread",
        "image": ""
      },
      {
        "text": "Lo stato o modalità",
        "image": ""
      },
      {
        "text": "L’identificatore del processo",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il PCB (Process Control Block) contiene informazioni relative al processo, non ai thread. L'identificatore del thread appartiene al TCB (Thread Control Block), che è una struttura separata.",
    "hint": "Il PCB gestisce il processo come entità, mentre i thread sono gestiti dal TCB."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sugli algoritmi di scheduling è vera?",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Il quanto di tempo ottimale per lo scheduler round-robin è maggiore del tipico tempo di completa esecuzione di un processo interattivo",
        "image": ""
      },
      {
        "text": "Lo scheduler First Come First Served favorisce i processi I/O-bound",
        "image": ""
      },
      {
        "text": "Anche assumendo che tutti i processi prima o poi terminino, lo scheduler First Come First Served soffre di starvation",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "B è falsa perché il quanto ottimale deve essere MINORE del tempo tipico di un processo interattivo per garantire buona responsività. C è falsa perché FCFS svantaggia i processi I/O-bound (devono aspettare i CPU-bound). D è falsa perché FCFS non ha starvation se tutti i processi terminano.",
    "hint": "Ricorda le caratteristiche di FCFS: semplice, non preemptive, ma può causare effetto convoglio."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla segmentazione della memoria è falsa? ",
    "options": [
      {
        "text": "Diversi segmenti possono avere diverse lunghezze",
        "image": ""
      },
      {
        "text": "Differentemente dalla paginazione, il programmatore assembler di un processo non interagisce esplicitamente con la gestione dei segmenti",
        "image": ""
      },
      {
        "text": "Per accedere ad un indirizzo contenuto in un segmento di un processo, tale segmento dovrà essere posizionato in memoria principale",
        "image": ""
      },
      {
        "text": "Un indirizzo di memoria principale va visto come un numero di segmento più uno spiazzamento all'interno di tale segmento",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Nella segmentazione, diversamente dalla paginazione, il programmatore assembler può interagire esplicitamente con la gestione dei segmenti, potendo definire nel codice i segmenti (codice, dati, stack). L'affermazione B è quindi falsa.",
    "hint": "Ricorda che nella segmentazione il programmatore può dichiarare esplicitamente i segmenti nel codice sorgente."
  },
  {
    "question": "Quale delle seguenti affermazioni sull'algoritmo per il rilevamento del deadlock visto a lezione è vera?",
    "options": [
      {
        "text": "Richiede in input, per ogni processo p e per ogni risorsa r, il numero massimo di istanze di r che p chiederà nel corso della sua esecuzione",
        "image": ""
      },
      {
        "text": "Se al passo 3 viene trovato un processo non marcato che soddisfi la condizione Qik ≤ wik, allora c'è un deadlock",
        "image": ""
      },
      {
        "text": "I processi marcati sono quelli che non sono coinvolti in un deadlock",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo di rilevamento del deadlock (algoritmo del banchiere o wait-for graph) marca progressivamente i processi che possono completare la loro esecuzione; i processi NON marcati alla fine sono quelli coinvolti nel deadlock.",
    "hint": "I processi marcati sono quelli 'sani' che possono terminare normalmente."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sul long-term scheduler è falsa? ",
    "options": [
      {
        "text": "Viene chiamato in causa esclusivamente quando viene creato un nuovo processo",
        "image": ""
      },
      {
        "text": "Avendo le necessarie informazioni, una tipica strategia è mantenere una giusta proporzione, stabilita a priori, tra processi I/O-bound e CPU-bound",
        "image": ""
      },
      {
        "text": "Avendo le necessarie informazioni, una tipica strategia è ammettere in memoria principale i processi che richiedono dispositivi di I/O diversi da [...]",
        "image": ""
      },
      {
        "text": "Decide quali processi, tra quelli appena creati, possono essere ammessi in memoria principale per l'esecuzione",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il long-term scheduler interviene non solo alla creazione di nuovi processi, ma anche quando un processo termina e si liberano risorse di memoria, permettendo l'ammissione di nuovi processi in memoria centrale.",
    "hint": "Il long-term scheduler viene chiamato anche quando un processo termina e si libera spazio in memoria."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla memoria virtuale con paginazione è vera? ",
    "options": [
      {
        "text": "Il difetto principale del prepaging è che potrebbe portare in memoria pagine cui poi non si fa riferimento",
        "image": ""
      },
      {
        "text": "Placement policy e replacement policy sono sinonimi ed indicano lo stesso insieme di metodologie",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Il difetto principale del paging on demand è che causa molti page fault dopo alcuni secondi di esecuzione",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il prepaging (pre-caricamento di pagine) ha il difetto di poter caricare in memoria pagine che poi non verranno effettivamente utilizzate, sprecando tempo e risorse di I/O.",
    "hint": "Il prepaging tenta di anticipare le richieste, ma potrebbe sbagliare."
  },
  {
    "question": "Quale dei seguenti requisiti deve soddisfare un meccanismo che offra la mutua esclusione?",
    "options": [
      {
        "text": "Non deve essere fatta alcuna assunzione sulla velocità di esecuzione dei processi coinvolti",
        "image": ""
      },
      {
        "text": "Se un processo fa richiesta di entrare nella sezione critica, deve poterlo fare subito",
        "image": ""
      },
      {
        "text": "Se un processo non fa richiesta di entrare nella sezione critica, deve comunque accordarsi all'esecuzione degli altri processi",
        "image": ""
      },
      {
        "text": "Si può assumere che un processo che non sia nella sezione critica prima o poi ci entri",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Un meccanismo di mutua esclusione valido deve funzionare indipendentemente dalla velocità relativa dei processi, senza fare assunzioni su quanto tempo impiega ciascun processo.",
    "hint": "Deve funzionare correttamente sia con processi molto veloci che molto lenti."
  },
  {
    "question": "Quale delle seguenti affermazioni sui metodi di gestione dello spazio libero su disco è vera?",
    "options": [
      {
        "text": "Se viene usata la lista di blocchi liberi, c'è un overhead di spazio, contrariamente alla concatenazione di blocchi liberi",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Se ci sono blocchi da 1kB, e il disco contiene 1TB, l'occupazione dovuta alla lista di blocchi liberi è dell'1%",
        "image": ""
      },
      {
        "text": "Se viene usata la lista di blocchi liberi, una parte viene memorizzata su disco ed una parte in memoria principale",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Nella lista di blocchi liberi, ogni blocco libero contiene un puntatore al blocco successivo, occupando spazio utile. La concatenazione di blocchi liberi (o bitmap) utilizza invece un vettore di bit, senza overhead di puntatori nei blocchi dati.",
    "hint": "Pensare a come i puntatori vengono memorizzati nella lista collegata dei blocchi liberi."
  },
  {
    "question": "Quale delle seguenti affermazioni sul kernel di un sistema operativo è vera?",
    "options": [
      {
        "text": "È responsabile dell'accensione del computer ",
        "image": ""
      },
      {
        "text": "Viene swappato dal disco alla memoria principale ad ogni context switch ",
        "image": ""
      },
      {
        "text": "È responsabile, tra le altre cose, della gestione dei processori",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il kernel è il nucleo del sistema operativo e gestisce le risorse hardware, inclusi i processori (CPU). Tra le sue funzioni c'è lo scheduling della CPU e la gestione dei context switch.",
    "hint": "Il kernel gestisce tutte le risorse hardware del sistema."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sulla preemption è vera?",
    "options": [
      {
        "text": "Se uno scheduler è non-preemptive, permette sempre ai suoi processi di essere eseguiti sul processore, senza interruzioni, fino al loro completamento",
        "image": ""
      },
      {
        "text": "Se uno scheduler è non-preemptive, è possibile che un processo monopolizzi il processore, anche in presenza di altri processi ready",
        "image": ""
      },
      {
        "text": "Se uno scheduler è preemptive, non è possibile che un processo monopolizzi il processore, anche in presenza di altri processi ready",
        "image": ""
      },
      {
        "text": "Per avere un trattamento equo sui processi, è sufficiente usare uno scheduler preemptive",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Uno scheduler non-preemptive non può interrompere un processo in esecuzione. Un processo CPU-bound che non si blocca mai può quindi monopolizzare il processore indefinitamente, anche se ci sono altri processi ready in attesa.",
    "hint": "In uno scheduler non-preemptive, cosa succede quando un processo CPU-bound è in esecuzione?"
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sugli algoritmi di scheduling è vera?",
    "options": [
      {
        "text": "Con lo scheduler Shortest Process Next, i processi con una grande immagine su RAM potrebbero soffrire di starvation",
        "image": ""
      },
      {
        "text": "Lo scheduler round-robin virtuale migliora il round-robin classico, facendo sì che i processi I/O-bound non vengano sfavoriti",
        "image": ""
      },
      {
        "text": "Lo scheduler First Come First Served \"degenera\"nello scheduler round-robin se il quanto di tempo è troppo lungo",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il round-robin virtuale introduce code separate per i processi in attesa di I/O e quelli in attesa della CPU, dando priorità ai processi I/O-bound quando tornano ready. Questo compensa il loro svantaggio nel round-robin classico.",
    "hint": "Come vengono penalizzati i processi I/O-bound nel round-robin tradizionale?"
  },
  {
    "question": "Quale delle seguenti affermazioni sugli indirizzi di memoria principale è vera?",
    "options": [
      {
        "text": "Un indirizzo ﬁsico fa sempre riferimento alla memoria secondaria",
        "image": ""
      },
      {
        "text": "Per rispettare il requisito di rilocazione, occorre trasformare indirizzi ﬁsici in logici",
        "image": ""
      },
      {
        "text": "Gli indirizzi relativi sono usati nella paginazione",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nella paginazione, gli indirizzi logici sono composti da un numero di pagina e un offset (indirizzo relativo). La MMU traduce questo indirizzo relativo nell'indirizzo fisico corrispondente.",
    "hint": "La paginazione usa indirizzi logici composti da numero di pagina e offset."
  },
  {
    "question": "Quale delle seguenti affermazioni sui termini tipici della concorrenza è falsa?",
    "options": [
      {
        "text": "Una sezione critica è una porzione di memoria che contiene almeno una variabile condivisa tra più processi",
        "image": ""
      },
      {
        "text": "Una operazione atomica è una sequenza di istruzioni macchina tale che, se un processo la esegue, allora arriverà a termine senza interruzioni da altri processi",
        "image": ""
      },
      {
        "text": "Il requisito di mutua esclusione prevede che un solo processo possa eseguire un certo segmento di codice o accedere ad una determinata risorsa",
        "image": ""
      },
      {
        "text": "Una race condition è una violazione della mutua esclusione || È possibile che 2 distinti processi chiamino la stessa funzione atomica",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'affermazione A è falsa perché una sezione critica è una porzione di CODICE (non memoria) che accede a risorse condivise, non una porzione di memoria contenente variabili.",
    "hint": "Ricorda che la sezione critica riguarda il codice, non la memoria fisica."
  },
  {
    "question": "Quale dei seguenti elementi fa parte del process control block?",
    "options": [
      {
        "text": "Nessuna delle altre opzioni contiene elementi del process control block",
        "image": ""
      },
      {
        "text": "Le informazioni sul contesto del processo, aggiornate ad ogni istruzione eseguita",
        "image": ""
      },
      {
        "text": "L'intera immagine del processo in memoria",
        "image": ""
      },
      {
        "text": "La tabella delle pagine di secondo livello",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'opzione B è errata perché il contesto del processo nel PCB viene salvato solo durante i context switch, non ad ogni istruzione eseguita. Le opzioni C e D non sono componenti del PCB.",
    "hint": "Il PCB contiene informazioni di controllo del processo, non l'intera immagine in memoria."
  },
  {
    "question": "Quale delle seguenti informazioni non è presente in una tipica entry di una directory di un ﬁle system?",
    "options": [
      {
        "text": "Il gruppo cui appartiene l'utente che ha creato il ﬁle",
        "image": ""
      },
      {
        "text": "La data di creazione del ﬁle",
        "image": ""
      },
      {
        "text": "Autorizzazioni per l'accesso al ﬁle",
        "image": ""
      },
      {
        "text": "Dimensione del ﬁle",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Nelle entry tipiche di directory NON è presente il gruppo dell'utente creatore, mentre sono presenti la data di creazione, i permessi e la dimensione del file.",
    "hint": "I file system conservano metadati essenziali come data, permessi e dimensione, ma non sempre il gruppo."
  },
  {
    "question": "Quale delle seguenti affermazioni sugli algoritmi di scheduling per i dischi è vera?",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "L'algoritmo C-SCAN deriva da SCAN, ed è stato sviluppato per evitare di favorire le richieste di tracce ai bordi del disco",
        "image": ""
      },
      {
        "text": "Per valutare le prestazioni dell'algoritmo con priorità è sufficiente fornire il ruolo degli utenti dei processi che effettuano le richieste",
        "image": ""
      },
      {
        "text": "L'algoritmo random ha la stessa funzione dell'algoritmo ottimo dei rimpiazzamenti di pagina: ha delle prestazioni ottime non raggiungibili dagli altri algoritmi",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "C-SCAN (Circular SCAN) è una variante di SCAN che tratta il disco come un circolo, permettendo un accesso più uniforme alle tracce ai bordi del disco.",
    "hint": "L'algoritmo C-SCAN deriva da SCAN e serve per evitare favoritismi sulle tracce esterne."
  },
  {
    "question": "Quale delle seguenti affermazioni sul metodo di allocazione contigua dei file è vera? ",
    "options": [
      {
        "text": "È possibile che ci sia frammentazione interna",
        "image": ""
      },
      {
        "text": "La compattazione permette di memorizzare file che altrimenti non potrebbero esserlo (pur essendo la loro dimensione minore di quella dello spazio libero)",
        "image": ""
      },
      {
        "text": "Non è necessaria la preallocazione",
        "image": ""
      },
      {
        "text": "La tabella di allocazione dei file necessita di memorizzare, per ogni file, il solo blocco di partenza",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La compattazione (deframmentazione) riordina i file nel disco rendendo lo spazio contiguo, permettendo così di memorizzare file che altrimenti non potrebbero essere salvati perché il loro spazio è frammentato.",
    "hint": "La compattazione risolve il problema della frammentazione esterna riordinando i blocchi."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla paginazione della memoria è vera? ",
    "options": [
      {
        "text": "Frame e pagine devono avere la stessa dimensione",
        "image": ""
      },
      {
        "text": "Tutte le pagine di un processo dovranno essere, prima o poi, posizionate in un frame",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Soffre del problema della frammentazione interna, e quindi necessita compattazione",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Nella paginazione, le pagine (unità logiche di memoria virtuale) e i frame (unità fisiche di memoria principale) devono avere dimensione identica per permettere un mapping diretto e semplice attraverso la tabella delle pagine.",
    "hint": "Pensa al mapping come a un puzzle: i pezzi (pagine) devono entrare esattamente negli spazi (frame)."
  },
  {
    "question": "Quale delle seguenti affermazioni sul controllo di accesso è vera? ",
    "options": [
      {
        "text": "Nel controllo di accesso basato su ruoli, ad ogni ruolo è assegnato un utente",
        "image": ""
      },
      {
        "text": "Nel controllo di accesso basato su ruoli, prima di stabilire se un'operazione è lecita, è necessario consultare una tabella soggetti-ruoli-oggetti",
        "image": ""
      },
      {
        "text": "Nel controllo di accesso discrezionale, prima di stabilire se un'operazione è lecita, è necessario consultare una tabella soggetti-oggetti",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nel controllo di accesso discrezionale (DAC), i permessi sono definiti direttamente nella relazione soggetto-oggetto: chi possiede una risorsa decide chi può accedervi e con quali modalità.",
    "hint": "Il termine 'discrezionale' indica che è il proprietario a decidere liberamente, senza vincoli esterni."
  },
  {
    "question": "Quale delle seguenti affermazioni è falsa? ",
    "options": [
      {
        "text": "Nel caso delle risorse riusabili, in un grafo dell'allocazione delle risorse ci possono essere più archi tra lo stesso nodo-processo e lo stesso nodo-risorsa",
        "image": ""
      },
      {
        "text": "Nel caso delle risorse riusabili, in un grafo dell'allocazione delle risorse ci possono essere archi sia da nodi-processi a nodi-risorse che viceversa",
        "image": ""
      },
      {
        "text": "Un grafo dell'allocazione delle risorse è un grafo diretto aciclico",
        "image": ""
      },
      {
        "text": "In un grafo dell'allocazione delle risorse, all'interno di un nodo rappresentante una risorsa, c'è un pallino per ogni istanza di quella risorsa",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Un grafo di allocazione delle risorse può contenere cicli: un ciclo indica che un processo attende una risorsa che potrebbe essere detenuta da un altro processo nel ciclo, ma non implica necessariamente deadlock.",
    "hint": "Non confondere la presenza di un ciclo con un deadlock: un ciclo è condizione necessaria ma non sufficiente."
  },
  {
    "question": "Quali delle seguenti affermazioni è vera? ",
    "options": [
      {
        "text": "La confidenzialità di un sistema operativo consiste nel fatto che la shell del sistema operativo deve essere intuitiva e dare del tu agli utenti",
        "image": ""
      },
      {
        "text": "La disponibilità (availability) di un sistema operativo consiste nel fatto che il sistema operativo deve essere sempre pronto a rispondere alle richieste di un utente",
        "image": ""
      },
      {
        "text": "La disponibilità (availability) di un sistema operativo consiste nel fatto che devono esistere delle repository online che permettano sia di installare che di aggiornare il sistema operativo",
        "image": ""
      },
      {
        "text": "La confidenzialità di un sistema operativo consiste nel fatto che il sistema operativo deve essere sempre pronto a rispondere alle richieste di un utente",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La disponibilità (availability) è uno dei tre pilastri della sicurezza informatica (insieme a confidenzialità e integrità) e riguarda la capacità del sistema di rispondere tempestivamente alle richieste legittime degli utenti.",
    "hint": "Pensa alla disponibilità come alla garanzia che un servizio sia raggiungibile quando serve."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla memoria virtuale con paginazione è vera? ",
    "options": [
      {
        "text": "Il difetto principale del prepaging è che potrebbe portare in memoria pagine cui poi non si fa riferimento",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Il difetto principale del paging on demand è che, dopo una prima fase di assestamento, causa molti page fault",
        "image": ""
      },
      {
        "text": "Placement policy e replacement policy sono sinonimi ed indicano lo stesso insieme di metodologie",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il prepagging carica in anticipo pagine che預期potrebbero servire, ma il rischio è portare in memoria pagine che poi non verranno mai referenziate, sprecando tempo I/O e spazio.",
    "hint": "Il prepagging è una scommessa: si prevede cosa servirà, ma si può sbagliare."
  },
  {
    "question": "Quale delle seguenti affermazioni sui dispositivi di memoria di massa è vera? ",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Un settore di un disco magnetico a testina mobile è l'area di una corona circolare del disco stesso",
        "image": ""
      },
      {
        "text": "Una traccia di un disco magnetico a testina mobile è l'area compresa da 2 raggi del disco stesso",
        "image": ""
      },
      {
        "text": "Per selezionare un settore su una traccia di un disco magnetico a testina mobile, è sufficiente posizionare la testina sulla giusta traccia",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "B è falsa perché un settore è uno 'spicchio' del disco (simile a una fetta di torta), non una corona circolare. C è falsa perché una traccia è l'intera corona circolare a una determinata distanza dal centro. D è falsa perché oltre a posizionare la testina sulla traccia corretta, bisogna attendere che il settore desiderato ruoti sotto la testina.",
    "hint": "Distingui tra la forma geometrica di un settore (spicchio) e quella di una traccia (corona circolare)."
  },
  {
    "question": "Quale delle seguenti affermazioni sul process control block è vera? ",
    "options": [
      {
        "text": "Viene salvato nella memoria utente assegnata al processo cui si riferisce",
        "image": ""
      },
      {
        "text": "Contiene tutte le informazioni sui thread del processo cui si riferisce",
        "image": ""
      },
      {
        "text": "Per i processi in modalità blocked, tutte le informazioni che contiene sono cancellate",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "A è falsa perché il PCB risiede nello spazio di indirizzamento del kernel, non nella memoria utente. B è falsa perché i thread hanno i propri TCB (Thread Control Block). C è falsa perché il PCB mantiene tutte le informazioni anche per i processi bloccati, non vengono cancellate.",
    "hint": "Ricorda che il PCB è una struttura dati del kernel che persiste per tutto il ciclo di vita del processo."
  },
  {
    "question": "Quale delle seguenti affermazioni sui semafori per la gestione della concorrenza è falsa? ",
    "options": [
      {
        "text": "Semafori generali e semafori binari hanno lo stesso potere computazionale (ovvero, permettono di risolvere gli stessi problemi)",
        "image": ""
      },
      {
        "text": "Le primitive sui semafori sono in grado di mettere un processo in blocked, senza usare, a tal proposito, il busy-waiting",
        "image": ""
      },
      {
        "text": "Per implementare le primitive sui semafori, servono un contatore ed una coda, che saranno condivisi da tutti i semafori usati",
        "image": ""
      },
      {
        "text": "L'implementazione delle primitive sui semafori è garantita atomica dal sistema operativo",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Ogni semaforo ha il proprio contatore e la propria coda; non sono condivisi tra tutti i semafori. Questo permette a ciascun semaforo di gestire indipendentemente i propri processi in attesa.",
    "hint": "Pensa a come funzionerebbero due semafori indipendenti: servirebbero contatori e code separati."
  },
  {
    "question": "Quale delle seguenti affermazioni sugli algoritmi di scheduling per i dischi è falsa? ",
    "options": [
      {
        "text": "Nell'algoritmo F-SCAN, immediatamente prima che vengano scambiati i contenuti delle code F ed R, la coda F è vuota, mentre la coda R contiene le richieste arrivate mentre si servivano le richieste dentro F",
        "image": ""
      },
      {
        "text": "L'algoritmo Minimum Service Time può portare alla starvation di un processo, che non verrà quindi mai selezionato, se la richiesta era bloccante, per andare in esecuzione sul processore",
        "image": ""
      },
      {
        "text": "L'algoritmo LIFO è il più equo nei confronti dei processi che effettuano le richieste al disco",
        "image": ""
      },
      {
        "text": "Gli algoritmi Minimum Service Time, SCAN, C-SCAN, N-steps-SCAN ed F-SCAN non sono ottimizzati per essere usati su dischi con testine multiple selezionabili elettronicamente",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "LIFO (Last In First Out) non è affatto equo: favorisce solo le richieste più recenti e può causare starvation di quelle più vecchie, che potrebbero non essere mai servite.",
    "hint": "L'equità implica che tutte le richieste abbiano possibilità di essere servite, indipendentemente dall'ordine di arrivo."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sul long-term scheduler è falsa? ",
    "options": [
      {
        "text": "Decide quali processi, tra quelli appena creati, possono essere ammessi in memoria principale per l'esecuzione",
        "image": ""
      },
      {
        "text": "Avendo le necessarie informazioni, una tipica strategia è mantenere una giusta proporzione, stabilita a priori, tra processi I/O-bound e CPU-bound",
        "image": ""
      },
      {
        "text": "Viene chiamato in causa esclusivamente quando viene creato un nuovo processo",
        "image": ""
      },
      {
        "text": "Avendo le necessarie informazioni, una tipica strategia è ammettere in memoria principale i processi che richiedono dispositivi di I/O diversi da quelli richiesti dai processi già attivi",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il long-term scheduler viene chiamato anche quando un processo termina (liberando memoria) o quando il grado di multiprogrammazione scende sotto una soglia, non solo alla creazione di nuovi processi.",
    "hint": "Il long-term scheduler gestisce il grado di multiprogrammazione, non solo l'ingresso di nuovi processi."
  },
  {
    "question": "Quale delle seguenti affermazioni sui metodi di gestione dello spazio libero su disco è vera? ",
    "options": [
      {
        "text": "Se ci sono blocchi da 1kB, e il disco contiene 1TB, l'occupazione dovuta alla lista di blocchi liberi è dell'1%",
        "image": ""
      },
      {
        "text": "Se viene usata la lista di blocchi liberi, tale lista viene interamente mantenuta in memoria principale",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Se viene usata la lista di blocchi liberi, c'è un overhead di spazio, contrariamente alla concatenazione di blocchi liberi",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La lista di blocchi liberi (free list) memorizza esplicitamente l'indirizzo di ogni blocco libero, occupando spazio su disco. La concatenazione (linked list di blocchi liberi) invece usa gli stessi blocchi liberi per collegarsi tra loro, senza overhead aggiuntivo.",
    "hint": "Ricorda la differenza tra memorizzare puntatori espliciti e usare i blocchi liberi stessi come puntatori."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla memoria cache è vera? ",
    "options": [
      {
        "text": "La memoria cache è direttamente indirizzabile in assembler",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "È possibile che, in un dato istante, la cache e la memoria RAM non siano coerenti tra loro",
        "image": ""
      },
      {
        "text": "L'algoritmo di rimpiazzamento per la cache stabilisce quale blocco di RAM deve essere sostituito da un blocco di cache",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nel meccanismo di write-back, le scritture in cache non vengono immediatamente propagate in RAM; la cache può contenere dati più recenti (sporchi) rispetto alla memoria principale, causando incoerenza temporanea.",
    "hint": "Pensa a cosa succede quando scrivi in cache ma non ancora in RAM nel write-back."
  },
  {
    "question": "Quale delle seguenti affermazioni sui problemi dei produttori/consumatori e dei lettori/scrittori, nelle accezioni viste a lezione, è vera? ",
    "options": [
      {
        "text": "Per il problema dei produttori/consumatori, non deve essere mai possibile che più consumatori accedano contemporaneamente al buffer, mentre nel problema dei lettori/scrittori deve sempre possibile che più lettori, in assenza di scrittori, accedano all'area di memoria",
        "image": ""
      },
      {
        "text": "Per il problema dei produttori/consumatori, non deve essere mai possibile che più produttori accedano contemporaneamente al buffer, mentre nel problema dei lettori/scrittori deve essere sempre possibile che più scrittori (in assenza di lettori) accedano all'area di memoria",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Per il problema dei produttori/consumatori, deve essere sempre possibile che più consumatori accedano contemporaneamente al buffer, mentre nel problema dei lettori/scrittori non deve essere mai possibile che più scrittori accedano all'area di memoria",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Nel problema produttori/consumatori il buffer è una risorsa critica che richiede mutua esclusione: solo un consumatore alla volta può prelevare. Nel problema lettori/scrittori, i lettori possono accedere simultaneamente perché non modificano i dati, mentre gli scrittori necessitano di accesso esclusivo.",
    "hint": "Ricorda che i lettori non modificano i dati, quindi possono coesistere; i consumatori invece modificano il buffer (lo svuotano)."
  },
  {
    "question": "Quale delle seguenti affermazioni sui (vecchi) metodi per il partizionamento della memoria è vera? ",
    "options": [
      {
        "text": "Con il partizionamento fisso, le partizioni devono avere tutte la stessa dimensione",
        "image": ""
      },
      {
        "text": "Con il buddy system, ogni indirizzo di memoria può ricadere in 2 porzioni",
        "image": ""
      },
      {
        "text": "Con il partizionamento fisso, ci possono essere al massimo N processi attivi (ovvero, accettati per l'esecuzione), dove N è il numero di partizioni",
        "image": ""
      },
      {
        "text": "Con il partizionamento dinamico, si manifesta il problema della frammentazione esterna",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Nel partizionamento dinamico (variabile) la memoria viene allocata su richiesta esatta, ma quando i processi terminano si creano buchi tra partizioni cariche. Questi buchi sparsi non contigui costituiscono la frammentazione esterna, che non può essere usata per allocare nuovi processi.",
    "hint": "La frammentazione esterna deriva da spazi liberi non contigui che non possono soddisfare richieste di memoria contigua."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sulla preemption è vera? ",
    "options": [
      {
        "text": "Se uno scheduler è preemptive e vi è più di 1 processo ready, non è possibile che un processo monopolizzi il processore",
        "image": ""
      },
      {
        "text": "Per avere un trattamento equo sui processi, è sufficiente usare uno scheduler preemptive",
        "image": ""
      },
      {
        "text": "Se uno scheduler è non-preemptive, permette sempre ai suoi processi di essere eseguiti senza interruzioni sul processore fino al loro completamento",
        "image": ""
      },
      {
        "text": "Se uno scheduler è non-preemptive, è possibile che un processo monopolizzi il processore, anche in presenza di altri processi ready",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Uno scheduler non-preemptive (cooperativo) non può interrompere un processo in esecuzione nemmeno se ci sono altri processi pronti. Il processo tiene la CPU fino a quando non si blocca volontariamente o termina, potenzialmente monopolizzando il processore.",
    "hint": "In uno scheduler non-preemptive, solo il processo stesso può rilasciare la CPU."
  },
  {
    "question": "Nel modello dei processi a 5 stati, quali delle seguenti transizioni non è possibile? ",
    "options": [
      {
        "text": "Blocked == Running",
        "image": ""
      },
      {
        "text": "Running == Ready",
        "image": ""
      },
      {
        "text": "Blocked == Exit",
        "image": ""
      },
      {
        "text": "Blocked == Ready",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Nel modello a 5 stati, un processo nello stato Blocked non può passare direttamente allo stato Running perché deve prima tornare nello stato Ready (quando l'evento che lo bloccava si verifica), e solo lo scheduler può portarlo da Ready a Running.",
    "hint": "Ricorda che da Blocked si può andare solo a Ready, non direttamente a Running."
  },
  {
    "question": "Quale delle seguenti affermazioni sul metodo di allocazione indicizzata dei file è vera? ",
    "options": [
      {
        "text": "Il consolidamento permette sempre di ridurre la dimensione dell'indice",
        "image": ""
      },
      {
        "text": "Se usato con porzioni di dimensione variabile, i blocchi indice devono contenere anche la lunghezza di ogni porzione",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Non c'è modo per il sistema operativo di distinguere tra blocchi con dati e blocchi con indici",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Nell'allocazione indicizzata con porzioni di dimensione variabile, ogni entry dell'indice deve contenere non solo il puntatore al blocco dati ma anche la lunghezza della porzione, poiché il sistema deve sapere quanti byte leggere per ciascuna porzione.",
    "hint": "Con porzioni variabili, come facciamo a sapere quanto leggere da ciascun blocco?"
  },
  {
    "question": "Quale delle seguenti affermazioni sul requisito di rilocazione nella gestione della memoria è vera? ",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Se viene realizzato tramite sostituzione degli indirizzi nel programma sorgente (al momento della creazione del processo), allora il relativo processo dovrà cominciare sempre allo stesso indirizzo; tale indirizzo dovrà essere uguale per tutti i processi",
        "image": ""
      },
      {
        "text": "Se viene realizzato tramite sostituzione degli indirizzi nel programma sorgente (al momento della creazione del processo), allora il relativo processo potrà trovarsi in diverse posizioni della memoria in diversi momenti del sua esecuzione",
        "image": ""
      },
      {
        "text": "Se viene realizzato tramite sostituzione degli indirizzi nel programma sorgente (al momento della creazione del processo), serve hardware speciale",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La rilocazione tramite sostituzione nel programma sorgente (loadtime) produce indirizzi assoluti fissi a compile-time, quindi il processo deve sempre caricarsi allo stesso indirizzo; nessuna delle altre opzioni descrive correttamente questo meccanismo.",
    "hint": "Se sostituisco gli indirizzi nel sorgente, questi diventano fissi o rimangono relativi?"
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sulla preemption è vera?",
    "options": [
      {
        "text": "Se uno scheduler è non-preemptive, permette sempre ai suoi processi di essere eseguiti sul processore, senza interruzioni, fino al loro completamento",
        "image": ""
      },
      {
        "text": "Se uno scheduler è non-preemptive, è possibile che un processo monopolizzi il processore, anche in presenza di altri processi ready",
        "image": ""
      },
      {
        "text": "Se uno scheduler è preemptive, non è possibile che un processo monopolizzi il processore, anche in presenza di altri processi ready",
        "image": ""
      },
      {
        "text": "Per avere un trattamento equo sui processi, è sufficiente usare uno scheduler preemptive",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Uno scheduler non-preemptive non interrompe un processo in esecuzione, quindi un processo CPU-bound può terminare il suo quanto di tempo naturale (o l'intero burst) prima di cedere il processore, monopolizzandolo anche con altri processi ready.",
    "hint": "Cosa succede se un processo CPU-bound ha un burst lungo in uno scheduler che non preemptiona?"
  },
  {
    "question": "Quale dei seguenti requisiti deve soddisfare un meccanismo che offra la mutua esclusione? ",
    "options": [
      {
        "text": "Non deve essere fatta alcuna assunzione sulla velocità di esecuzione dei processi coinvolti",
        "image": ""
      },
      {
        "text": "Se un processo non fa richiesta di entrare nella sezione critica, deve comunque sincronizzarsi all'esecuzione degli altri processi",
        "image": ""
      },
      {
        "text": "Se un processo è nella sezione critica, occorre che rilasci subito la sezione critica stessa",
        "image": ""
      },
      {
        "text": "Se un processo fa richiesta di entrare nella sezione critica, deve poter entrare subito nella sezione critica stessa",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Un meccanismo corretto di mutua esclusione deve funzionare indipendentemente dalle velocità relative dei processi, poiché non si può assumere nulla sulla loro temporizzazione in un sistema reale.",
    "hint": "Il meccanismo deve funzionare anche se un processo è infinitamente più lento di un altro?"
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sul dispatcher è falsa? ",
    "options": [
      {
        "text": "Il resource balancing è un criterio di sistema non prestazionale",
        "image": ""
      },
      {
        "text": "Il rispetto delle deadline è un criterio utente prestazionale",
        "image": ""
      },
      {
        "text": "Il throughput è un criterio di sistema prestazionale",
        "image": ""
      },
      {
        "text": "La predictability è un criterio utente prestazionale",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La predictibility (prevedibilità) è un criterio di sistema, non utente. I criteri di sistema misurano le prestazioni complessive del sistema (throughput, utilizzo CPU), mentre i criteri utente riguardano l'esperienza del singolo utente (tempo di risposta, deadline).",
    "hint": "Ricorda la distinzione tra criteri di sistema (qualità del servizio globale) e criteri utente (qualità percepita dal singolo utente)."
  },
  {
    "question": "Quale delle seguenti affermazioni sugli interrupt (o eccezioni) è falsa? ",
    "options": [
      {
        "text": "Devono essere gestiti da opportuno software di sistema",
        "image": ""
      },
      {
        "text": "Una volta gestito l'interrupt o l'eccezione, quando (e se) si torna ad eseguire il processo interrotto, l'esecuzione ripartirà sempre dall'istruzione successiva a quella dove è stato ricevuto l'interrupt o l'eccezione",
        "image": ""
      },
      {
        "text": "Normalmente, non vengono gestiti dal programmatore dell'applicazione che li ha causati",
        "image": ""
      },
      {
        "text": "Possono essere creati direttamente dai dispositivi di I/O",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Per le eccezioni di tipo fault (come page fault o division by zero), dopo la gestione si ritorna a ripetere l'istruzione che ha causato l'eccezione, non l'istruzione successiva. Questo è fondamentale per permettere alla condizione di essere risolta e ritentare l'operazione.",
    "hint": "Ricorda la differenza tra interrupt (si riparte dall'istruzione successiva) e fault (si ritenta l'istruzione che ha causato l'eccezione)."
  },
  {
    "question": "Quale delle seguenti affermazioni sulle istruzioni macchina speciali per la gestione della concorrenza è vera? ",
    "options": [
      {
        "text": "Sono basate sul busy-waiting, ovvero sul fatto che un processo si mette autonomamente in stato blocked",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Non riescono ad evitare il manifestarsi del deadlock, a meno che non sia presente un sistema a priorità",
        "image": ""
      },
      {
        "text": "Come per la disabilitazione delle interruzioni, non funzionano per architetture con più processori o core",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Le istruzioni macchina speciali (test-and-set, compare-and-swap) non usano busy-waiting ma meccanismi atomici hardware, riescono a prevenire il deadlock con algoritmi giusti, e funzionano anche su multiprocessore tramite atomici hardware.",
    "hint": "Le istruzioni atomiche hardware sono la base per costruire lock e semafori senza busy-waiting."
  },
  {
    "question": "Quale delle seguenti affermazioni sui processi è vera? ",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Per la terminazione normale di un processo, è tipicamente prevista un'apposita system call, come ad esempio exit",
        "image": ""
      },
      {
        "text": "Un processo può morire quando si effettua il process spawning",
        "image": ""
      },
      {
        "text": "Un processo può essere creato dal modulo di gestione della memoria per gestire la traduzione da indirizzi virtuali a fisici",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La system call exit (o return in main) è il meccanismo standard per la terminazione normale di un processo in tutti i sistemi operativi Unix-like e Windows, permettendo al processo di restituire un exit code e liberare le risorse.",
    "hint": "Il process spawning crea nuovi processi, non li fa morire; la memoria non crea processi."
  },
  {
    "question": "Quale delle seguenti affermazioni è falsa? ",
    "options": [
      {
        "text": "Nel caso di un sistema operativo a kernel separato, la gestione dei process switch è a sua volta un processo",
        "image": ""
      },
      {
        "text": "Nel caso di un sistema operativo in cui le funzioni del sistema operativo vengono eseguite all'interno dei processi utente, non c'è bisogno di un process switch per eseguire una funzionalità del sistema operativo",
        "image": ""
      },
      {
        "text": "Nel caso di un sistema operativo in cui le funzioni del sistema operativo vengono eseguite all'interno dei processi utente, se un processo effettua una syscall e poi può continuare ad essere eseguito, non avviene alcun process switch",
        "image": ""
      },
      {
        "text": "Nel caso di un sistema operativo in cui le funzioni del sistema operativo vengono eseguite come processi separati, c'è sempre bisogno di un process switch per eseguire una funzionalità del sistema operativo",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La gestione del process switch nel kernel separato NON è un processo, ma viene eseguita direttamente dal kernel (modalità kernel) senza creare un nuovo processo. Il process switch è un'operazione del kernel, non un processo.",
    "hint": "Il process switch è una funzione del kernel eseguita in modalità sistema, non un processo separato."
  },
  {
    "question": "Quale delle seguenti affermazioni sul metodo di allocazione concatenata dei file è vera? ",
    "options": [
      {
        "text": "Il consolidamento permette di memorizzare file che altrimenti non potrebbero esserlo (pur essendo la loro dimensione minore di quella dello spazio libero)",
        "image": ""
      },
      {
        "text": "La tabella di allocazione dei file deve contenere l'intera catena",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Viene usato con porzioni di dimensione variabile, ma piccola",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nell'allocazione concatenata non esiste una tabella di allocazione: i blocchi sono collegati sequenzialmente tramite puntatori contenuti nei blocchi stessi. Il consolidamento (compaction) serve a unire blocchi liberi contigui, non a memorizzare file più grandi. L'allocazione concatenata usa porzioni a dimensione fissa (blocchi), non variabile.",
    "hint": "Ricorda che nell'allocazione concatenata i puntatori sono nei blocchi, non in una tabella esterna."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla memoria virtuale con paginazione è vera? ",
    "options": [
      {
        "text": "Nel caso di una tabella delle pagine a 2 livelli, viene tipicamente richiesto che tutte le tabelle delle pagine di secondo livello entrino in una pagina",
        "image": ""
      },
      {
        "text": "Il numero di bit di un indirizzo virtuale è necessariamente diverso a seconda che si usi una tabella delle pagine ad 1 o a 2 livelli",
        "image": ""
      },
      {
        "text": "Il numero di bit di una entry di una tabella delle pagine di ultimo livello è uguale al numero di bit di controllo più il logaritmo (arrotondato all'intero superiore) del massimo numero di frame in memoria principale",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Nella paginazione a 2 livelli, si cerca tipicamente di far entrare ogni tabella di secondo livello in una singola pagina fisica: questo evita di dover aggiungere ulteriori livelli di indirezione e semplifica la gestione della memoria.",
    "hint": "Pensa a come il design delle tabelle a 2 livelli minimizzi i page fault durante la traduzione degli indirizzi."
  },
  {
    "question": "Quale delle seguenti affermazioni sul deadlock è falsa? ",
    "options": [
      {
        "text": "Affinchè ci sia un deadlock, sono necessarie le condizioni di attesa circolare, hold-and-wait, mutua esclusione e no preemption",
        "image": ""
      },
      {
        "text": "Per prevenire il deadlock, è necessario cercare di impedire almeno una delle 3 condizioni di mutua esclusione, hold-and-wait e no preemption",
        "image": ""
      },
      {
        "text": "Affinchè il deadlock sia possibile, sono necessarie le condizioni di mutua esclusione, hold-and-wait e no preemption",
        "image": ""
      },
      {
        "text": "Per prevenire il deadlock impedendo l'hold-and-wait, si può in alcuni casi imporre ai processi di richiedere tutte le risorse fin dall'inizio",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Per prevenire il deadlock basta impedire UNA qualsiasi delle 4 condizioni (non 3). In particolare, la mutua esclusione non può essere impedita per molte risorse (es. stampanti), quindi si agisce sulle altre tre.",
    "hint": "Ricorda: Coffman ha identificato 4 condizioni necessarie, ma per prevenirne uno basta bloccarne una sola."
  },
  {
    "question": "Quale delle seguenti affermazioni è vera? ",
    "options": [
      {
        "text": "La modalità di un processo utente è sempre la modalità di sistema",
        "image": ""
      },
      {
        "text": "La modalità di un processo utente è inizialmente la modalità utente; può diventare modalità sistema nel momento in cui va in esecuzione il dispatcher",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "La modalità di un processo utente è sempre la modalità utente",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La modalità di un processo utente cambia durante l'esecuzione: passa da utente a sistema quando avviene un sistema call o interrupt, e il dispatcher gira anch'esso in modalità sistema (kernel). Quindi né 'sempre utente' né 'sempre sistema' sono corretti.",
    "hint": "Pensa a cosa succede quando un processo utente fa una system call."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla memoria virtuale con paginazione è vera? ",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Per ogni processo, il resident set contiene lo stesso numero di pagine",
        "image": ""
      },
      {
        "text": "Un tipico algoritmo per il replacement scope è quello dell'orologio",
        "image": ""
      },
      {
        "text": "La gestione del resident set tramite politica dinamica mira ad ampliare il numero di pagine di un processo durante l'esecuzione del processo stesso",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "B) Falso: il resident set varia dinamicamente. C) Falso: l'algoritmo dell'orologio è per page replacement, non per replacement scope. D) Falso: la politica dinamica mira a mantenere il numero ottimale di pagine, non necessariamente ad ampliare.",
    "hint": "Ricorda la differenza tra resident set (pagine caricate) e working set (pagine usate attivamente)."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sul dispatcher è falsa?",
    "options": [
      {
        "text": "Il response time è un criterio utente prestazionale",
        "image": ""
      },
      {
        "text": "Il turnaround time (normalizzato o no) è un criterio utente prestazionale",
        "image": ""
      },
      {
        "text": "Il throughput è un criterio di sistema non prestazionale",
        "image": ""
      },
      {
        "text": "La fairness è un criterio di sistema non prestazionale",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il throughput misura il numero di processi completati per unità di tempo (es. processi/secondo) ed è un criterio di sistema che valuta le prestazioni complessive del dispatcher.",
    "hint": "Il throughput indica l'efficienza del sistema nel completare lavoro, quindi è un criterio prestazionale."
  },
  {
    "question": "Quale delle seguenti affermazioni è falsa?",
    "options": [
      {
        "text": "Diversi thread di uno stesso processo condividono lo stesso thread identifier",
        "image": ""
      },
      {
        "text": "Tra le funzioni di sistema per i thread, è tipicamente prevista una funzione per bloccare e sbloccare esplicitamente i thread stessi",
        "image": ""
      },
      {
        "text": "Diversi thread di uno stesso processo condividono lo stesso process identifier",
        "image": ""
      },
      {
        "text": "Diversi thread di uno stesso processo condividono i file aperti",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Ogni thread ha un proprio thread identifier (TID) univoco che lo distingue dagli altri thread dello stesso processo, mentre il process identifier (PID) è condiviso.",
    "hint": "Il PID identifica il processo, mentre ogni thread ha un proprio identificativo univoco."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla page cache è falsa?",
    "options": [
      {
        "text": "Nell'algoritmo di sostituzione basato su frequenza a 3 segmenti della page cache, i contatori vengono sempre incrementati, tranne quando sono nel segmento vecchio",
        "image": ""
      },
      {
        "text": "Nell'algoritmo di sostituzione basato su frequenza a 3 segmenti della page cache, i settori che possono essere sostituiti sono solo quelli del segmento vecchio",
        "image": ""
      },
      {
        "text": "Nell'algoritmo di sostituzione basato su frequenza a 3 segmenti della page cache, l'unico segmento in cui i contatori non vengono incrementati e i settori non possono essere sostituti è quello nuovo",
        "image": ""
      },
      {
        "text": "L'algoritmo di sostituzione basato su frequenza a 3 segmenti della page cache può avere buone performance anche quando dei settori vengono acceduti spesso, ma tra il primo accesso e quelli successivi ci sono molti altri accessi ad altri settori",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Nell'algoritmo ARC a 3 segmenti, i contatori NON vengono incrementati quando le pagine sono nel segmento vecchio (oldest), mentre vengono incrementati quando sono nei segmenti new e middle.",
    "hint": "Nel segmento oldest i contatori non vengono modificati per evitare di favorire eccessivamente pagine mantenute a lungo."
  },
  {
    "question": "Quali delle seguenti affermazioni sulla efficienza di un sistema operativo è falsa?",
    "options": [
      {
        "text": "Deve minimizzare il tempo di risposta, tenendo presenti eventuali priorità",
        "image": ""
      },
      {
        "text": "Deve servire il maggior numero di utenti possibile, tenendo presenti eventuali livelli di accesso",
        "image": ""
      },
      {
        "text": "Deve dare accesso alle risorse in modo equo ed egualitario tra tutti i processi",
        "image": ""
      },
      {
        "text": "Deve massimizzare l'uso delle risorse per unità di tempo, tenendo presenti eventuali priorità",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'accesso equo non significa egualitario: un sistema operativo deve rispettare le priorità e può assegnare più risorse a processi con priorità maggiore.",
    "hint": "Le priorità dei processi influenzano l'allocazione delle risorse."
  },
  {
    "question": "Si consideri una unità disco con una velocità di rotazione di R rivoluzioni al minuto (rpm). La testina, per spostarsi da una traccia alla successiva, impiega un tempo trascurabile. Ogni traccia del disco contiene T kB. Si assuma che una porzione di dimensione P kB di un file sia memorizzata sul disco in settori contigui. Stimare il tempo totale, in secondi, necessario per il trasferimento di questi P kB di dati dal disco in memoria principale, nel caso in cui la testina sia già posizionata sul settore di partenza.",
    "options": [
      {
        "text": "P/(T*R/60)",
        "image": ""
      },
      {
        "text": "T*(R/60)/P",
        "image": ""
      },
      {
        "text": "T/(P*R/60)",
        "image": ""
      },
      {
        "text": "P*R/60",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La velocità di trasferimento è T kB per ogni rotazione, e con R rpm la velocità è T*R/60 kB/s. Dividendo P per questa velocità si ottiene il tempo totale.",
    "hint": "Calcola prima la velocità di trasferimento in kB/s, poi dividi i dati da trasferire per questa velocità."
  },
  {
    "question": "Un sistema con gestione paginata semplice della memoria ha indirizzi di B bit e pagine di dimensione P kB. Se tutta la memoria è paginabile, qual è il numero massimo di elementi contenuti nella tabella delle pagine di un processo?",
    "options": [
      {
        "text": "P/B",
        "image": ""
      },
      {
        "text": "P*1024/2B",
        "image": ""
      },
      {
        "text": "2^B/(P*1024)",
        "image": ""
      },
      {
        "text": "B/P",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il numero di voci nella tabella delle pagine corrisponde al numero di pagine logiche che un processo può avere, calcolato come spazio degli indirizzi (2^B byte) diviso per la dimensione di ogni pagina (P*1024 byte).",
    "hint": "La tabella delle pagine ha una voce per ogni pagina logica del processo."
  },
  {
    "question": "Si consideri la seguente soluzione (sbagliata) al problema della mutua esclusione tra processi: ",
    "options": [
      {
        "text": "Assumendo che il dispatcher, prima o poi, dia l'opportunità di andare in esecuzione a tutti i processi coinvolti, è comunque possibile la starvation (rispetto all'entrata nella sezione critica)",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Supponendo che ci siano 2 processi, se lo scheduler permette a P(0) di arrivare fino ad assegnare 1 a bolt, allora il requisito base della mutua esclusione (sul numero massimo di processi nella sezione critica) è rispettato",
        "image": ""
      },
      {
        "text": "Sono possibili deadlock",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "int bolt = 0;\r\nvoid P(int i)\r\n    while (bolt == 1) /* do nothing */;\r\n    bolt = 1;\r\n    /* critical section */;\r\n    bolt = 0;\r\n    /* remainder */;",
    "explanation": "Con bolt inizializzato a 0, se entrambi i processi controllano bolt prima che uno possa assegnare 1, entrambi escono dal ciclo while e possono accedere alla sezione critica contemporaneamente, causando potenziale deadlock o violazione della mutua esclusione.",
    "hint": "Il problema è la race condition tra il controllo e l'assegnazione di bolt."
  },
  {
    "question": "Si consideri il seguente modo di implementare la mutua esclusione:",
    "options": [
      {
        "text": "La soluzione implementa correttamente la mutua esclusione solo se si disabilitano le interruzioni prima di chiamare P",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "La soluzione non implementa correttamente la mutua esclusione perché bisogna chiamare exchange invece di compare_and_swap",
        "image": ""
      },
      {
        "text": "La soluzione non implementa correttamente la mutua esclusione",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "int bolt = 1;\r\nvoid P(int i)\r\n    while(true)\r\n      while (compare_and_swap(bolt, 1, 0) == 0) ;\r\n      critical_section();\r\n      bolt = 1;",
    "explanation": "compare_and_swap atomico garantisce mutua esclusione: solo un processo può entrare quando bolt passa da 1 a 0. Le altre affermazioni sono false perché non serve disabilitare interruzioni né usare exchange.",
    "hint": "L'atomicità di compare_and_swap garantisce la mutua esclusione."
  },
  {
    "question": "Si consideri la seguente soluzione al problema della mutua esclusione tra processi: ",
    "options": [
      {
        "text": "Il requisito base della mutua esclusione (sul numero massimo di processi nella sezione critica) è rispettato",
        "image": ""
      },
      {
        "text": "È certo il deadlock",
        "image": ""
      },
      {
        "text": "Se si scambiano le chiamate semWait e semSignal, il requisito base della mutua esclusione (sul numero massimo di processi in sezione critica) non è rispettato",
        "image": ""
      },
      {
        "text": "Se si elimina la chiamata a semWait, il requisito base della mutua esclusione (sul numero massimo di processi nella sezione critica) è rispettato",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "semaphore s = 0;\r\nvoid P(int i)\r\n    semWait(s);\r\n    /* critical section */;\r\n    semSignal(s);\r\n    /* remainder */;",
    "explanation": "Con semaforo inizializzato a 0, il primo processo che arriva si blocca su semWait. Eliminando semWait, tutti i processi entrano liberamente nella sezione critica, rispettando implicitamente il requisito di(mutua esclusione in senso lato, anche se non c'è sincronizzazione).",
    "hint": "Il semaforo a 0 blocca subito il primo processo."
  },
  {
    "question": "I seguenti due processi concorrenti condividono una variabile: ",
    "options": [
      {
        "text": "N*2 + 1, 2*(N + 1), N + 1",
        "image": ""
      },
      {
        "text": "N*2 + 1, 2*(N + 1), N*2",
        "image": ""
      },
      {
        "text": "N*2 + 1, 2*(N + 1)",
        "image": ""
      },
      {
        "text": "N*2 + 1, 2*(N + 1), N + 1, N*2",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "semaphore S = 1;\r\nint X = N;\r\n\r\n[Process 1]             [Process 2]\r\n    int Y;                       int Z;\r\n    semWait(S);          semWait(S);    \r\n    Y = X*2;                  Z = X+1;\r\n    X = Y;                      X = Z;\r\n    semSignal(S);       semSignal(S); ",
    "explanation": "Analizzando tutti gli interleaving possibili, i valori finali di X sono N*2+1 (se P1 legge per primo e P2 scrive) o 2*(N+1) (se P2 legge per primo e P1 scrive). I valori N+1 e N*2 sono solo transitori.",
    "hint": "Considera tutti gli ordini possibili di lettura e scrittura."
  },
  {
    "question": "I seguenti tre processi concorrenti condividono due semafori: ",
    "options": [
      {
        "text": "0",
        "image": ""
      },
      {
        "text": "3",
        "image": ""
      },
      {
        "text": "Infinito",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "semaphore U = 3; \r\nsemaphore V = 0;\r\n\r\n[Process 1]                      [Process 2]                        [Process 3]\r\n  while(1)                           while(1)                              while(1)  \r\n        semWait(U);                     semWait(V);                       semWait(V);\r\n        print(\"A\");                          print(\"B\");                             print(\"C\");\r\n        semSignal(V);                  semSignal(V);\r\n",
    "explanation": "Il sistema non può proseguire indefinitamente: dopo 3 esecuzioni di Process 1, il semaforo U reaches 0 e Process 1 si blocca. Process 2 e 3 possono alternarsi grazie a V, ma non possono riaprire U. Quindi il sistema si blocca dopo un numero finito di passi, ma non può nemmeno esaurirsi completamente poiché Process 2 e 3 possono ancora alternarsi. Nessuna delle opzioni (0, 3, infinito) descrive correttamente questo comportamento.",
    "hint": "Traccia l'evoluzione dei semafori: U parte da 3 e viene decrementato da Process 1, V parte da 0 e viene incrementato/decrementato."
  },
  {
    "question": "Si consideri la seguente soluzione al problema della mutua esclusione tra processi: ",
    "options": [
      {
        "text": "Se n = 1, non c'è deadlock ",
        "image": ""
      },
      {
        "text": "Se n > 1, non c'è deadlock ",
        "image": ""
      },
      {
        "text": "Il requisito base della mutua esclusione (sul numero massimo di processi nella sezione critica) è rispettato ",
        "image": ""
      },
      {
        "text": "Almeno un requisito della mutua esclusione non è rispettato ",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "const message null = /* null message */; \r\nmailbox box;\r\nvoid P(int i) { \r\n     message msg;\r\n     while (true) {\r\n          receive(box, msg);\r\n          /* critical section */;  \r\n          send(box, msg);\r\n          /* remainder */;  } }\r\n\r\nvoid main() {\r\n     box = create_mailbox();\r\n     nbsend(box, null);\r\n     parbegin (P(1), P(2), . . ., P(n));  }",
    "explanation": "Con un solo processo (n=1), non può verificarsi deadlock perché non c'è competizione: l'unico processo può sempre ricevere il messaggio, eseguire la sezione critica e rimandare il messaggio. Con più processi, due processi potrebbero bloccarsi entrambi in receive aspettando un messaggio.",
    "hint": "Analizza cosa succede quando n=1 vs quando n>1, in particolare il comportamento della receive."
  },
  {
    "question": "Si consideri la soluzione al problema del produttore/consumatore che usa lo scambio messaggi vista a lezione. Quale delle seguenti affermazioni è vera?",
    "options": [
      {
        "text": "Assumendo che non ci siano errori in precedenza, è possibile che 2 produttori tentino di immettere contemporaneamente 2 diversi prodotti nello stesso slot del buffer",
        "image": ""
      },
      {
        "text": "Assumendo che non ci siano errori in precedenza, è possibile che un consumatore tenti di prelevare un prodotto dal buffer quando quest'ultimo è vuoto",
        "image": ""
      },
      {
        "text": "Assumendo che non ci siano errori in precedenza, è possibile che un produttore tenti di immettere un prodotto nel buffer quando quest'ultimo è pieno",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "const int capacity = /* buffering capacity */ ;\r\n           mailbox mayproduce, mayconsume;\r\n    \r\n     void main() {\r\n         mayproduce = create_mailbox(),\r\n         mayconsume = create_mailbox();\r\n         for (int i = 1; i <= capacity; i++)\r\n              nbsend (mayproduce,null);\r\n         parbegin (producer,consumer); }\r\n    \r\n    void producer() {\r\n         message pmsg;\r\n         while (true) {\r\n           receive (mayproduce,pmsg);\r\n           pmsg = produce(); /* fa anche append */\r\n           nbsend (mayconsume,pmsg);  } }\r\n    \r\n    void consumer() {\r\n         message cmsg;\r\n         while (true) {\r\n           receive (mayconsume,cmsg);\r\n           consume (cmsg); /* fa anche take */\r\n           nbsend (mayproduce,null);  } }",
    "explanation": "Il codice usa nbsend (send non bloccante), quindi non c'è sincronizzazione tra l'invio del messaggio e la ricezione effettiva. Due produttori potrebbero ricevere entrambi 'mayproduce' (conoscendo che c'è uno slot disponibile), produrre due oggetti diversi, e poi inviare entrambi a 'mayconsume' contemporaneamente - ma il buffer ha un solo slot per ogni messaggio ricevuto.",
    "hint": "nbsend non garantisce che il ricevente abbia effettivamente completato la receive."
  },
  {
    "question": "Considerare un insieme di cinque processi P1, P2, P3, P4, P5 con i seguenti tempi di arrivo e tempi di esecuzione in millisecondi. Quale delle seguenti affermazioni è falsa?",
    "options": [
      {
        "text": "Non ci sono sufficienti informazioni per determinare come si comporterebbe l'algoritmo di scheduling a feedback classico di Unix",
        "image": ""
      },
      {
        "text": "Non ci sono sufficienti informazioni per determinare come si comporterebbe l'algoritmo di scheduling Virtual Round-Robin",
        "image": ""
      },
      {
        "text": "Non ci sono sufficienti informazioni per determinare come si comporterebbe l'algoritmo di scheduling Round-Robin",
        "image": ""
      },
      {
        "text": "Non ci sono sufficienti informazioni per determinare come si comporterebbe l'algoritmo di scheduling SRT",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "Processo    Tempo di Arrivo Tempo di Esecuzione\r\nP1  0   14\r\nP2  8   16\r\nP3  5   3\r\nP4  11  7\r\nP5  17  9\r\n",
    "explanation": "Per l'algoritmo SRT (Shortest Remaining Time), che è un algoritmo preemptive shortest job first, abbiamo tutti i dati necessari: i tempi di arrivo e i tempi di esecuzione. Gli altri algoritmi (Unix feedback, Virtual Round-Robin, Round-Robin) richiedono informazioni aggiuntive come quantum, priorità iniziale, o politiche di boosting.",
    "hint": "Quale algoritmo richiede solo tempi di arrivo e burst per essere determinato?"
  },
  {
    "question": "Considerare un insieme di cinque processi P1, P2, P3, P4, P5 con i seguenti tempi di arrivo e tempi di esecuzione in millisecondi. Quale delle seguenti affermazioni è falsa?",
    "options": [
      {
        "text": "Gli unici 2 processi che non sono serviti subito (ovvero, appena arrivati) sono P3 e P5",
        "image": ""
      },
      {
        "text": "Il tempo medio di attesa è tra 10 ed 11 ms",
        "image": ""
      },
      {
        "text": "Il processo con il più lungo tempo di attesa è P1",
        "image": ""
      },
      {
        "text": "Il tempo medio di turnaround è tra 2 e 3 ms ",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "Processo    Tempo di Arrivo Tempo di Esecuzione\r\nP1  0   14\r\nP2  8   16\r\nP3  5   3\r\nP4  11  7\r\nP5  17  9\r\n",
    "explanation": "Con FCFS (first-come-first-served), P3 arriva a 5 ma viene servito dopo P1 che era già in esecuzione, quindi non viene servito 'subito' all'arrivo. Analogamente P4 arriva a 11 e viene servito dopo P2. Quindi i processi non serviti subito sono P3 e P4, non P3 e P5.",
    "hint": "Traccia l'ordine di esecuzione con FCFS: chi viene eseguito quando arrivano nuovi processi?"
  },
  {
    "question": "Quale delle seguenti affermazioni, riguardanti il joint progress diagram di 2 processi, è vera? ",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Può essere usato per visualizzare le possibilità di deadlock, ma solo se i processi richiedono al massimo 2 risorse",
        "image": ""
      },
      {
        "text": "Può essere usato per determinare quando uno dei due processi va in esecuzione a discapito dell'altro",
        "image": ""
      },
      {
        "text": "Può essere usato per determinare quando uno dei due processi sperimenta un page fault",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il joint progress diagram è uno strumento teorico per analizzare l'interazione tra processi, specificamente per individuare regioni di unsafe execution dove può verificarsi deadlock. Non ha limitazioni sul numero di risorse (B è falsa), non determina scheduling (C è falsa) e non è correlato a page fault (D è falsa).",
    "hint": "Ricorda che il joint progress diagram serve per analizzare unsafe regions, non per scheduling o fault."
  },
  {
    "question": "Quale delle seguenti affermazioni sui dispositivi di I/O è vera? ",
    "options": [
      {
        "text": "Il data rate confronta le velocità di trasferimento dati tra 2 diversi dispositivi di I/O",
        "image": ""
      },
      {
        "text": "Ciascun dispositivo di I/O può essere usato solo da un ben determinato tipo di applicazioni",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Tutti i dispositivi di I/O scambiano informazioni con la CPU in blocchi, per motivi di efficienza",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Le affermazioni A, B e D sono tutte false. Il data rate è la velocità di un singolo dispositivo, non un confronto (A). I dispositivi I/O non sono limitati a un tipo di applicazione (B). Non tutti i dispositivi trasferiscono in blocchi (es. tastiera invia caratteri singoli) (D).",
    "hint": "Considera che esistono dispositivi che trasferiscono dati in modo carattere (come la tastiera), non solo a blocchi."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla traduzione di un indirizzo virtuale in fisico, in un sistema con memoria virtuale con paginazione (avente tabella delle pagine ad 1 livello), è falsa?",
    "options": [
      {
        "text": "L'hardware deve anche estrarre dall'indirizzo virtuale il numero di pagina virtuale; tale operazione è equivalente ad una divisione intera",
        "image": ""
      },
      {
        "text": "L'hardware deve anche usare il numero di pagina per accedere alla tabella delle pagine del processo in esecuzione. A tal proposito, deve conoscere l'inizio di tale tabella, che viene definito dal software (sistema operativo). Tale indirizzo può cambiare durante l'esecuzione del processo: sta al sistema operativo mantenerlo aggiornato",
        "image": ""
      },
      {
        "text": "L'hardware deve anche usare il numero di frame ottenuto dalla tabella delle pagine per comporre, insieme con l'offset originale, l'indirizzo fisico. Tale operazione è equivalente ad uno shift seguito da una somma",
        "image": ""
      },
      {
        "text": "L'hardware deve anche cercare il numero di pagina nelle entries della tabella delle pagine del processo in esecuzione.",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'hardware NON cerca il numero di pagina nelle entries: usa il numero di pagina virtuale come indice (offset) per accedere direttamente alla entry corrispondente nella page table. È un'operazione di indicizzazione, non di ricerca.",
    "hint": "L'accesso alla page table è indexed, non searched: il VPN è un indice, non una chiave di ricerca."
  },
  {
    "question": "Quale delle seguenti affermazioni sui file system è vera? ",
    "options": [
      {
        "text": "I file system, che adottano il metodo journaling, mantengono un log per le operazioni di sola scrittura da effettuare, e le realizzano solo in un secondo momento",
        "image": ""
      },
      {
        "text": "Un volume coincide sempre con un disco, quindi se un computer ha 2 dischi avrà 2 volumi",
        "image": ""
      },
      {
        "text": "I dati possono essere ricavati dai metadati",
        "image": ""
      },
      {
        "text": "I metadati possono essere ricavati dai dati",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il journaling registra le operazioni di scrittura in un log (journal) prima di eseguirle, garantendo consistenza in caso di crash. Le altre opzioni sono false: un volume può essere parte di un disco (B), i metadati descrivono i dati ma non li contengono (C), e viceversa (D).",
    "hint": "Il journaling funziona come un diario delle operazioni da compiere, eseguite poi in modo atomico."
  },
  {
    "question": "Quale delle seguenti affermazioni sui meccanismi per la gestione della concorrenza è vera? ",
    "options": [
      {
        "text": "Usando i semafori di qualsiasi tipo, è possibile scrivere processi che non soffrano di starvation",
        "image": ""
      },
      {
        "text": "Disabilitando gli interrupt, è possibile scrivere processi che non soffrano di starvation",
        "image": ""
      },
      {
        "text": "Senza usare né semafori, né scambio messaggi, né istruzioni macchina atomiche, è possibile scrivere processi che non soffrano di starvation per garantire la mutua esclusione tra 2 processi",
        "image": ""
      },
      {
        "text": "Usando le istruzioni macchina exchange e compare_and_swap, è possibile scrivere processi che non soffrano di starvation",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Con la tecnica della commutazione strettamente alternata (turn), due processi possono ottenere mutua esclusione senza semafori, messaggi o istruzioni atomiche. Ogni processo cede il turno all'altro, garantendo fairness e assenza di starvation.",
    "hint": "Esiste una soluzione classica basata su una variabile condivisa 'turn' che alterna l'accesso."
  },
  {
    "question": "Quale dei seguenti elementi non è una delle parti che definiscono un processo? ",
    "options": [
      {
        "text": "Informazioni sullo stato delle risorse",
        "image": ""
      },
      {
        "text": "La priorità",
        "image": ""
      },
      {
        "text": "Il contatore di programma",
        "image": ""
      },
      {
        "text": "I dati contenuti nella porzione di memoria a lui dedicata",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Le parti che definiscono un processo sono il contatore di programma, la priorità e i dati (stack e heap). Le informazioni sullo stato delle risorse (file aperti, memoria allocata) sono gestite dal sistema operativo e non definiscono il processo in sé.",
    "hint": "Ricorda che un processo è definito dal suo contesto di esecuzione e dalle sue risorse private, non da quelle condivise con il sistema."
  },
  {
    "question": "Un computer esegue 20 istruzioni ogni microsecondo. Ricordando che 1 millisecondo = 1000 microsecondi = 1000000 nanosecondi, per eseguire una singola istruzione impiega",
    "options": [
      {
        "text": "0.05 microsecondi",
        "image": ""
      },
      {
        "text": "0.05 millisecondi",
        "image": ""
      },
      {
        "text": "0.05 nanosecondi",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Se il computer esegue 20 istruzioni in 1 microsecondo, il tempo per una singola istruzione è 1/20 = 0.05 microsecondi. È sufficiente dividere il tempo totale per il numero di istruzioni.",
    "hint": "Ricorda che il tempo per una singola istruzione si calcola come: tempo totale / numero di istruzioni."
  },
  {
    "question": "Quale delle seguenti affermazioni è falsa?",
    "options": [
      {
        "text": "Diversi thread di uno stesso processo condividono lo stesso thread identifier[1]",
        "image": ""
      },
      {
        "text": "Tra le funzioni di sistema per i thread, è tipicamente prevista una funzione per bloccare e sbloccare esplicitamente i thread stessi",
        "image": ""
      },
      {
        "text": "Diversi thread di uno stesso processo condividono lo stesso process identifier",
        "image": ""
      },
      {
        "text": "Diversi thread di uno stesso processo condividono i file aperti",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Ogni thread all'interno di uno stesso processo ha un proprio Thread Identifier (TID) univoco, diversamente dal Process Identifier (PID) che è condiviso da tutti i thread del processo.",
    "hint": "Ricorda la differenza tra PID (condiviso da tutti i thread) e TID (univoco per ogni thread)."
  },
  {
    "question": "Quale delle seguenti affermazioni è vera?",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Nell'algoritmo di sostituzione basato su frequenza a 2 segmenti della page cache, un blocco passa da un segmento ad un altro esclusivamente per scorrimento",
        "image": ""
      },
      {
        "text": "L'algoritmo di LFU della page cache ha buone performance quando un settore viene acceduto molto spesso in poco tempo, per poi non essere più usato",
        "image": ""
      },
      {
        "text": "L'algoritmo di sostituzione basato su frequenza a 2 segmenti della page cache può non avere buone performance quando un settore viene acceduto spesso, ma tra il primo accesso...",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Nell'algoritmo a 2 segmenti (2Q), un blocco passa dal segmento first-in-first-out (FIFO) al segmento second chance esclusivamente quando viene nuovamente acceduto (scorrimento), non per semplice passaggio di tempo.",
    "hint": "L'algoritmo 2Q usa due code: una per l'ingresso (FIFO) e una per i blocchi riacceduti."
  },
  {
    "question": "Quale delle seguenti affermazioni sugli i-node di UNIX è falsa?",
    "options": [
      {
        "text": "Ogni directory può contenere molti i-node",
        "image": ""
      },
      {
        "text": "Per modificare una directory un utente deve aprire il file speciale corrispondente e poi modifcarlo opportunamente",
        "image": ""
      },
      {
        "text": "ogni directory è un file speciale, organizzato come una lista di entry, ciascuna delle quali contiene il nome del file ed il relativo i-node number",
        "image": ""
      },
      {
        "text": "Ogni directory è identificata da un i-node",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In UNIX, le directory non vengono modificate aprendo file speciali, ma attraverso chiamate di sistema dedicate come mkdir, rmdir, rename, link e unlink. I file speciali rappresentano dispositivi, non directory.",
    "hint": "Le directory vengono gestite tramite system call specifiche, non come file normali."
  },
  {
    "question": "Quale delle seguenti affermazioni è vera sulla memoria virtuale con paginazione a segmentazione?",
    "options": [
      {
        "text": "Sia la tabella dei segmenti che quella delle pagine di un processo contengono, in ciascuna entry, un bit per indicare se la pagina o il segmento sono stati modificati",
        "image": ""
      },
      {
        "text": "Un indirizzo virtuale contiene anche un bit per indicare se la pagina corrispondente è o no in memoria principale",
        "image": ""
      },
      {
        "text": "La tabella delle pagine di un processo contiene una pagina speciale dove è memorizzato il process control block del processo stesso",
        "image": ""
      },
      {
        "text": "Ogni entry di una tabella delle pagine contiene un numero di pagina ed un offset",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il bit di 'dirty' o modifica è presente sia nelle entry della tabella dei segmenti che in quelle della tabella delle pagine, indicando se il corrispondente segmento/pagina è stato modificato in memoria e deve essere salvato su disco in caso di sostituzione.",
    "hint": "Il dirty bit serve per decidere cosa fare quando una pagina/segmento deve essere rimosso dalla memoria."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla memoria virtuale con paginazione è vera?",
    "options": [
      {
        "text": "Per avere un overhead accettabile, occorre demandare la traduzione degli indirizzi all'hardware, mentre al software resta da gestire prelievo, posizionamento e sostituzione delle pagine",
        "image": ""
      },
      {
        "text": "Per avere un overhead accettabile, occorre demandare la traduzione degli indirizzi e la politica di sostituzione delle pagine all'hardware, mentre al software resta da gestire prelievo e posizionamento delle pagine",
        "image": ""
      },
      {
        "text": "Per avere un overhead accettabile, occorre demandare all'hardware la traduzione degli indirizzi ed il prelievo, il posizionamento e la sostituzione delle pagine",
        "image": ""
      },
      {
        "text": "Per avere un overhead accettabile, occorre demandare al software anche la traduzione degli indirizzi",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La traduzione degli indirizzi da virtuale a fisico è un'operazione frequente che, se gestita interamente dal software, causerebbe un overhead troppo elevato per il sistema.",
    "hint": "Pensa a quante traduzioni di indirizzi avvengono per ogni istruzione e quale componente è più adatto a gestirle."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla concorrenza tra processi o thread è vera?",
    "options": [
      {
        "text": "L'istruzione exchange non può ricevere costanti in input su nessun suo argomento, mentre per l'istruzione compare_and_swap questo non vale",
        "image": ""
      },
      {
        "text": "Per realizzare opportunamente l'istruzione compare_and_swap è sufficiente disabilitare le interruzioni",
        "image": ""
      },
      {
        "text": "Le istruzioni speciali exchange e compare_and_swap sono garantite atomiche dal sistema operativo",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'istruzione exchange scambia il contenuto di due registri, quindi non può usare costanti come argomenti; compare_and_swap invece confronta un valore con una costante e può therefore usare costanti.",
    "hint": "Prova a implementare mentalmente queste istruzioni e vedi quali operandi richiedono."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sugli algoritmi di scheduling è vera?",
    "options": [
      {
        "text": "L'exponential averaging permette di stimare la dimensione dell'immagine di un processo, a partire dalle precedenti immagini di quello stesso processo",
        "image": ""
      },
      {
        "text": "La funzione di decisione dello scheduler Highest Response Ratio Next considera tanto il tempo di esecuzione stimato quanto il tempo trascorso in attesa",
        "image": ""
      },
      {
        "text": "L'exponential averaging è una tecnica applicabile dal solo scheduler Short Process Next",
        "image": ""
      },
      {
        "text": "La funzione di decisione dello scheduler Shortest Remaining Time considera tanto il tempo di esecuzione richiesto quanto il tempo trascorso in attesa",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'exponential averaging è una tecnica che stima il valore successivo di una serie (come il tempo di burst) usando una media ponderata tra il valore precedente e quello attuale: tn+1 = α * tn + (1-α) * tn-1.",
    "hint": "Questa tecnica è usata per predire il comportamento futuro basandosi sulla storia recente."
  },
  {
    "question": "Quale delle seguenti azioni non viene necessariamente eseguita al momento della creazione di un processo in un sistema operativo moderno?",
    "options": [
      {
        "text": "Inizializzazione del process control block",
        "image": ""
      },
      {
        "text": "Allocazione di spazio di memoria RAM e di swap",
        "image": ""
      },
      {
        "text": "Esecuzione del processo",
        "image": ""
      },
      {
        "text": "Creazione di un PID unico",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Un processo appena creato viene messo nello stato 'pronto' (ready) e non viene eseguito immediatamente; lo scheduler deciderà quando assegnargli la CPU.",
    "hint": "Ricorda la differenza tra creazione di un processo e la sua effettiva esecuzione."
  },
  {
    "question": "Quale delle seguenti affermazioni sul file system FAT è vera?",
    "options": [
      {
        "text": "Usa il metodo di allocazione contiguo",
        "image": ""
      },
      {
        "text": "La tabella di allocazione dei file contiene tante righe quanti sono i file memorizzati sul disco, più una riga speciale per i blocchi liberi",
        "image": ""
      },
      {
        "text": "Ogni cluster del disco contiene sia dati del disco che l'indirizzo del prossimo cluster (o l'indicazione che si tratta dell'ultimo cluster)",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Tutte e tre le opzioni A, B e C contengono errori: FAT usa allocazione concatenata (non contigua), la tabella FAT ha tante voci quanti sono i cluster (non i file), e i puntatori al prossimo cluster sono memorizzati nella tabella FAT, non all'interno di ogni cluster.",
    "hint": "Ricorda che in FAT la 'tabella' contiene i puntatori, non i cluster stessi."
  },
  {
    "question": "Quale delle seguenti affermazioni sul requisito di rilocazione nella gestione della memoria è vera?",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Prevede che un processo possa essere allocato in memoria principale, in fase di avvio o al rientro da uno swap, in una tra diverse posizioni possibili",
        "image": ""
      },
      {
        "text": "Prevede che chi programma un processo utente possa richiedere, tramite system call, la posizione del processo in memoria principale",
        "image": ""
      },
      {
        "text": "Per poterlo soddisfare senza creare overhead inaccettabile, è sempre stato necessario dell'hardware aggiuntivo",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'opzione B è effettivamente corretta: il requisito di rilocazione permette a un processo di essere caricato in posizioni diverse in memoria. Le opzioni C e D sono false. Probabilmente l'intento era mostrare un caso in cui tutte le affermazioni sembrano false tranne una.",
    "hint": "Il requisito di rilocazione riguarda la possibilità di caricare un processo in posizioni di memoria differenti."
  },
  {
    "question": "Quale delle seguenti affermazioni sul modello dei processi a 7 stati è vera?",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Gli stati Ready, New e Blocked del modello a 5 stati vengono sdoppiati, e ne viene creata una versione Suspend",
        "image": ""
      },
      {
        "text": "Un processo è Suspend quando scade il timeout del dispatcher",
        "image": ""
      },
      {
        "text": "È possibile la transizione Ready/Suspend ==> Blocked/Suspend",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Nel modello a 7 stati, 'New' non viene sdoppiato (solo Ready e Blocked hanno versioni Suspend), lo stato Suspend non è causato da timeout del dispatcher, e la transizione Ready/Suspend ==> Blocked/Suspend non è ammessa.",
    "hint": "Nel modello a 7 stati, il processo può passare da Suspend a Ready ma non direttamente a Blocked."
  },
  {
    "question": "Quale delle seguenti affermazioni sugli i-node di Unix è vera?",
    "options": [
      {
        "text": "Per ogni file-system su disco organizzato con i-node, tutti gli i-node di tutti i file su tale file-system sono memorizzati esclusivamente su disco",
        "image": ""
      },
      {
        "text": "I puntatori a tripla indirezione di un i-node vengono usati solo se la dimensione del file lo richiede",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Ad ogni file effettivamente memorizzato su disco può essere associato un solo numero di i-node",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "I puntatori a tripla indirezione (triple indirect) vengono usati solo quando i file sono talmente grandi da richiedere più livelli di indirizzamento indiretto oltre ai puntatori diretti e a quelli a indirezione singola e doppia.",
    "hint": "Gli i-node hanno puntatori diretti, a singola, doppia e tripla indirezione per file di dimensioni crescenti."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni sul dispatcher è falsa?",
    "options": [
      {
        "text": "Il throughput è definito come il numero di processi completati per unità di tempo",
        "image": ""
      },
      {
        "text": "Il turnaround time è definito, per un dato processo, come il tempo che intercorre tra la sua prima esecuzione sul processore e il suo completamento",
        "image": ""
      },
      {
        "text": "Un dispatcher con buone prestazioni sul response time deve tipicamente sia minimizzare il valore medio di sistema del response time, sia massimizzare il numero di utenti con un basso valore per il response time",
        "image": ""
      },
      {
        "text": "Il processor utilization è definito come il rapporto tra il tempo in cui il processore viene usato ed il tempo totoale del sistema",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il turnaround time si definisce come il tempo che intercorre tra il momento in cui il processo entra nel sistema (submission) e il suo completamento, non dalla prima esecuzione sul processore.",
    "hint": "Il turnaround time include tutto il tempo di attesa in coda, non solo il tempo di esecuzione effettiva."
  },
  {
    "question": "Quale delle seguenti affermazioni sull'algoritmo del banchiere per evitare il deadlock visto a lezione è falsa?",
    "options": [
      {
        "text": "Se si procede da uno stato ad un altro, necessariamente è stata fatta almeno una richiesta ad almeno una risorsa da parte di almeno un processo",
        "image": ""
      },
      {
        "text": "Richiede in input, per ogni processo p e per ogni risorsa r, il numero massimo di istanze di r che p chiederà nel corso della sua esecuzione",
        "image": ""
      },
      {
        "text": "All'inizio e alla fine di ogni invocazione dell'algoritmo, Vi = Ri - ∑j = 1, ..., nAi, j",
        "image": ""
      },
      {
        "text": "La matrice C - A può contenere elementi negativi, ma le matrici C ed A contengono solo elementi non negativi",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Nell'algoritmo del banchiere, la matrice C-A rappresenta le risorse ancora richiedibili (max - allocato) e deve sempre essere non negativa per uno stato valido e sicuro; se fosse negativa, il processo avrebbe già superato le sue richieste massime, violando i vincoli del sistema.",
    "hint": "Ricorda che C-A rappresenta le risorse ancora richiedibili e deve essere sempre >= 0 in uno stato valido."
  },
  {
    "question": "Quale delle seguenti affermazioni sugli scheduler per architetture multiprocessore è vera?",
    "options": [
      {
        "text": "Con l'assegnamento statico, si dà un processore a caso tra quelli liberi ai processi che mantengono un uso della RAM pressoché costante",
        "image": ""
      },
      {
        "text": "Uno svantaggio dell'assegnamento statico è il suo overhead maggiore rispetto a quello dinamico",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Assegnando i processi del sistema operativo con l'assegnamento dinamico, si rischia di creare un bottleneck su un solo processore",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'assegnamento statico ha overhead MINORE (non maggiore) rispetto a quello dinamico, poiché non richiede decisioni di scheduling ad ogni context switch; inoltre l'assegnamento dinamico distribuisce il carico su più processori evitando bottleneck.",
    "hint": "L'overhead statico è generalmente minore di quello dinamico, non maggiore."
  },
  {
    "question": "Assumendo un sistema monoprocessore, quale delle seguenti affermazioni è falsa? ",
    "options": [
      {
        "text": "Lo scheduler ha, tra i suoi obiettivi, quello dell'equità tra i processi, a meno che non siano definite delle priorità",
        "image": ""
      },
      {
        "text": "Lo scheduler va scritto in modo che il suo overhead sia basso",
        "image": ""
      },
      {
        "text": "Lo scheduler ha, tra i suoi obiettivi, quello di massimizzare il volume di lavoro dei processi nel tempo",
        "image": ""
      },
      {
        "text": "Lo scheduler ha, tra i suoi obiettivi, quello di evitare il deadlock",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Lo scheduler gestisce la CPU e la sua allocazione ai processi, ma il deadlock è un problema di allocazione delle risorse (non solo CPU) che viene gestito da algoritmi specifici di gestione dei deadlock, non dallo scheduler della CPU.",
    "hint": "Lo scheduler gestisce la CPU, ma il deadlock riguarda l'allocazione di tutte le risorse, non solo la CPU."
  },
  {
    "question": "Quale delle seguenti affermazioni sui metodi di gestione del deadlock è vera?",
    "options": [
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "L'unico metodo, che richiede di conoscere in anticipo il massimo numero di risorse che un processo dovrà chiedere, è quello per rilevare il deadlock",
        "image": ""
      },
      {
        "text": "L'unico metodo che non prevede mai la preemption delle risorse è quello che evita il deadlock",
        "image": ""
      },
      {
        "text": "Il metodo più permissivo nei confronti delle richieste di risorse è quello che consiste nel prevenire il deadlock",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo del banchiere per evitare il deadlock richiede che le risorse siano richieste volontariamente e non prevede mai preemption, a differenza dei metodi di rilevamento e prevenzione che possono prevedere preemption.",
    "hint": "Il metodo per evitare il deadlock (Banchiere) lavora con richieste volontarie senza togliere risorse ai processi."
  },
  {
    "question": "Quale delle seguenti affermazioni sulla memoria virtuale con paginazione è vera?",
    "options": [
      {
        "text": "Il thrashing si verifica quando l'overhead dovuto alla gestione della paginazione è molto basso",
        "image": ""
      },
      {
        "text": "La paginazione con memoria virtuale funziona bene nonostante il principio di località",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è corretta",
        "image": ""
      },
      {
        "text": "Il principio di località afferma che poche pagine saranno sempre sufficienti per eseguire ogni processo senza thrashing",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il thrashing si verifica quando l'overhead è MOLTO ALTO (non basso); la paginazione funziona bene GRAZIE al principio di località; il principio di località afferma che i processi tendono a usare un insieme limitato di pagine, ma non garantisce che sia sempre sufficiente per evitare thrashing.",
    "hint": "Il thrashing è causato da overhead elevato, non basso, e il principio di località è ciò che rende la paginazione efficiente."
  },
  {
    "question": "Quale delle seguenti affermazioni sui metodi di gestione dello spazio libero su disco è vera?",
    "options": [
      {
        "text": "Uno dei possibili metodi è quello di scorrere la tabella di allocazione dei file e ricavare per esclusione i blocchi liberi",
        "image": ""
      },
      {
        "text": "Nessuna delle altre opzioni è vera",
        "image": ""
      },
      {
        "text": "Nel caso si usi un metodo di allocazione dinamica, non è necessario aggiornare le informazioni sullo spazio libero quando vengono aggiunti dati ad un file",
        "image": ""
      },
      {
        "text": "Se viene usata una tabella di bit, allora il metodo di allocazione non può essere la preallocazione",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Le alternative A, C e D sono tutte false. A è falsa perché i metodi di gestione dello spazio libero (bitmap, lista concatenata, lista raggruppata) non derivano i blocchi liberi per esclusione dalla tabella di allocazione. C è falsa perché l'allocazione dinamica richiede comunque l'aggiornamento delle strutture dati per lo spazio libero. D è falsa perché la tabella di bit è compatibile con qualsiasi metodo di allocazione, inclusa la preallocazione.",
    "hint": "Ricorda che i metodi di gestione dello spazio libero (bitmap, linked list, grouped list) sono indipendenti dal metodo di allocazione dei file."
  },
  {
    "question": "Quale delle seguenti operazioni non è tipicamente effettuata su un file?",
    "options": [
      {
        "text": "Apertura",
        "image": ""
      },
      {
        "text": "Connessione",
        "image": ""
      },
      {
        "text": "Posizionamento (seek)",
        "image": ""
      },
      {
        "text": "Lock / Unlock",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Le operazioni tipiche su un file includono apertura (open), seek (posizionamento) e lock/unlock per controllo concorrenza. 'Connessione' è un'operazione associata a risorse di rete o database, non ai file system.",
    "hint": "Quale di queste operazioni è tipica delle connessioni di rete piuttosto che dei file?"
  }
]