[
  {
    "question": "Il sistema operativo",
    "options": [
      {
        "text": "Coincide con il kernel",
        "image": ""
      },
      {
        "text": "Costituisce l'interfaccia tra la macchina fisica (hardware) e le applicazioni utente",
        "image": ""
      },
      {
        "text": "√à soggetto alle politiche di scheduling",
        "image": ""
      },
      {
        "text": "Risiede in memoria principale anche in seguito allo shutdown della macchina",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il sistema operativo agisce come intermediario essenziale che maschera la complessit√† dell'hardware fisico, fornendo ai programmi applicativi un'interfaccia uniforme e astratta per accedere alle risorse della macchina. Questo livello di astrazione permette alle applicazioni di funzionare indipendentemente dalle specifiche caratteristiche hardware sottostanti.",
    "hint": "Pensa al ruolo di 'intermediario' che svolge il SO tra i componenti fisici e i programmi che usi quotidianamente."
  },
  {
    "question": "In un sistema operativo microkernel",
    "options": [
      {
        "text": "Alcune delle funzionalit√† sono implementate in spazio utente anzich√© all'interno del kernel",
        "image": ""
      },
      {
        "text": "I processi utente possono interagire direttamente con il sistema,evitando l'uso di system call",
        "image": ""
      },
      {
        "text": "La comunicazione tra le varie componenti del sistema √® pi√π efficiente",
        "image": ""
      },
      {
        "text": "Non sono previsti meccanismi di protezione  ",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'architettura microkernel sposta fuori dal kernel la maggior parte dei servizi tradizionalmente interni (come driver e file system), eseguendoli come processi utente privilegiati per aumentare modularit√† e sicurezza. Questo contrasta con i kernel monolitici dove tutte le funzionalit√† risiedono nello spazio kernel.",
    "hint": "Considera la differenza tra ci√≤ che rimane nel nucleo centrale e ci√≤ che viene 'esternalizzato' in processi separati."
  },
  {
    "question": "In un sistema operativo strutturato secondo un approccio microkernel",
    "options": [
      {
        "text": "Non necessita di avere due modalit√† di utilizzo della CPU (user vs.kernel mode)",
        "image": ""
      },
      {
        "text": "Non necessita di meccanismi di comunicazione tra porzioni diverse del sistema operativo",
        "image": ""
      },
      {
        "text": "E' pi√π efficiente di un sistema monolitico",
        "image": ""
      },
      {
        "text": "Ad eccezione delle funzionalit√† fondamentali, implementa tutto il resto in spazio utente",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il microkernel mantiene nel kernel solo le funzionalit√† minime indispensabili come la gestione della memoria, scheduling e comunicazione inter-processo, mentre servizi come file system e driver diventano server in user space. Questa separazione favorisce manutenibilit√† e isolamento dei guasti a scapito di qualche overhead di comunicazione.",
    "hint": "Rifletti sul principio di 'minimizzazione' del nucleo centrale rispetto ai servizi aggiuntivi."
  },
  {
    "question": "L'insieme di istruzioni del livello macchina:",
    "options": [
      {
        "text": "Sono composte da un codice operativo e da zero o pi√π operandi",
        "image": ""
      },
      {
        "text": "Sono definite da uno specifico linguaggio macchina",
        "image": ""
      },
      {
        "text": "Sono un'astrazione dell'architettura hardware",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Le istruzioni macchina rappresentano il livello pi√π basso di programmazione, composte da codici operativi che specificano l'azione e operandi che indicano i dati coinvolti, definite dal set di istruzioni specifico dell'architettura (ISA). Questo livello costituisce l'interfaccia software-hardware che astrae i dettagli circuitali sottostanti.",
    "hint": "Analizza singolarmente ciascuna opzione pensando alla struttura binaria delle istruzioni e al loro rapporto con l'hardware."
  },
  {
    "question": "I registri interni della CPU e la cache sono unit√† di memoria:",
    "options": [
      {
        "text": "Non volatili",
        "image": ""
      },
      {
        "text": "Gestite interamente dall'architettura a livello hardware",
        "image": ""
      },
      {
        "text": "Gestite interamente dal sistema operativo",
        "image": ""
      },
      {
        "text": "Molto economiche e altamente performanti",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Registri e cache sono gestiti direttamente dalla logica hardware della CPU senza intervento del sistema operativo; i registri sono allocati dal compilatore o dal processore stesso durante l'esecuzione, mentre la cache √® trasparente al software gestita dai controller di memoria. Il SO opera a livello di memoria principale (RAM) e non controlla direttamente queste risorse interne al processore.",
    "hint": "Distingui tra memoria gestita automaticamente dall'elettronica del processore e quella gestita dal software di sistema."
  },
  {
    "question": "La transizione da user a kernel mode avviene quando:",
    "options": [
      {
        "text": "Un programma esegue una chiamata di funzione",
        "image": ""
      },
      {
        "text": "Si avvia il computer (bootstrap)",
        "image": ""
      },
      {
        "text": "Si esegue la prima istruzione di un programma",
        "image": ""
      },
      {
        "text": "Scade il quanto di tempo assegnato al processo in esecuzione",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Quando scade il quanto di tempo, il timer hardware genera un interrupt che forza la CPU a passare in modalit√† kernel per eseguire lo scheduler e gestire il cambio di contesto. Questo √® uno dei principali meccanismi di transizione da user a kernel mode.",
    "hint": "Considera il ruolo del timer interrupt nella gestione della CPU."
  },
  {
    "question": "Il device controller di un dispositivo di I/O:",
    "options": [
      {
        "text": "Contiene dei registri che ne indicano lo stato",
        "image": ""
      },
      {
        "text": "Contiene dei registri che ne consentono il controllo da parte della CPU",
        "image": ""
      },
      {
        "text": "Contiene dei registri per lo scambio di dati con la CPU",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il device controller integra registri di stato per monitorare le condizioni del dispositivo, registri di controllo per ricevere comandi dalla CPU e buffer dati per il trasferimento delle informazioni, svolgendo tutte queste funzioni essenziali.",
    "hint": "Ricorda che il controller deve gestire comando, stato e dati del dispositivo."
  },
  {
    "question": "Le chiamate di sistema:",
    "options": [
      {
        "text": "Sono sempre bloccanti",
        "image": ""
      },
      {
        "text": "Causano la terminazione del processo in corso e l'avvio di un nuovo processo",
        "image": ""
      },
      {
        "text": "Devono essere implementate in spazio utente",
        "image": ""
      },
      {
        "text": "Devono essere implementate in spazio kernel",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Le chiamate di sistema richiedono l'esecuzione di codice privilegiato per accedere a risorse hardware e strutture dati protette del sistema operativo, operazioni permesse esclusivamente in modalit√† kernel.",
    "hint": "Pensa alla protezione delle risorse del sistema operativo."
  },
  {
    "question": "Una chiamata di sistema bloccante",
    "options": [
      {
        "text": "Sposta in coda pronti (ready) il processo che la esegue",
        "image": ""
      },
      {
        "text": "Interrompe definitivamente il processo che la esegue",
        "image": ""
      },
      {
        "text": "Interrompe temporaneamente il processo che la esegue",
        "image": ""
      },
      {
        "text": "Necessit√† che il processo che la esegue ne verifichi periodicamente l'esito (polling)",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Una chiamata bloccante sospende temporaneamente l'esecuzione del processo, trasferendolo in stato di attesa (waiting) fino al completamento dell'operazione richiesta, senza terminare il processo.",
    "hint": "Distingui tra lo stato di attesa e la terminazione di un processo."
  },
  {
    "question": "Il system call handler:",
    "options": [
      {
        "text": "√à invocato dallo scheduler del sistema operativo",
        "image": ""
      },
      {
        "text": "Viene invocato alla scadenza del quanto temporale",
        "image": ""
      },
      {
        "text": "Viene eseguito in spazio utente",
        "image": ""
      },
      {
        "text": "Gestisce le chiamate di sistema tramite la system call table",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il system call handler √® una routine del kernel che, utilizzando la system call table come indice, individua e invoca la specifica funzione kernel corrispondente al numero di chiamata ricevuto.",
    "hint": "Immagina come una tabella di lookup per associare numeri a funzioni specifiche."
  },
  {
    "question": " Il codice generico del system call handler:",
    "options": [
      {
        "text": "Viene eseguito in spazio utente",
        "image": ""
      },
      {
        "text": "√à indicizzato tramite la interrupt vector table (IVT)",
        "image": ""
      },
      {
        "text": "Viene invocato alla scadenza del quanto temporale",
        "image": ""
      },
      {
        "text": "Viene invocato dallo scheduler del sistema operativo",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Le system call vengono attivate tramite interrupt software (trap) che causano il passaggio in modalit√† kernel. L'IVT contiene gli indirizzi dei gestori per ogni tipo di interrupt, incluso quello dedicato alle system call, permettendo al processore di localizzare ed eseguire il codice del handler appropriato.",
    "hint": "Considera come il processore determina l'indirizzo del codice da eseguire quando viene generato un interrupt software."
  },
  {
    "question": "L'interrupt vector table(IVT):",
    "options": [
      {
        "text": "Si aggiorna dinamicamente ad ogni interruzione",
        "image": ""
      },
      {
        "text": "E' una struttura dati che contiene puntatori ai vari gestori(handler) delle interruzioni",
        "image": ""
      },
      {
        "text": "E' una struttura dati che √® associata a ciascun processo",
        "image": ""
      },
      {
        "text": "E' una struttura dati che contiene puntatori a codici di errori",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'Interrupt Vector Table √® una struttura dati globale del sistema, tipicamente residente in una zona fissa della memoria, che associa a ciascun numero di interrupt l'indirizzo del corrispondente gestore (handler) da eseguire.",
    "hint": "Pensa a cosa serve al processore per gestire eventi asincroni come interrupt hardware o eccezioni."
  },
  {
    "question": "La system-call table:",
    "options": [
      {
        "text": "Contiene tante entry quanto sono le chiamate di sistema supportare",
        "image": ""
      },
      {
        "text": "Contiene tante entry quante sono le interruzioni supportare",
        "image": ""
      },
      {
        "text": "Contiene tante entry quanti sono i dispositivi di I/O presenti nel sistema",
        "image": ""
      },
      {
        "text": "Contiene tante entry quanti sono i processi in esecuzione",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La system-call table √® una struttura dati interna al kernel che mappa ogni numero di system call (es. 0, 1, 2...) al puntatore della funzione che la implementa. Pertanto contiene esattamente tante entry quante sono le diverse chiamate di sistema disponibili nel sistema operativo.",
    "hint": "Ogni numero identificativo univoco di una system call corrisponde a un indice in questa tabella."
  },
  {
    "question": "La system-call table √® una struttura dati gestita:",
    "options": [
      {
        "text": "Dai dispositivi di I/O",
        "image": ""
      },
      {
        "text": "Dal processo utente",
        "image": ""
      },
      {
        "text": "Sia dal kernel del sistema operativo che dal processo utente",
        "image": ""
      },
      {
        "text": "Dal kernel del sistema operativo",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La system-call table risiede nello spazio di memoria protetto del kernel ed √® accessibile solo in modalit√† privilegiata. I processi utente possono solo invocare le system call attraverso l'interfaccia pubblica, ma non possono modificare la tabella.",
    "hint": "Ricorda che questa tabella contiene codice eseguibile in modalit√† kernel e definisce il confine tra spazio utente e kernel."
  },
  {
    "question": "Se si cambia l'implementazione di una chiamata di sistema esistente:",
    "options": [
      {
        "text": "E' sempre necessario modificare il codice utente che ne fa uso",
        "image": ""
      },
      {
        "text": "Non √® mai necessario modificare il codice utente che ne fa uso",
        "image": ""
      },
      {
        "text": "Non √® necessario modificare il codice utente che ne fa uso, a patto che cambi anche l'interfaccia (API) della chiamata di sistema",
        "image": ""
      },
      {
        "text": "Non √® necessario modificare il codice utente che ne fa uso, a patto che non cambi anche l‚Äôinterfaccia (API) della chiamata di sistema",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Questo principio riflette la separazione tra interfaccia (API) e implementazione: il codice utente dipende solo dalla firma e dal comportamento osservabile della chiamata, non dai dettagli interni. Se l'API rimane stabile, l'implementazione pu√≤ essere ottimizzata o corretta senza impattare i programmi esistenti.",
    "hint": "Pensa al concetto di information hiding e alla stabilit√† dell'interfaccia tra sistema operativo e applicazioni."
  },
  {
    "question": "Un processore impiega 5 cicli di clock per eseguire un'istruzione (CPI = 5), ossia per completare l'intero ciclo fetch-decode-execute. Assumendo che la frequenza di clock del processore sia pari a 5 MHz, quante istruzioni √® in grado di eseguire in un secondo? (Si ricordi che 1 MHz = 1*10^6 cicli al secondo)",
    "options": [
      {
        "text": "1*10^3",
        "image": ""
      },
      {
        "text": "Decido di NON rispondere a questa domanda",
        "image": ""
      },
      {
        "text": "25*10^3",
        "image": ""
      },
      {
        "text": "1*10^6",
        "image": ""
      },
      {
        "text": "25*10^6",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il numero di istruzioni eseguite al secondo (IPS) si calcola dividendo la frequenza di clock per il CPI (Cycles Per Instruction). Con 5 MHz (5√ó10‚Å∂ cicli/s) e CPI=5, si ottengono 10‚Å∂ istruzioni al secondo.",
    "hint": "Ricorda che IPS = Frequenza / CPI."
  },
  {
    "question": "Data una CPU multicore con ùëöunit√†(cores), il numero di processi/thread che ad un certo istante si trovano nella ‚Äúcoda‚Äù di esecuzione(running):",
    "options": [
      {
        "text": "Pu√≤ essere superiore a ùëö",
        "image": ""
      },
      {
        "text": "E‚Äô esattamente pari a ùëö",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "E' al massimo pari a ùëö",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "In un sistema multicore con m core, il grado di multiprogrammazione nella fase di esecuzione (running) √® limitato dal numero di unit√† di elaborazione disponibili. Ogni core pu√≤ eseguire al pi√π un thread alla volta in modalit√† running, quindi il numero massimo di processi in stato running contemporaneamente √® m.",
    "hint": "Ogni core pu√≤ eseguire un solo thread alla volta in stato running."
  },
  {
    "question": "La creazione di un nuovo processo da parte di un processo avviene tramite:",
    "options": [
      {
        "text": "Una chiamata di sistema",
        "image": ""
      },
      {
        "text": "Una chiamata di funzione",
        "image": ""
      },
      {
        "text": "L'invio di un interruzione",
        "image": ""
      },
      {
        "text": "Nessuna delle risposte precedenti √® corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La creazione di un processo (ad esempio tramite fork() in Unix/Linux) richiede l'intervento del sistema operativo per allocare risorse e creare il PCB, pertanto avviene attraverso una system call che passa il controllo al kernel in modalit√† privilegiata.",
    "hint": "L'operazione richiede privilegi del kernel per gestire le risorse del sistema."
  },
  {
    "question": "Il sistema operativo tiene traccia dello stato di un processo tramite:",
    "options": [
      {
        "text": "Un'apposita area dedicata e protetta della memoria principale",
        "image": ""
      },
      {
        "text": "Un apposito registro interno della CPU",
        "image": ""
      },
      {
        "text": "Un'apposita area dedicata e protetta della memoria cache",
        "image": ""
      },
      {
        "text": "Un apposito campo all'interno del process control block (PCB)",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il PCB (Process Control Block) √® la struttura dati principale usata dal SO per gestire i processi, contenente tutte le informazioni necessarie incluso lo stato corrente (new, ready, running, waiting, terminated).",
    "hint": "Cerca la struttura dati che contiene tutte le informazioni di gestione di un processo."
  },
  {
    "question": "Un processo in esecuzione sulla CPU passa in stato ready quando:",
    "options": [
      {
        "text": "Riceve un segnale di interruzione da parte di un dispositivo di I/O",
        "image": ""
      },
      {
        "text": "Fa richiesta di input da parte dell‚Äôutente",
        "image": ""
      },
      {
        "text": "Fa richiesta di una pagina che non √® presente in memoria principale",
        "image": ""
      },
      {
        "text": "Esegue una chiamata di funzione",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'arrivo di un interrupt (es. da I/O o timer) causa la sospensione del processo corrente che, tramite lo scheduler, pu√≤ essere riportato nella coda ready per permettere la gestione dell'evento o l'esecuzione di altri processi.",
    "hint": "Un interrupt esterno interrompe l'esecuzione corrente e pu√≤ attivare lo scheduler."
  },
  {
    "question": "Un processo in esecuzione sulla CPU passa in stato waiting quando:",
    "options": [
      {
        "text": "Riceve un segnale da parte di un dispositivo di I/O",
        "image": ""
      },
      {
        "text": "Termina il quanto di tempo ad esso assegnato",
        "image": ""
      },
      {
        "text": "Apre una connessione di rete (ad es., un socket TCP)",
        "image": ""
      },
      {
        "text": "Esegue una chiamata di funzione",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'apertura di una connessione di rete richiede operazioni di I/O che bloccano il processo fino al completamento della connessione o del trasferimento dati, causando la transizione dallo stato running a waiting.",
    "hint": "Pensa a quali operazioni richiedono l'attesa di risorse esterne come la rete."
  },
  {
    "question": "Un processo in esecuzione sulla CPU passa in stato waiting quando:",
    "options": [
      {
        "text": "Fa richiesta di input da parte dell'utente",
        "image": ""
      },
      {
        "text": "Esegue una chiamata di funzione",
        "image": ""
      },
      {
        "text": "Termina il quanto di tempo ad esso assegnato",
        "image": ""
      },
      {
        "text": "Riceve un segnale di interruzione da parte di un dispositivo di I/O",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La richiesta di input da parte dell'utente √® un'operazione di I/O che blocca il processo finch√© non vengono forniti dati dai dispositivi di input, forzando il passaggio allo stato waiting.",
    "hint": "Considera quale azione richiede l'attesa di un'interazione umana esterna."
  },
  {
    "question": "Un processo in esecuzione sulla CPU passa in stato waiting quando:",
    "options": [
      {
        "text": "Termina il quanto di tempo ad esso assegnato",
        "image": ""
      },
      {
        "text": "L'utente trascina il dispositivo di puntamento(e.g. mouse)",
        "image": ""
      },
      {
        "text": "Esegue una chiamata di funzione",
        "image": ""
      },
      {
        "text": "Riceve un segnale di interruzione da parte di un dispositivo di I/O",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La lettura dell'input da un dispositivo di puntamento √® un'operazione di I/O che blocca il processo fino all'evento di input, causando la transizione allo stato waiting.",
    "hint": "Quale opzione descrive un'operazione di input che blocca l'esecuzione?"
  },
  {
    "question": "Quanti processi saranno presenti nel sistema a seguito di queste chiamata: pid_1 = fork(); pid_2 = fork(); pid_3 = fork();?",
    "options": [
      {
        "text": "8",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "3",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Ogni chiamata fork() raddoppia il numero di processi esistenti. Dopo tre fork consecutive, il numero totale di processi √® 2¬≥ = 8, includendo il processo padre originale.",
    "hint": "Ricorda che ogni processo esistente esegue le fork successive, moltiplicandosi."
  },
  {
    "question": "I processi CPU-bound che non eseguono richieste di I/O:",
    "options": [
      {
        "text": "Hanno una priorit√† alta",
        "image": ""
      },
      {
        "text": "Hanno una priorit√† bassa",
        "image": ""
      },
      {
        "text": "Sono processi mediamente brevi",
        "image": ""
      },
      {
        "text": "Possono non rilasciare mai la CPU volontariamente",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "I processi CPU-bound eseguono computazioni intensive senza effettuare chiamate di I/O bloccanti, quindi non rilasciano volontariamente la CPU ma devono essere forzatamente preempted dallo scheduler.",
    "hint": "Cosa distingue i processi CPU-bound da quelli I/O-bound riguardo al rilascio della CPU?"
  },
  {
    "question": "Lo scheduler della CPU si attiva:",
    "options": [
      {
        "text": "Quando un processo tenta di eseguire una scrittura su discord",
        "image": ""
      },
      {
        "text": "Quando il codice di un programma esegue una divisione per zero",
        "image": ""
      },
      {
        "text": "Quando scade il quanto di tempo",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Lo scheduler della CPU viene invocato ad ogni trap o interrupt che causa il rilascio del processore: eccezioni aritmetiche (divisione per zero), richieste di I/O (scrittura su disco) o scadenza del quanto temporale (timer interrupt) generano tutti un context switch.",
    "hint": "Considera quali eventi hardware o software forzano il sistema operativo a scegliere un nuovo processo da eseguire."
  },
  {
    "question": "Lo scheduling preemptive(basato su time slice o quanto temporale):",
    "options": [
      {
        "text": "Da la priorit√† ai processi CPU-bound",
        "image": ""
      },
      {
        "text": "Si attiva solamenta alla scadenza del quanto temporale(time slice)",
        "image": ""
      },
      {
        "text": "Si attiva solamente a fronte di una chiamata di sistema",
        "image": ""
      },
      {
        "text": "Fornisce un limite superiore al tempo di CPU assegnato a ciascun processo",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il quanto temporale (time slice) rappresenta la massima porzione di tempo CPU che un processo pu√≤ utilizzare continuativamente prima di essere forzatamente sospeso (preempted), garantendo che nessun processo monopolizzi la CPU.",
    "hint": "Rifletti sul significato di 'preemption' e su cosa venga misurato dal time slice."
  },
  {
    "question": "In un sistema uniprocessore (single core) time-sharing in cui i processi in esecuzione sono tutti puramente CPU-bound:",
    "options": [
      {
        "text": "L'impiego dei multi-threading consente di migliorare la latenza del sistema",
        "image": ""
      },
      {
        "text": "L'impiego del multi-threading consente di diminuire il tempo di completamente di ciascun processo",
        "image": ""
      },
      {
        "text": "L'impiego del multi-threading consente di migliorare il throughput del sistema",
        "image": ""
      },
      {
        "text": "L'impiego dei multi-threading non costituisce alcun vantaggio",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Su un singolo core, processi CPU-bound non beneficiano del multithreading perch√© i thread competono per la stessa unit√† di elaborazione senza possibilit√† di parallelismo reale; il context switching aggiunge solo overhead senza migliorare throughput o tempi di completamento.",
    "hint": "Pensa a cosa succede quando pi√π thread computazionali devono condividere una sola unit√† di esecuzione fisica."
  },
  {
    "question": "In caso di scheduling preemptive, lo scheduler interviene:",
    "options": [
      {
        "text": "Quando un processo passa dallo stato running allo stato waiting",
        "image": ""
      },
      {
        "text": "Quando un processo passa dallo stato running allo stato ready",
        "image": ""
      },
      {
        "text": "Quando un processo passa dallo stato waiting allo stato ready",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Nello scheduling preemptive, lo scheduler deve intervenire ad ogni cambio di stato rilevante: quando un processo rilascia volontariamente la CPU (running‚Üíwaiting), quando viene preempted (running‚Üíready), o quando un processo pronto potrebbe avere priorit√† maggiore (waiting‚Üíready).",
    "hint": "Ricorda che lo scheduling preemptive richiede ricalcolo delle priorit√† ad ogni variazione della coda dei pronti."
  },
  {
    "question": "Se un processo arriva nella coda dei pronti all'istante t.0 = 2e termina all'istante t.f = 15, il suo tempo di turnaround equivale a",
    "options": [
      {
        "text": "13",
        "image": ""
      },
      {
        "text": "2",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "15",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il tempo di turnaround (o tempo di ritorno) √® definito come l'intervallo totale tra l'arrivo del processo nel sistema e il suo completamento, calcolato come t_f - t_0 = 15 - 2 = 13.",
    "hint": "Ricorda la formula: turnaround = istante di completamento - istante di arrivo."
  },
  {
    "question": "Se un processo arriva nella coda dei pronti all‚Äôistante ùë°0 = 3 e termina all‚Äôistante ùë°ùëì = 25, il tempo di attesa equivale a",
    "options": [
      {
        "text": "3",
        "image": ""
      },
      {
        "text": "22",
        "image": ""
      },
      {
        "text": "25",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il tempo di attesa √® definito come il tempo trascorso in coda dei pronti prima dell'inizio dell'esecuzione. Conoscendo solo l'istante di arrivo (3) e quello di terminazione (25), possiamo calcolare solo il tempo di turnaround (22), ma non il tempo di attesa senza sapere quando il processo ha effettivamente iniziato l'esecuzione o la durata del suo burst CPU.",
    "hint": "Per calcolare l'attesa serve sapere quando il processo ha ottenuto la CPU per la prima volta, non solo quando √® arrivato e quando ha finito."
  },
  {
    "question": "I thread di uno stesso processo condividono:",
    "options": [
      {
        "text": "Lo stack",
        "image": ""
      },
      {
        "text": "Le variabili globali",
        "image": ""
      },
      {
        "text": "I valori dei registri della CPU",
        "image": ""
      },
      {
        "text": "Nessuna delle informazioni elencate sopra",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "I thread di uno stesso processo condividono lo spazio degli indirizzi, quindi il codice, i dati globali e l'heap, mentre mantengono stack separati per le chiamate di funzione locali e contesti di esecuzione indipendenti (registri).",
    "hint": "Pensa a cosa appartiene all'intero processo rispetto a ci√≤ che √® privato di ogni singolo flusso di esecuzione."
  },
  {
    "question": "Lo user thread:",
    "options": [
      {
        "text": "Necessita del supporto di una opportuna thread table a livello kernel",
        "image": ""
      },
      {
        "text": "E' la pi√π piccola unit√† schedulabile sulla CPU dal sistema operativo",
        "image": ""
      },
      {
        "text": "E' gestito in spazio utente tramite un'apposita libreria",
        "image": ""
      },
      {
        "text": "Coincide sempre con uno ed un solo kernel thread",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Gli user thread sono implementati interamente in spazio utente tramite librerie di threading (come pthread in modalit√† user-space), senza intervento del kernel. Il sistema operativo vede solo il processo come un'unica entit√†, mentre la gestione dei thread √® demandata alla libreria runtime.",
    "hint": "Considera chi gestisce la creazione e lo scheduling quando il sistema operativo non conosce l'esistenza dei singoli thread."
  },
  {
    "question": "Nel modello di thread mapping cosiddetto one-to-one:",
    "options": [
      {
        "text": "Consente di gestire i thread tramite un'apposita libreria a livello utente",
        "image": ""
      },
      {
        "text": "Pu√≤ essere implementato solo su sistemi multiprocessore",
        "image": ""
      },
      {
        "text": "Causa il blocco di tutti i thread di un processo se anche uno solo di questi thread esegue una chiamata di sistema bloccante",
        "image": ""
      },
      {
        "text": "Consente di gestire i thread a livello del kernel del sistema operativo",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Nel modello one-to-one, ogni thread a livello utente corrisponde esattamente a un thread kernel. Questo richiede che il sistema operativo gestisca direttamente i thread tramite system call, permettendo vera concorrenza ma con maggiore overhead di gestione.",
    "hint": "In questo modello, il kernel √® pienamente consapevole di ogni singolo thread e pu√≤ schedularli indipendentemente."
  },
  {
    "question": "Nel modello di thread mapping cosiddetto many-to-one:",
    "options": [
      {
        "text": "Molti user thread possono essere distribuiti su pi√π CPU (se presenti)",
        "image": ""
      },
      {
        "text": "L'effetto di una chiamata bloccante da parte di uno user thread non blocca gli altri thread da cui √® composto il processo",
        "image": ""
      },
      {
        "text": "Molti user thread sono mappati su un singolo kernel thread",
        "image": ""
      },
      {
        "text": "Molti kernel thread sono mappati su un singolo user thread",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nel modello many-to-one, molti thread utente vengono mappati su un unico thread kernel. Questo implica che il kernel vede solo un'entit√† schedulabile per quel processo, quindi una chiamata bloccante di un thread blocca tutti gli altri thread del processo.",
    "hint": "Immagina molti flussi logici che devono condividere un'unica entit√† di esecuzione visibile al sistema operativo."
  },
  {
    "question": "Il modello di thread mapping considerato many-to-many",
    "options": [
      {
        "text": "Non prevede alcun limite al numero di kernel thread",
        "image": ""
      },
      {
        "text": "Pu√≤ essere implementato solo su sistemi multiprocessore",
        "image": ""
      },
      {
        "text": "Causa il blocco di tutti i thread di un processo se anche uno solo di questi thread esegue una chiamata di sistema bloccante",
        "image": ""
      },
      {
        "text": "E' il compromesso tra un'implementazione dei thread puramente user level e una puramente kernel level",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il modello many-to-many consente di mappare pi√π thread utente su un numero minore o uguale di thread kernel, bilanciando la leggerezza della gestione in user space con la capacit√† di eseguire parallelamente system call bloccanti. Rappresenta quindi un ibrido tra il modello many-to-one (tutti user-level) e one-to-one (tutti kernel-level).",
    "hint": "Considera i vantaggi e svantaggi dei modelli many-to-one e one-to-one."
  },
  {
    "question": "Si parla di parallelismo quando:",
    "options": [
      {
        "text": "Vengono eseguiti processi single-threaded su CPU multicore",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi multi-threaded su CPU single core",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi multi-threaded su CPU multicore",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il parallelismo richiede l'esecuzione fisicamente simultanea di pi√π istruzioni, possibile solo combinando hardware multi-core con software multi-threaded che distribuisca il carico sui diversi core. Su CPU single-core si pu√≤ avere solo concorrenza tramite interleaving, non parallelismo reale.",
    "hint": "Necessita sia di risorse hardware multiple che di capacit√† di suddividere il lavoro in pi√π flussi."
  },
  {
    "question": "Si parla di concorrenza quando:",
    "options": [
      {
        "text": "Vengono eseguiti processi multi-threaded su CPU single core",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi single-threaded su CPU single core",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi single-threaded su CPU multicore",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi multi-threaded su CPU multicore",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La concorrenza indica la capacit√† di gestire multiple esecuzioni che progrediscono nello stesso arco temporale attraverso multiplexing (time-sharing), tipicamente su un singolo core dove i thread si alternano rapidamente. Il parallelismo invece richiede multi-core.",
    "hint": "Si tratta di progresso simultaneo nel tempo, non di esecuzione fisica nello stesso istante."
  },
  {
    "question": "La comunicazione tra thread dello stesso processo rispetto a quella tra processi diversi:",
    "options": [
      {
        "text": "√à pi√π lenta poich√© i thread sono gestiti da librerie di alto livello",
        "image": ""
      },
      {
        "text": "√à pi√π veloce poich√© i thread non eseguono context switch",
        "image": ""
      },
      {
        "text": "√à pi√π veloce poich√© i thread condividono lo stesso spazio di indirizzamento",
        "image": ""
      },
      {
        "text": "Non c'√® alcuna differenza sostanziale in termini di performance",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "I thread di uno stesso processo condividono lo spazio di indirizzamento, permettendo comunicazione diretta tramite memoria condivisa senza costosi cambi di contesto o meccanismi IPC (pipe, socket) necessari tra processi diversi, che hanno spazi di indirizzamento isolati.",
    "hint": "Pensa alla visibilit√† delle variabili tra thread dello stesso processo rispetto a processi separati."
  },
  {
    "question": "Il kernel thread:",
    "options": [
      {
        "text": "Coincide sempre con uno ed un solo user thread",
        "image": ""
      },
      {
        "text": "√à gestito in spazio utente tramite un'apposita libreria",
        "image": ""
      },
      {
        "text": "√à la pi√π piccola unit√† schedulabile sulla CPU dal sistema operativo",
        "image": ""
      },
      {
        "text": "√à il termine con cui si identificano i processi propri del sistemaoperativo (i.e., non i processi utente)",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il kernel thread √® l'entit√† di esecuzione gestita direttamente dallo scheduler del sistema operativo, che ne controlla lo stato e l'allocazione sulla CPU tramite system call. √à pi√π leggero di un processo ma √® l'unit√† minima che il kernel pu√≤ schedulare autonomamente.",
    "hint": "Qual √® l'entit√† minima che il dispatcher del SO pu√≤ mettere in esecuzione sulla CPU?"
  },
  {
    "question": "L'uso di una primitiva di sincronizzazione lock prevede che:",
    "options": [
      {
        "text": "La lock sia inizialmente libera",
        "image": ""
      },
      {
        "text": "La lock venga acquisita prima dell'ingresso nella sezione critica",
        "image": ""
      },
      {
        "text": "La lock venga rilasciata dopo l'uscita dalla sezione critica",
        "image": ""
      },
      {
        "text": "Tutte le condizioni precedenti devono essere verificate",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Per garantire la mutua esclusione corretta, una lock deve essere inizialmente disponibile, acquisita prima di accedere alla risorsa condivisa e rilasciata subito dopo l'uso, altrimenti si verificherebbero deadlock o violazioni della sezione critica.",
    "hint": "Considera le tre fasi fondamentali: inizializzazione, ingresso nella sezione critica e uscita."
  },
  {
    "question": "L'acquisizione di una lock:",
    "options": [
      {
        "text": "Deve avvenire in modo atomico, evitando che lo scheduler interrompa l'acquisizione",
        "image": ""
      },
      {
        "text": "Necessita obbligatoriamente del supporto di istruzioni hardware atomiche",
        "image": ""
      },
      {
        "text": "Necessita obbligatoriamente che il sistema operativo disabiliti le interruzioni",
        "image": ""
      },
      {
        "text": "Nessuna delle risposte precedenti √® corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'atomicit√† dell'acquisizione √® essenziale per prevenire race condition durante l'operazione stessa di lock; se interrompibile, due processi potrebbero leggere contemporaneamente che la lock √® libera e acquisirla entrambi, violando la mutua esclusione.",
    "hint": "Cosa impedisce che due thread leggano contemporaneamente il valore 'libero' della stessa lock?"
  },
  {
    "question": "Un semaforo pu√≤ essere utilizzato per:",
    "options": [
      {
        "text": "Forzare le politiche di scheduling tra processi/thread",
        "image": ""
      },
      {
        "text": "Accedere al codice del kernel",
        "image": ""
      },
      {
        "text": "Lo scambio di messaggi tra processi/thread",
        "image": ""
      },
      {
        "text": "Gestire le interruzioni che giungono alla CPU",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "I semafori sono strumenti di sincronizzazione che regolano l'accesso a risorse condivise e coordinano l'esecuzione dei processi attraverso operazioni atomiche wait e signal, implementando politiche di ordinamento e controllo del flusso.",
    "hint": "Pensa a come un semaforo controlla quanti processi possono accedere contemporaneamente a una risorsa."
  },
  {
    "question": "L'invocazione del metodo wait() su un semaforo il cui valore √® pari a 2:",
    "options": [
      {
        "text": "Lascia invariato il valore del semaforo a 2 e fa proseguire il processo che ha eseguito l'invocazione (al netto delle politiche di scheduling)",
        "image": ""
      },
      {
        "text": "Decrementa il valore del semaforo a 1 e blocca il processo che ha eseguito l'invocazione",
        "image": ""
      },
      {
        "text": "Incrementa il valore del semaforo a 3 e fa proseguire il processo che ha eseguito l'invocazione (al netto delle politiche di scheduling)",
        "image": ""
      },
      {
        "text": "Decrementa il valore del semaforo a 1 e fa proseguire il processo che ha eseguito l'invocazione (al netto delle politiche di scheduling)",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'operazione wait() decrementa il valore del semaforo; se il risultato √® non negativo (come nel caso da 2 a 1), il processo prosegue immediatamente, mentre il blocco avviene solo quando il valore diventa negativo dopo il decremento.",
    "hint": "Ricorda che wait() blocca il processo solo quando il contatore diventa negativo, altrimenti prosegue."
  },
  {
    "question": "L'istruzione test-and-set:",
    "options": [
      {
        "text": "√à un'istruzione atomica che consente di implementare le primitive di sincronizzazione",
        "image": ""
      },
      {
        "text": "√à un'istruzione atomica che consente di disabilitare le interruzioni",
        "image": ""
      },
      {
        "text": "√à un'istruzione atomica che consente di aggiornare i valori di pi√π registri simultaneamente",
        "image": ""
      },
      {
        "text": "√à un'istruzione atomica che consente di resettare il valore di un semaforo",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Test-and-set √® un'istruzione hardware atomica che legge il valore di una variabile e la imposta a 1 in un'unica operazione indivisibile; costituisce il fondamento per implementare spinlock e mutex in modo corretto.",
    "hint": "√à un'operazione Read-Modify-Write atomica usata come base per costruire meccanismi di mutua esclusione."
  },
  {
    "question": "La differenza tra deadlock e starvation risiede nel fatto che:",
    "options": [
      {
        "text": "Si riferiscono a codice utente e codice di sistema (rispettivamente)",
        "image": ""
      },
      {
        "text": "Nel caso di starvation tutto il sistema √® completamente bloccato",
        "image": ""
      },
      {
        "text": "Non vi √® alcuna differenza",
        "image": ""
      },
      {
        "text": "Nel caso di deadlock tutto il sistema √® completamente bloccato",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il deadlock si verifica quando due o pi√π processi sono bloccati in un ciclo di attesa circolare per risorse, impedendo a quei processi di procedere. La starvation invece si riferisce a una situazione in cui un processo specifico rimane indefinitamente in attesa di una risorsa perch√© altri processi l'hanno sempre precedenza, ma il sistema nel complesso continua a operare.",
    "hint": "Pensa alla differenza tra un blocco circolare reciproco e un'attesa indefinita causata da priorit√† o politiche di scheduling."
  },
  {
    "question": "Con il termine address binding si intende:",
    "options": [
      {
        "text": "Il processo di traduzione da indirizzi logici a indirizzi fisici",
        "image": ""
      },
      {
        "text": "Il processo di inizializzazione delle variabili globali di un programma",
        "image": ""
      },
      {
        "text": "Il processo di collegamento tra il codice compilato ed eventuali librerie esterne",
        "image": ""
      },
      {
        "text": "Nessuna delle risposte precedenti √® corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'address binding √® il meccanismo che associa gli indirizzi logici (virtuali) generati dal programma agli indirizzi fisici della memoria RAM. Questo mapping pu√≤ avvenire in tempi diversi (compile, load o execution time) ed √® fondamentale per la gestione della memoria virtuale.",
    "hint": "Considera il passaggio dalla visione astratta del programma alla sua collocazione concreta in memoria fisica."
  },
  {
    "question": "Lo swapping consente di:",
    "options": [
      {
        "text": "Implementare la rilocazione dinamica del codice di un processo",
        "image": ""
      },
      {
        "text": "Risolvere il problema della frammentazione esterna",
        "image": ""
      },
      {
        "text": "Trasferire temporaneamente su disco i processi che non sono attualmente in esecuzione",
        "image": ""
      },
      {
        "text": "Scambiare le aree di memoria occupate da due o pi√π processi",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Lo swapping (o scambio) consiste nel trasferire interi processi dalla memoria principale al disco (swap out) e viceversa (swap in) per gestire la sovrapposizione di pi√π processi rispetto alla memoria fisica disponibile. Questo permette di sospendere temporaneamente processi inattivi per liberare spazio.",
    "hint": "Immagina cosa succede quando la RAM √® piena e il sistema operativo deve fare spazio per un processo pronto all'esecuzione."
  },
  {
    "question": "La gestione 'paginata' della memoria (paging):",
    "options": [
      {
        "text": "Prevede che lo spazio di indirizzamento logico di un processo sia non-contiguo e suddiviso in blocchi di dimensioni fissate (pages)",
        "image": ""
      },
      {
        "text": "Non richiede alcun supporto hardware per essere implementata in modo efficiente",
        "image": ""
      },
      {
        "text": "Prevede che lo spazio di indirizzamento fisico di un processo sia non-contiguo e suddiviso in blocchi di dimensioni fissate (frames)",
        "image": ""
      },
      {
        "text": "Risolve il problema della frammentazione interna",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nella paginazione, la memoria fisica √® suddivisa in blocchi di dimensione fissa chiamati frame (o page frames), mentre lo spazio logico del processo √® suddiviso in pagine della stessa dimensione. Le pagine possono essere allocate in frame non contigui, eliminando la frammentazione esterna.",
    "hint": "Distingui attentamente tra l'organizzazione dello spazio logico del processo (pagine) e quello della memoria fisica (frame)."
  },
  {
    "question": "La cache TLB (Translation Look-aside Buffer)",
    "options": [
      {
        "text": "E' condivisa tra tutti i processi del sistema",
        "image": ""
      },
      {
        "text": "Consente una traduzione mediamente pi√π rapida degli indirizzi logici",
        "image": ""
      },
      {
        "text": "Contiene un sottoinsieme delle entry della page table",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La TLB √® una cache associativa hardware che memorizza le traduzioni di indirizzi recentemente utilizzate (entry della page table) per evitare accessi costanti alla memoria principale. √à condivisa tra i processi (spesso con invalidazione al context switch) e riduce significativamente il tempo medio di accesso alla memoria.",
    "hint": "Ricorda che si tratta di una cache di traduzione che ottimizza l'accesso alla memoria evitando la doppia consultazione della page table in RAM."
  },
  {
    "question": "La dimensione (i.e., il numero di entry) della page table:",
    "options": [
      {
        "text": "√à direttamente proporzionale alla dimensione (fissata) delle pagine",
        "image": ""
      },
      {
        "text": "Si adatta a seconda delle richieste di accesso alla memoria di ciascun processo",
        "image": ""
      },
      {
        "text": "Dipende dalla dimensione (fissata) delle pagine",
        "image": ""
      },
      {
        "text": "Varia dinamicamente a seconda del processo",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il numero di entry nella page table √® determinato dividendo lo spazio di indirizzamento virtuale per la dimensione della pagina; pertanto, una volta fissata la dimensione delle pagine, anche il numero di entry risulta conseguentemente determinato.",
    "hint": "Considera la formula: numero di entry = spazio di indirizzamento / dimensione pagina."
  },
  {
    "question": "La dimensione (i.e., il numero di entry) della page table:",
    "options": [
      {
        "text": "Varia dinamicamente a seconda del processo",
        "image": ""
      },
      {
        "text": "E' direttamente proporzionale alla dimensione (fissata)",
        "image": ""
      },
      {
        "text": "E' inversamente proporzionale alla dimensione (fissata) delle pagine",
        "image": ""
      },
      {
        "text": "Si adatta a seconda delle richieste di accesso alla memoria di ciascun processo",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Se la dimensione delle pagine aumenta, il numero di pagine necessarie per coprire lo stesso spazio di indirizzamento virtuale diminuisce proporzionalmente, riducendo quindi il numero di entry nella page table in modo inversamente proporzionale.",
    "hint": "Se raddoppi la dimensione delle pagine, il numero di entry necessarie si dimezza."
  },
  {
    "question": "Un compilatore genera l'indirizzo logico 576 per riferirsi ad una certa locazione di memoria fisica. Assumendo che la traduzione degli indirizzi avvenga tramite rilocazione statica con indirizzo fisico base = 24, quale sar√† l'indirizzo fisico corrispondente?",
    "options": [
      {
        "text": "576",
        "image": ""
      },
      {
        "text": "552",
        "image": ""
      },
      {
        "text": "600",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere al problema",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Nella rilocazione statica, per verificare che l'indirizzo logico sia valido e non ecceda i limiti del processo √® necessario conoscere anche la dimensione del processo (limite), informazione non fornita nel problema.",
    "hint": "Oltre alla base, serve il limite per controllare che l'offset sia entro i confini del processo."
  },
  {
    "question": "Si consideri un processo di dimensione pari a 2,488 bytes e un blocco di memoria libero di dimensione pari a 2,699 bytes. In questo caso, assumendo il vincolo di allocazione contigua della memoria, la scelta pi√π conveniente √®:",
    "options": [
      {
        "text": "Allocare l'intero blocco al processo, sprecando 211 bytes(frammentazione interna)",
        "image": ""
      },
      {
        "text": " Allocare la porzione del blocco necessaria al processo e aggiungere alla lista dei blocchi liberi i 211 bytes rimanente(frammentazione esterna)",
        "image": ""
      },
      {
        "text": "Attendere che vi sia un blocco di dimensione multipla rispetto a quella del processo",
        "image": ""
      },
      {
        "text": "Attendere che vi sia un blocco di dimensione inferiore adatto a contenere il processo",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Nell'allocazione contigua a partizioni fisse, un processo occupa un intero blocco di memoria anche se non lo riempie completamente, generando frammentazione interna pari alla differenza tra dimensione del blocco e del processo.",
    "hint": "Con blocchi di dimensione fissa, lo spazio in eccesso rimane inutilizzato all'interno del blocco allocato."
  },
  {
    "question": "Si consideri un processo di dimensione pari a 4,996 e un blocco di memoria libero di dimensione pari a 5,016 bytes. In questo caso, assumendo il vincolo di allocazione contigua della memoria, la scelta pi√π conveniente √®:",
    "options": [
      {
        "text": "Attendere che vi sia un blocco di dimensione inferiore adatto a contenere il processo",
        "image": ""
      },
      {
        "text": "Allocare l'intero blocco al processo, sprecando 20 bytes(frammentazione interna)",
        "image": ""
      },
      {
        "text": "Attendere che vi sia un blocco di dimensione multipla rispetto a quella dei processi",
        "image": ""
      },
      {
        "text": "Allocare la porzione del blocco necessaria al processo e aggiungere alla lista dei blocchi liberi i 20 bytes rimanenti(frammentazione esterna)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In sistemi con allocazione a partizioni fisse, il processo viene caricato in un blocco di dimensione prefissata e lo spazio rimanente (20 bytes) costituisce frammentazione interna, non recuperabile per altri processi.",
    "hint": "La frammentazione interna si verifica quando lo spazio allocato √® maggiore di quello richiesto all'interno di un blocco fisso."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 99 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D le cui dimensioni sono rispettivamente 102 KiB, 99 KiB, 256 KiB e 128 KiB, quale blocco verr√† allocato per P assumendo una politica Worst-Fit?",
    "options": [
      {
        "text": "blocco A",
        "image": ""
      },
      {
        "text": "blocco C",
        "image": ""
      },
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "blocco D",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La politica Worst-Fit seleziona il blocco libero di dimensione maggiore tra quelli che soddisfano la richiesta, al fine di ridurre la frammentazione esterna lasciando blocchi residui pi√π grandi. Il blocco C (256 KiB) √® il pi√π grande disponibile tra quelli sufficienti per i 99 KiB richiesti.",
    "hint": "Cerca il blocco pi√π grande che possa contenere il processo."
  },
  {
    "question": " Si supponga che un processo P necessiti di un'area di memoria libera pari a 99 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D, E, F le cui dimensioni sono rispettivamente 300 KiB, 600 KiB, 350 KiB, 200 KiB, 750 KiB e 125 KiB, quale blocco verr√† allocato per P assumendo una politica Worst-Fit?",
    "options": [
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "Non √® possibile soddisfare la richiesta, pertanto P dovr√† attendere",
        "image": ""
      },
      {
        "text": "C e i restati 25 KiB vengono allocati su A",
        "image": ""
      },
      {
        "text": "blocco E",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Worst-Fit alloca sempre il blocco di memoria pi√π grande disponibile che possa contenere il processo. Tra i blocchi elencati, E (750 KiB) √® quello di dimensione maggiore e pu√≤ ospitare i 99 KiB richiesti.",
    "hint": "Identifica il blocco con la dimensione massima nella lista."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 128 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D le cui dimensioni sono rispettivamente 105 KiB, 916 KiB, 129 KiB e 80 KiB, quale blocco verr√† allocato per P assumendo una politica First-Fit?",
    "options": [
      {
        "text": "blocco A",
        "image": ""
      },
      {
        "text": "blocco D",
        "image": ""
      },
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "blocco C",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La strategia First-Fit scorre la lista dei blocchi liberi dall'inizio e seleziona il primo blocco di dimensione sufficiente. Il blocco A (105 KiB) √® troppo piccolo, mentre il blocco B (916 KiB) √® il primo che pu√≤ contenere i 128 KiB richiesti.",
    "hint": "Scansiona la lista dall'inizio e fermati al primo blocco abbastanza grande."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 115 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D,E,F le cui dimensioni sono rispettivamente 300 KiB, 600 KiB, 350 KiB, 200 KiB,750 KiB e 125 KiB quale blocco verr√† allocato per P assumendo una politica First-Fit?",
    "options": [
      {
        "text": "blocco A",
        "image": ""
      },
      {
        "text": "blocco F",
        "image": ""
      },
      {
        "text": "blocco E",
        "image": ""
      },
      {
        "text": "blocco D",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Con First-Fit, si alloca il primo blocco nella lista che abbia dimensione maggiore o uguale alla richiesta. Il blocco A (300 KiB) √® il primo che soddisfa questa condizione per i 115 KiB necessari.",
    "hint": "Controlla i blocchi in ordine sequenziale: il primo che supera i 115 KiB √® la risposta."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 375 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D,E,F le cui dimensioni sono rispettivamente 300 KiB, 600 KiB, 350 KiB, 200 KiB,750 KiB e 125 KiB quale blocco verr√† allocato per P assumendo una politica Best-Fit?",
    "options": [
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "blocco C e i restanti 25 Kib vengono allocati su A",
        "image": ""
      },
      {
        "text": "blocco E",
        "image": ""
      },
      {
        "text": "Non √® possibile soddisfare la richiesta, pertanto P dovr√† attendere",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Best-Fit cerca il blocco pi√π piccolo tra quelli che possono contenere la richiesta, minimizzando lo spreco di memoria. Tra i blocchi sufficienti (B da 600 KiB ed E da 750 KiB), B √® quello che lascia lo spreco minore.",
    "hint": "Cerca il blocco che spreca meno spazio tra quelli che possono contenere 375 KiB."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 34 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D le cui dimensioni sono rispettivamente 36 KiB, 90 KiB, 42 KiB e 35 KiB, quale blocco verr√† allocato per P assumendo una politica Best-Fit?",
    "options": [
      {
        "text": "blocco A",
        "image": ""
      },
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "blocco C",
        "image": ""
      },
      {
        "text": "blocco D",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La politica Best-Fit seleziona il blocco di memoria libera pi√π piccolo che sia sufficiente a contenere il processo, minimizzando lo spreco di memoria. Tra i blocchi disponibili, D (35 KiB) √® il pi√π piccolo che pu√≤ contenere 34 KiB, lasciando solo 1 KiB inutilizzato contro i 2 KiB di A, 8 KiB di C e 56 KiB di B.",
    "hint": "Cerca il blocco che lascia lo spazio residuo minimo tra quelli sufficientemente grandi."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 4 KiB, ossia 4,096 bytes. Assumendo che l'indirizzamento avvenga con lunghezza di parola (word size) pari 2 bytes e che M utilizzi una gestione paginata con blocchi di dimensione pari a S = 128 bytes, quanti bit sono necessari per identificare l'indice di pagina (p) e l'offset (interno alla pagina), rispettivamente?",
    "options": [
      {
        "text": "p=6; offset=5",
        "image": ""
      },
      {
        "text": "b.p=7; offset=5",
        "image": ""
      },
      {
        "text": "p=5; offset=7",
        "image": ""
      },
      {
        "text": "p=5; offset=6",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Con blocchi di 128 bytes, l'offset richiede log‚ÇÇ(128) = 7 bit. La memoria totale di 4 KiB contiene 4096/128 = 32 frame, che richiedono log‚ÇÇ(32) = 5 bit per l'indirizzamento della pagina.",
    "hint": "Calcola quanti frame ci sono in totale e quanti bit servono per indirizzare all'interno di un singolo frame."
  },
  {
    "question": "Si consideri una memoria M di capacit√† pari a 512 bytes con frame di dimensione pari a 16 bytes. Dato l'indirizzo del byte 197, quale sar√† l'indirizzo di pagina (p) e l'offset (interno alla pagina):",
    "options": [
      {
        "text": "p=5; offset=12",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "p=13; offset=0",
        "image": ""
      },
      {
        "text": "p=12; offset=5",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'indirizzo di pagina si calcola come divisione intera tra l'indirizzo logico e la dimensione del frame (197 √∑ 16 = 12), mentre l'offset √® il resto della divisione (197 mod 16 = 5).",
    "hint": "Dividi l'indirizzo per la dimensione del frame: il quoziente √® la pagina, il resto √® l'offset."
  },
  {
    "question": "Si consideri una memoria M di capacit√† pari a 100 bytes con frame di dimensione pari a 10 bytes. Dato l‚Äôindirizzo del byte 37, quale sar√† l‚Äôindirizzo di pagina (p) e l‚Äôoffset (interno alla pagina).",
    "options": [
      {
        "text": "p=3; offset=7",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "p=7; offset=3",
        "image": ""
      },
      {
        "text": "p=0; offset=37",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Con frame di 10 bytes, l'indirizzo 37 cade nella pagina 3 (37 √∑ 10 = 3 con resto 7), quindi offset 7. La dimensione totale della memoria non √® necessaria per il calcolo.",
    "hint": "Usa la divisione intera per trovare la pagina e il modulo per l'offset."
  },
  {
    "question": "Si consideri un processo di dimensione pari a 2,097 bytes e un blocco di memoria libero di dimensione pari a 2,104 bytes. In questo caso, assumendo il vincolo di allocazione contigua della memoria, la scelta pi√π conveniente √®:",
    "options": [
      {
        "text": "Attendere che vi sia un blocco di dimensione multipla rispetto a quella del processo",
        "image": ""
      },
      {
        "text": "Allocare l'intero blocco al processo, sprecando 7 bytes (frammentazione interna)",
        "image": ""
      },
      {
        "text": "Attendere che vi sia un blocco di dimensione inferiore adatto a contenere il processo",
        "image": ""
      },
      {
        "text": "Allocare la porzione del blocco necessaria al processo e aggiungere alla lista dei blocchi liberi i 7 bytes rimanenti (frammentazione esterna)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In un sistema di allocazione contigua con partizioni fisse, il processo occupa l'intero blocco assegnato, generando frammentazione interna pari alla differenza tra dimensione blocco e processo (7 bytes). Non √® possibile dividere il blocco per evitare sprechi in questo modello.",
    "hint": "Nell'allocazione contigua con blocchi prefissati, il processo prende tutto lo spazio assegnato anche se non lo riempie completamente."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 2 KiB, ossia 2,048 bytes. Assumendo che l‚Äôindirizzamento avvenga con lunghezza di parola (word size) pari a 4 bytes, quanti bit sono necessari ad indirizzare le parole contenute in M?",
    "options": [
      {
        "text": "2",
        "image": ""
      },
      {
        "text": "9",
        "image": ""
      },
      {
        "text": "11",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere al problema",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La memoria contiene 2048/4 = 512 parole. Per indirizzare 512 locazioni distinte servono log‚ÇÇ(512) = 9 bit, poich√© 2‚Åπ = 512.",
    "hint": "Calcola prima il numero totale di parole dividendo la capacit√† per la word size, poi calcola il logaritmo in base 2."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 4 KiB ossia 4,096 bytes. Assumendo che l‚Äôindirizzamento avvenga con lunghezza di parola (word size) pari a 2 bytes, quanti bit sono necessari ad indirizzare le parole contenute in M?",
    "options": [
      {
        "text": "10",
        "image": ""
      },
      {
        "text": "11",
        "image": ""
      },
      {
        "text": "12",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La memoria contiene 4096/2 = 2048 parole. Per indirizzare 2048 locazioni distinte servono log‚ÇÇ(2048) = 11 bit, poich√© 2¬π¬π = 2048.",
    "hint": "Ricorda che il numero di bit necessari corrisponde all'esponente della potenza di 2 che d√† il numero totale di parole."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 8 KiB, ossia 8,192 bytes. Assumendo che l'indirizzamento avvenga con lunghezza di parola (word size) pari al singolo byte e che M utilizzi una gestione paginata con blocchi di dimensione pari a S = 128 bytes, quale dimensione (intesa come numero di entry) ha la corrispondente page table T?",
    "options": [
      {
        "text": "I dati sono insufficienti per rispondere al problema",
        "image": ""
      },
      {
        "text": "13",
        "image": ""
      },
      {
        "text": "64",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La page table ha una entry per ogni pagina fisica. Con 8192 byte di memoria e pagine da 128 byte, si ottengono 8192/128 = 64 pagine.",
    "hint": "Il numero di entry √® dato dal rapporto tra la capacit√† totale della memoria e la dimensione del blocco di paginazione."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 8 KiB, ossia 8,192 bytes. Assumendo che l‚Äôindirizzamento avvenga con lunghezza di parola (word size) pari a 4 bytes e che M utilizzi una gestione paginata con blocchi di dimensione pari a S = 256 bytes, quale sar√† il numero di entry della corrispondente page table T?",
    "options": [
      {
        "text": "32",
        "image": ""
      },
      {
        "text": "2048",
        "image": ""
      },
      {
        "text": "8",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La dimensione della page table dipende solo dal numero di pagine fisiche, non dalla word size. Con 8192 byte e pagine da 256 byte, si hanno 8192/256 = 32 pagine.",
    "hint": "La word size non influenza il numero di pagine; dividi semplicemente la capacit√† totale per la dimensione del blocco."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 16 KiB, ossia 16,384 bytes. Assumendo che l‚Äôindirizzamento avvenga con lunghezza di parola (word size) pari a 4 bytes e che M utilizzi una gestione paginata con blocchi di dimensione pari a S = 64 bytes, quale sar√† il numero di entry della corrispondente page table T?",
    "options": [
      {
        "text": "a",
        "image": ""
      },
      {
        "text": "b",
        "image": ""
      },
      {
        "text": "c",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere al problema",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Con 16384 byte di memoria e blocchi da 64 byte, si ottengono 16384/64 = 256 pagine fisiche, quindi la page table contiene 256 entry.",
    "hint": "Calcola il rapporto tra la capacit√† totale (16 KiB) e la dimensione del blocco (64 byte) per trovare il numero di entry."
  },
  {
    "question": "Si consideri un sistema operativo che utilizza indirizzi logici da 21 bit, indirizzo fisico da 16 bit e memoria paginata in cui ciascuna pagina ha dimensione 2 KiB(2048 bytes). Qual √® la dimensione massima di memoria fisica supportata dal sistema?",
    "options": [
      {
        "text": "32 KiB",
        "image": ""
      },
      {
        "text": "64 KiB",
        "image": ""
      },
      {
        "text": "2 MiB",
        "image": ""
      },
      {
        "text": "Non esiste un limite fisico alla memoria supportata dal sistema",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La dimensione della memoria fisica √® determinata esclusivamente dalla lunghezza dell'indirizzo fisico: con 16 bit si possono indirizzare 2^16 = 65536 byte, ovvero 64 KiB. La dimensione della pagina e l'indirizzo logico sono irrilevanti per questo calcolo specifico.",
    "hint": "Calcola quanti byte puoi indirizzare con 16 bit, indipendentemente dalla paginazione."
  },
  {
    "question": "La memoria virtuale consente di:",
    "options": [
      {
        "text": "Aumentare l'efficienza delle operazioni di I/O",
        "image": ""
      },
      {
        "text": "Mantenere allocate in memoria fisica solo alcune pagine dello spazio di indirizzamento logico di un processo",
        "image": ""
      },
      {
        "text": "Diminuire il grado di multiprogrammazione del sistema",
        "image": ""
      },
      {
        "text": "Eseguire un processo direttamente dai dispositivi di memoria secondaria (e.g., disco)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La memoria virtuale separa lo spazio degli indirizzi logici da quello fisico, permettendo di mantenere in RAM solo le pagine necessarie (working set) mentre il resto risiede su disco. Questo consente di eseguire processi pi√π grandi della memoria fisica disponibile.",
    "hint": "Pensa al concetto di 'working set' e alla separazione tra spazio logico e fisico."
  },
  {
    "question": "Se un'istruzione idempotente genera un page fault:",
    "options": [
      {
        "text": "Il processo di cui fa parte l'istruzione termina",
        "image": ""
      },
      {
        "text": "Le istruzioni idempotenti non possono generare page fault",
        "image": ""
      },
      {
        "text": "L'istruzione non verr√† pi√π eseguita una volta effettuato il ritorno dalla gestione del page fault",
        "image": ""
      },
      {
        "text": "L'istruzione verr√† nuovamente eseguita al ritorno dalla gestione del page fault",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Le istruzioni idempotenti producono lo stesso risultato anche se eseguite multiple volte con gli stessi operandi. Quando si verifica un page fault, il sistema operativo carica la pagina mancante e riesegue l'istruzione dall'inizio, operazione sicura proprio grazie all'idempotenza.",
    "hint": "Cosa significa che un'operazione √® idempotente e come questo facilita la ripresa dopo un interrupt?"
  },
  {
    "question": ".Il problema della frammentazione esterna:",
    "options": [
      {
        "text": "Necessita di un supporto hardware per essere risolto",
        "image": ""
      },
      {
        "text": "Non √® risolvibile a meno di un riavvio del sistema",
        "image": ""
      },
      {
        "text": "E‚Äô una conseguenza del vincolo di allocazione contigua della memoria",
        "image": ""
      },
      {
        "text": "Causa un‚Äôinterruzione hardware",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La frammentazione esterna si verifica negli schemi di allocazione contigua quando la memoria libera √® frammentata in blocchi non contigui troppo piccoli per soddisfare richieste successive. Questo √® una conseguenza diretta del vincolo di allocare processi in blocchi di memoria contigua.",
    "hint": "Considera cosa succede quando processi di dimensioni diverse rilasciano blocchi di memoria in uno schema di allocazione contigua."
  },
  {
    "question": "Il problema della frammentazione esterna",
    "options": [
      {
        "text": "Non √® risolvibile a meno di un riavvio del sistema",
        "image": ""
      },
      {
        "text": "Causa un‚Äôinterruzione hardware",
        "image": ""
      },
      {
        "text": "Necessita di un supporto hardware per essere risolto",
        "image": ""
      },
      {
        "text": "E‚Äô dovuto all‚Äô allocazione/deallocazione di blocchi contigui di memoria",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La frammentazione esterna √® causata specificatamente dall'allocazione e deallocazione dinamica di blocchi contigui di dimensioni variabili, che crea 'buchi' sparsi nella memoria. Questo fenomeno √® intrinseco ai sistemi di allocazione contigua come le partizioni dinamiche.",
    "hint": "Rifletti sul risultato dell'allocazione e rilascio ripetuto di blocchi di memoria di dimensioni diverse in uno schema contiguo."
  },
  {
    "question": "Il working set √®:",
    "options": [
      {
        "text": "Fissato per ogni quanto di tempo",
        "image": ""
      },
      {
        "text": "Relativamente grande rispetto all‚Äôintero spazio di indirizzamento di un processo",
        "image": ""
      },
      {
        "text": "Relativamente piccolo rispetto all‚Äôintero spazio di indirizzamento di un processo",
        "image": ""
      },
      {
        "text": "Fissato per l‚Äôintera esecuzione di un processo",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il working set rappresenta l'insieme delle pagine attivamente utilizzate da un processo in un dato intervallo di tempo, riflettendo il principio di localit√† dei riferimenti. Tipicamente √® molto pi√π piccolo dello spazio di indirizzamento totale perch√© i programmi accedono solo a una porzione limitata del loro codice/dati in ogni istante.",
    "hint": "Pensa al principio di localit√†: quante pagine usa realmente un processo in un dato momento rispetto alla sua memoria totale?"
  },
  {
    "question": "Si consideri un sistema che implementa la politica LRU per la sostituzione dei frame mediante l‚Äôuso di un timestamp. Ad ogni richiesta di accesso ad un determinato frame occorre:",
    "options": [
      {
        "text": "Incrementare una variabile di tipo contatore",
        "image": ""
      },
      {
        "text": "Aggiornare il valore del timestamp con quello corrente",
        "image": ""
      },
      {
        "text": "Impostare un bit di validit√†",
        "image": ""
      },
      {
        "text": "Nessuna delle precedenti risposte √® corretta",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo LRU (Least Recently Used) richiede di identificare la pagina non utilizzata da pi√π tempo. Utilizzando un timestamp, ogni accesso a un frame deve aggiornare il suo timestamp al valore corrente per marcarlo come 'recentemente usato', permettendo di individuare il meno recente come quello con timestamp pi√π vecchio.",
    "hint": "LRU significa 'Least Recently Used': come tieni traccia dell'ultimo utilizzo con un timestamp?"
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: B, C, C, B, A, E, B, A, E, D, B. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo LRU di sostituzione delle pagine.",
    "options": [
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      },
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Simulando l'algoritmo LRU con 3 frame inizialmente vuoti, si verificano page fault su B, C, A, E, D, B. Le prime due richieste riempiono i frame, A occupa il terzo, E sostituisce C (LRU), poi D sostituisce B, e infine B sostituisce A.",
    "hint": "Tieni traccia dell'ordine di utilizzo; quando i frame sono pieni, sostituisci la pagina non acceduta da pi√π tempo."
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: D, B, A, C, C, E, A, D, B, E, D, A. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo LRU di sostituzione delle pagine.",
    "options": [
      {
        "text": "10",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "9",
        "image": ""
      },
      {
        "text": "6",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Con 3 frame e algoritmo LRU, la sequenza genera page fault su D, B, A, C, E, D, B, E, A. Dopo aver riempito i tre frame iniziali con D, B, A, ogni nuova pagina diversa (C, E, D, B, E, A) causa un fault sostituendo la pagina meno recentemente utilizzata.",
    "hint": "Ricorda che ad ogni accesso (hit o fault) la pagina diventa la pi√π recente; traccia attentamente l'ordine di invecchiamento."
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: C,B,C,B,A,E,B,A. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo LRU di sostituzione delle pagine.",
    "options": [
      {
        "text": "2",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      },
      {
        "text": "1",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "I page fault si verificano su C, B, A, E. Le pagine C e B sono caricate nei primi due frame, poi A riempie il terzo. Quando arriva E, deve sostituire la pagina meno recentemente usata (C), mentre i successivi accessi a B e A sono hit.",
    "hint": "Nota che C e B vengono riutilizzate prima che i frame si riempiano, riducendo il numero totale di fault."
  },
  {
    "question": "Data una memoria fisica composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: A, B, E, C, E, D, D, A, B. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo FIFO di sostituzione delle",
    "options": [
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "8",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Con l'algoritmo FIFO e 3 frame, la sequenza A,B,E,C,E,D,D,A,B genera fault iniziali per A,B,E, poi C sostituisce A (il pi√π vecchio), E √® gi√† presente (hit), D sostituisce B, D √® presente (hit), A sostituisce E, e infine B sostituisce C, per un totale di 7 page fault.",
    "hint": "Traccia l'ordine di arrivo delle pagine nei frame per determinare quale viene sostituita ad ogni fault."
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: D, A, C, B, B, A, C, B, D, E, A. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo FIFO di sostituzione delle pagine.",
    "options": [
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Utilizzando FIFO su 3 frame, si verificano fault per D,A,C,B (riempimento e prima sostituzione), poi hit per B,A,C,B, quindi D sostituisce A, E sostituisce C, e infine A sostituisce B, arrivando a 7 fault totali.",
    "hint": "Ricorda che dopo una sostituzione, la nuova pagina diventa l'ultima arrivata per le future sostituzioni."
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: E, B, E, C, D, E, A, B, E. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo FIFO di sostituzione delle pagine.",
    "options": [
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "8",
        "image": ""
      },
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Con FIFO e 3 frame, la sequenza E,B,E,C,D,E,A,B,E produce fault per E,B (riempimento), C (terzo frame), poi D sostituisce E, E sostituisce B, A sostituisce C, B sostituisce D, mentre l'ultima E √® gi√† in memoria (hit), per un totale di 7 fault.",
    "hint": "Verifica attentamente qual √® la pagina pi√π vecchia residente quando si verifica un fault dopo il riempimento iniziale."
  },
  {
    "question": "L'allocazione contigua di un file su disco:",
    "options": [
      {
        "text": "√à ottima sia per l'accesso diretto (random) che per quello sequenziale",
        "image": ""
      },
      {
        "text": "Presenta il problema della frammentazione",
        "image": ""
      },
      {
        "text": "Necessita il mantenimento dei blocchi liberi all'interno di una opportuna struttura dati",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'allocazione contigua memorizza file in blocchi consecutivi, consentendo accesso sequenziale e diretto efficiente tramite calcolo dell'indirizzo, ma soffre di frammentazione esterna e richiede strutture dati (bitmap o tabelle) per gestire lo spazio libero.",
    "hint": "Considera sia i vantaggi in termini di velocit√† di accesso che gli svantaggi legati alla gestione dello spazio dinamico."
  },
  {
    "question": "L‚Äôallocazione contigua di un file su un disco √® la scelta preferibile quando il disco √®:",
    "options": [
      {
        "text": "Un CD/DVD-ROM in sola lettura",
        "image": ""
      },
      {
        "text": "Un disco magnetico",
        "image": ""
      },
      {
        "text": "Un disco a stato solido",
        "image": ""
      },
      {
        "text": "In nessuno dei casi precedenti",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'allocazione contigua √® ideale per CD/DVD-ROM poich√© i dati vengono scritti una sola volta in modo sequenziale senza cancellazioni, eliminando il problema della frammentazione esterna e sfruttando l'efficienza dell'accesso sequenziale su dispositivi ottici.",
    "hint": "Pensa a quali supporti non permettono modifiche ai file gi√† scritti, rendendo irrilevante il problema principale dell'allocazione contigua."
  },
  {
    "question": "In un disco magnetico, il seek time:",
    "options": [
      {
        "text": "√à il tempo necessario al disco per posizionare le proprie testine su uno specifico settore",
        "image": ""
      },
      {
        "text": "Include il tempo di trasferimento alla memoria principale",
        "image": ""
      },
      {
        "text": "√à il tempo necessario al disco per posizionare le proprie testine su uno specifico cilindro",
        "image": ""
      },
      {
        "text": "√à trascurabile rispetto all'intero tempo necessario al trasferimento dei dati",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il seek time rappresenta il tempo necessario per spostare il braccio del disco e posizionare le testine sul cilindro (traccia) corretto. Non include il tempo di rotazione per trovare il settore (rotational latency) n√© il tempo di trasferimento dati.",
    "hint": "Distingui tra lo spostamento del braccio sul cilindro e la ricerca del settore specifico all'interno della traccia."
  },
  {
    "question": "Un disco √® composto da 15 cilindri, ciascuno di capacit√† pari a 500 MB. Qual √® la capacit√† totale del disco?",
    "options": [
      {
        "text": "7.5 GB",
        "image": ""
      },
      {
        "text": "75 GB",
        "image": ""
      },
      {
        "text": "750 MB",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere al problema4",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La capacit√† totale si ottiene moltiplicando il numero di cilindri per la capacit√† di ciascuno: 15 √ó 500 MB = 7500 MB = 7.5 GB. Questo calcolo assume che ogni cilindro contenga tutte le tracce sui vari piatti a quella specifica distanza dal centro.",
    "hint": "Converti 7500 MB in GB ricordando che 1 GB = 1000 MB nel sistema decimale usato per le unit√† di storage."
  },
  {
    "question": "Si supponga che il tempo di accesso alla memoria fisica sia tMA = 50 nsec. e che il tempo per la gestione di un page fault tFAULT  sia pari a 15 msec. Assumendo che la probabilit√† che si verifichi un page fault sia p = 0.0002, qual √® il tempo complessivo atteso di accesso alla memoria?",
    "options": [
      {
        "text": "~30.5 nsec",
        "image": ""
      },
      {
        "text": "~30.5 microsec",
        "image": ""
      },
      {
        "text": "~3.05 microsec",
        "image": ""
      },
      {
        "text": "~305 nsec",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il tempo medio di accesso si calcola con la formula pesata: EAT = (1-p)√ótMA + p√ótFAULT. Sostituendo i valori: 0.9998√ó50 nsec + 0.0002√ó15000000 nsec ‚âà 50 + 3000 = 3050 nsec = 3.05 Œºsec. Il page fault, pur essendo raro, domina il tempo totale a causa della sua elevata durata.",
    "hint": "Converti tutto in nanosecondi (15 msec = 15000000 nsec) e applica la media pesata; nota come il tempo di fault influenzi maggiormente il risultato finale."
  },
  {
    "question": "Si supponga che il tempo di accesso alla memoria fisica sia tMA = 25 nsec. e che il tempo per la gestione di un page fault  tFAULT sia pari a 30 msec. Assumendo che la probabilit√† che si verifichi un page fault sia p = 0.005, qual √® il tempo complessivo atteso di accesso alla memoria?",
    "options": [
      {
        "text": "~150.025 microsec",
        "image": ""
      },
      {
        "text": "~15.025 nsec",
        "image": ""
      },
      {
        "text": "~150.025 nsec",
        "image": ""
      },
      {
        "text": "~15.025 microsec",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Utilizzando la formula dell'accesso atteso EAT = (1-p)√ótMA + p√ótFAULT, si ottiene: 0.995√ó25 nsec + 0.005√ó30000000 nsec = 24.875 nsec + 150000 nsec = 150024.875 nsec ‚âà 150.025 Œºsec. La probabilit√† di fault pi√π elevata rispetto alla domanda precedente rende il tempo di gestione del fault predominante.",
    "hint": "Con p=0.5% il termine del page fault pesa molto di pi√π; converti 30 msec in nanosecondi e somma i due contributi ponderati."
  },
  {
    "question": "Si supponga che il tempo di accesso alla memoria fisica sia tMA = 50 nsec. e che il tempo per la gestione di un page fault tFAULT sia pari a 25 msec. Assumendo che il tempo medio di accesso alla memoria sia pari a 0.5 microsec, qual √® la probabilit√† p che si verifichi un page fault?",
    "options": [
      {
        "text": "~0.02%",
        "image": ""
      },
      {
        "text": "~0.2%",
        "image": ""
      },
      {
        "text": "~0.002%",
        "image": ""
      },
      {
        "text": "~0.0002%",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Dalla formula EAT = (1-p)√ótMA + p√ótFAULT, si ricava p = (EAT - tMA)/(tFAULT - tMA). Sostituendo: (500-50)/(25000000-50) ‚âà 450/25000000 = 0.000018 = 0.0018% ‚âà 0.002%. La probabilit√† √® estremamente bassa perch√© il tempo di fault √® molto maggiore del tempo di accesso normale.",
    "hint": "Isola p nell'equazione del tempo medio di accesso e risolvi l'equazione lineare; ricorda di convertire 0.5 microsec in 500 nsec per coerenza unitaria."
  },
  {
    "question": "Si supponga che il tempo di accesso alla memoria fisica sia tMA  = 60 nsec. e che il tempo per la gestione di un page fault tFAULT  sia pari a 5 msec. Quale dovr√† essere il valore della probabilit√† che si verifichi un fault () se si vuole garantire che il tempo atteso di accesso alla memoria sia al pi√π il 20% pi√π lento di tMA ? (Si ricordi che 1 msec = 10^3 microsec = 10^6 nsec)",
    "options": [
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "~0,00024%",
        "image": ""
      },
      {
        "text": " ~0,000024%",
        "image": ""
      },
      {
        "text": " ~0,0000024%",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il tempo di accesso atteso EAT = (1-p)¬∑tMA + p¬∑tFAULT. Imponendo EAT ‚â§ 1.2¬∑tMA = 72 nsec, si ottiene p ‚â§ (72-60)/(5¬∑10‚Å∂-60) ‚âà 12/5¬∑10‚Å∂ = 2.4¬∑10‚Åª‚Å∂, ovvero 0.00024%.",
    "hint": "Ricorda che il tempo atteso √® la media pesata tra accesso in memoria e gestione del fault, e che 5 msec = 5¬∑10‚Å∂ nsec."
  },
  {
    "question": "Si consideri un disco magnetico composto da 128 cilindri/tracce, numerati da 0 a 127 (0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 42. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 74, 50, 32, 55, 81 venga gestita da un algoritmo di scheduling SSTF (Shortest Seek Time First) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "86",
        "image": ""
      },
      {
        "text": "49",
        "image": ""
      },
      {
        "text": "123",
        "image": ""
      },
      {
        "text": "88",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo SSTF seleziona ad ogni passo la richiesta pi√π vicina alla posizione corrente della testina. Dalla posizione 42 la sequenza √®: 50 (distanza 8), 55 (5), 74 (19), 81 (7), 32 (49), per un totale di 88 cilindri attraversati.",
    "hint": "Calcola le distanze assolute da 42 a tutte le richieste, scegli la minima, ripeti dalla nuova posizione."
  },
  {
    "question": "Si consideri un disco magnetico composto da 128 cilindri/tracce, numerati da 0 a 127 (0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 87. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 43, 81, 36, 25, 127 venga gestita da un algoritmo di scheduling FCFS (First Come First Served) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "290",
        "image": ""
      },
      {
        "text": "240",
        "image": ""
      },
      {
        "text": "238",
        "image": ""
      },
      {
        "text": "265",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo FCFS serve le richieste in ordine di arrivo. La somma degli spostamenti √® |87-43| + |43-81| + |81-36| + |36-25| + |25-127| = 44 + 38 + 45 + 11 + 102 = 240 cilindri.",
    "hint": "Somma semplicemente le differenze assolute tra posizioni consecutive seguendo l'ordine della sequenza."
  },
  {
    "question": "Il tempo di trasferimento totale per un'operazione di I/O da disco magnetico √® pari a 30 msec. Sapendo che: il seek time complessivo √® pari a 18 msec, il rotational delay complessivo √® pari a 7 msec e che il transfer rate √® pari a 1.5 Gbit/sec, qual √® la quantit√† totale di dati trasferita? (Si ricordi che 1 B = 1 byte = 8 bit e 1 MB = 10^3 KB = 10^6 B)",
    "options": [
      {
        "text": "9.375 MB",
        "image": ""
      },
      {
        "text": "7.5 MB",
        "image": ""
      },
      {
        "text": "937.5 KB",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il tempo di trasferimento effettivo √® 30 - 18 - 7 = 5 msec. Moltiplicando per il transfer rate di 1.5 Gbit/s si ottengono 7.5 Mbit, che divisi per 8 danno 937.5 KB.",
    "hint": "Sottrai i tempi meccanici (seek e rotazione) dal tempo totale per ottenere il tempo effettivo di trasferimento dati."
  },
  {
    "question": "Il tempo di trasferimento totale per un'operazione di I/O da disco magnetico √® pari a 40 msec. Sapendo che: il seek time complessivo √® pari a 18 msec, il rotational delay complessivo √® pari a 7 msec e che il transfer rate √® pari a 5 Gbit/sec, qual √® la quantit√† totale di dati trasferita? (Si ricordi che 1 B = 1 byte = 8 bit e 1 MB = 10^3 KB = 10^6 B)",
    "options": [
      {
        "text": "9375 MB",
        "image": ""
      },
      {
        "text": "70 MB",
        "image": ""
      },
      {
        "text": "70 KB",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il tempo di trasferimento dati √® 40 - 18 - 7 = 15 msec. Con un rate di 5 Gbit/s si trasferiscono 75 Mbit, equivalenti a 9375 KB (o 9.375 MB). Il valore numerico 9375 corrisponde all'opzione A, considerando un'unit√† di misura diversa (KB invece di MB).",
    "hint": "Calcola il tempo netto di trasferimento (15 msec) e converti i Gbit in byte; il risultato numerico √® 9375 se espressi in KB."
  },
  {
    "question": "Il tempo di trasferimento totale per un'operazione di I/O da disco magnetico √® pari a 36 msec. Sapendo che il seek time complessivo √® pari a 13 msec e che sono stati trasferiti 2MB ad una velocit√† pari a 1 Gbit/sec qual √® il rotational delay del disco?(Si ricordi che 1 B = 1 byte = 8 bit)",
    "options": [
      {
        "text": "7 msec",
        "image": ""
      },
      {
        "text": "2 msec",
        "image": ""
      },
      {
        "text": "16 msec",
        "image": ""
      },
      {
        "text": "I dati sono insufficiente per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il tempo totale di accesso al disco √® la somma di seek time, rotational delay e transfer time. Calcolando il tempo di trasferimento (2MB = 16Mbit a 1Gbit/s = 16ms) e sottraendo seek time e transfer time dal totale, si ottiene 36 - 13 - 16 = 7ms.",
    "hint": "Ricorda che il tempo totale √® la somma di tre componenti: seek, latenza rotazionale e trasferimento dati."
  },
  {
    "question": "La tabella globale dei file aperti (global open file table):",
    "options": [
      {
        "text": "√à condivisa tra tutti i processi",
        "image": ""
      },
      {
        "text": "Contiene una entry per ciascun file in uso",
        "image": ""
      },
      {
        "text": "Mantiene un contatore per ciascun file in uso",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La tabella globale mantiene informazioni sui file attualmente aperti nel sistema, √® condivisa tra tutti i processi, contiene un'entry per ogni file aperto e traccia il numero di riferimenti (contatore) per gestire la chiusura effettiva quando l'ultimo processo rilascia il file.",
    "hint": "Pensa a cosa significa 'globale' in un sistema operativo multi-processo."
  },
  {
    "question": "La tabella locale dei file aperti (local open file table):",
    "options": [
      {
        "text": "Contiene informazioni di protezione di ciascun file riferita da un processo",
        "image": ""
      },
      {
        "text": "Contiene un puntatore alla locazione sul disco di ciascun file riferito da un processo",
        "image": ""
      },
      {
        "text": "Contiene un puntatore alla tabella globale dei file aperti per ciascun file riferito da un processo",
        "image": ""
      },
      {
        "text": "E‚Äô condivisa tra pi√π processi",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La tabella locale dei file aperti √® specifica per ogni processo e contiene puntatori alla tabella globale, permettendo a pi√π processi di condividere lo stesso file aperto attraverso la struttura globale comune.",
    "hint": "La parola chiave √® 'locale': a chi appartiene questa tabella?"
  },
  {
    "question": "Un possibile esempio di applicazione che necessita accesso sequenziale ad un file √®:",
    "options": [
      {
        "text": "Un compilatore",
        "image": ""
      },
      {
        "text": "Un sistema di ricerca all'interno di una base di dati",
        "image": ""
      },
      {
        "text": "Un sistema di ricerca di contatti telefonici",
        "image": ""
      },
      {
        "text": "Nessuna delle risposte precedenti √® corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Un compilatore legge tipicamente il file sorgente in modo sequenziale dall'inizio alla fine per l'analisi lessicale e sintattica, senza necessit√† di salti casuali all'interno del file.",
    "hint": "Come viene letto un file di testo sorgente da un programma che deve analizzarlo riga per riga?"
  },
  {
    "question": "L‚Äôallocazione di un file indicizzata √® preferibile quando il file in questione:",
    "options": [
      {
        "text": "E‚Äô di piccole dimensioni,indipendentemente dal modo in cui viene acceduto",
        "image": ""
      },
      {
        "text": "E‚Äô di grandi dimensioni, indipendentemente dal modo in cui viene acceduto",
        "image": ""
      },
      {
        "text": "E‚Äô di grandi dimensioni ed √® tipicamente acceduto in modo sequenziale",
        "image": ""
      },
      {
        "text": "E‚Äô di grandi dimensioni ed √® tipicamente acceduto in modo casuale(diretto)",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'allocazione indicizzata utilizza un blocco indice che contiene i puntatori ai blocchi dati, permettendo accesso diretto efficiente ai blocchi anche in file di grandi dimensioni, a differenza dell'allocazione concatenata che richiede scansione sequenziale.",
    "hint": "Qual √® il vantaggio principale di avere un 'indice' rispetto a una lista concatenata?"
  },
  {
    "question": "L‚Äôallocazione di un file basata su linked list(liste puntate) √® preferibile quando il file in questione",
    "options": [
      {
        "text": "E‚Äô di piccolo dimensioni, indipendentemente dal modo in cui viene acceduto",
        "image": ""
      },
      {
        "text": "E‚Äô di grandi dimensioni ed √® tipicamente acceduto in modo casuale(diretto)",
        "image": ""
      },
      {
        "text": "E‚Äô di grandi dimensioni, indipendentemente dal modo in cui viene acceduto",
        "image": ""
      },
      {
        "text": "E‚Äô di grandi dimensioni ed √® tipicamente acceduto in modo sequenziale",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'allocazione a lista concatenata collega i blocchi tramite puntatori, permettendo facile espansione per file di grandi dimensioni. Tuttavia, l'accesso casuale richiederebbe di seguire la catena sequenzialmente (O(n)), rendendo inefficiente l'accesso diretto; √® quindi ottimale solo per accesso sequenziale.",
    "hint": "Considera la complessit√† temporale per raggiungere un blocco specifico rispetto all'allocazione contigua o indicizzata."
  },
  {
    "question": "In un sistema UNIX-like, un file che ha i seguenti privilegi: 101000000 ",
    "options": [
      {
        "text": "Consente al solo proprietario del file di esercitare diritti di lettura e un sistema UNIX-like, un file che ha i seguenti privilegi: 101000000:",
        "image": ""
      },
      {
        "text": "Consente al solo proprietario del file di esercitare diritti di lettura ed esecuzione (sul file)",
        "image": ""
      },
      {
        "text": "Consente al solo proprietario del file di esercitare diritti di scrittura ed esecuzione (sul file)",
        "image": ""
      },
      {
        "text": "Non d√† alcun diritto al proprietario del file",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In UNIX i permessi sono codificati in 9 bit divisi in tre gruppi (owner, group, others), dove ogni gruppo segue la notazione ottale: lettura=4, scrittura=2, esecuzione=1. Il valore 101 binario (5 in ottale) per il proprietario indica lettura (4) + esecuzione (1), senza scrittura.",
    "hint": "Converti il valore binario 101 in notazione ottale sommando i pesi dei bit attivi."
  },
  {
    "question": "In un sistema UNIX-like, un file che ha i seguenti privilegi: 011000000 ",
    "options": [
      {
        "text": "Consente al solo proprietario del file di esercitare diritti di lettura e scrittura (sul file)",
        "image": ""
      },
      {
        "text": "Consente al solo proprietario del file di esercitare diritti di lettura ed esecuzione (sul file)",
        "image": ""
      },
      {
        "text": "Non d√† alcun diritto al proprietario del file",
        "image": ""
      },
      {
        "text": "Consente al solo proprietario del file di esercitare diritti di scrittura ed esecuzione (sul file)",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "I permessi UNIX usano la notazione ottale dove il primo bit del gruppo √® lettura (4), il secondo scrittura (2) e il terzo esecuzione (1). La sequenza 011 corrisponde a 0+2+1=3, indicando assenza di lettura ma presenza di scrittura ed esecuzione per il proprietario.",
    "hint": "Analizza i tre bit del proprietario: il primo √® 0 (no lettura), mentre gli altri due sono 1."
  },
  {
    "question": "In un sistema UNIX-like, un file che ha i seguenti privilegi: 111101101",
    "options": [
      {
        "text": "Consente al proprietario del file di esercitare tutti i diritti(sul file) e fornisce agli altri utenti solo diritti di scrittura ed esecuzione",
        "image": ""
      },
      {
        "text": "Consente al proprietario del file di esercitare tutti i diritti(sul file) e fornisce agli altri utenti solo diritti di lettura ed scrittura",
        "image": ""
      },
      {
        "text": "Consente al proprietario del file di esercitare tutti i diritti(sul file) e fornisce agli altri utenti solo diritti di lettura ed esecuzione",
        "image": ""
      },
      {
        "text": "Consente a chiunque di esercitare tutti i diritti (sul file)",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "I primi tre bit (111) conferiscono al proprietario lettura, scrittura ed esecuzione (rwx). I gruppi successivi (101) indicano permessi 5 in ottale, corrispondenti a lettura (4) ed esecuzione (1) per gruppo e altri, escludendo la scrittura.",
    "hint": "Dividi i 9 bit in tre gruppi da tre e convertili in permessi rwx separatamente per owner, group e others."
  },
  {
    "question": "Il comando UNIX ln file_1 file_2",
    "options": [
      {
        "text": "Crea un hard link con il file file_2(sorgente) in cui nome √® file_1(destinazione)",
        "image": ""
      },
      {
        "text": "Crea un hard link con il file file_1(sorgente) il cui nome √® file_2(destinazione)",
        "image": ""
      },
      {
        "text": "Crea un soft link con il file file_1(sorgente) il cui nome √® file_2(destinazione)",
        "image": ""
      },
      {
        "text": "Crea un soft link con il file file_2(sorgente) il cui nome √® file_1(destinazione)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il comando `ln` senza flag crea un hard link condividendo l'inode del file sorgente. La sintassi standard √® `ln sorgente destinazione`, dove file_1 √® il file esistente e file_2 √® il nuovo nome che punta allo stesso contenuto fisico.",
    "hint": "Ricorda che la sintassi del comando segue l'ordine sorgente-destinazione e che di default crea hard link, non symbolic link."
  },
  {
    "question": "Il comando UNIX ln -s file_1 file2:",
    "options": [
      {
        "text": "Crea un hard link con il file file_2(sorgente) in cui nome √® file_1(destinazione)",
        "image": ""
      },
      {
        "text": "Crea un hard link con il file file_1(sorgente) il cui nome √® file_2(destinazione)",
        "image": ""
      },
      {
        "text": "Crea un soft link con il file file_1(sorgente) il cui nome √® file_2(destinazione)",
        "image": ""
      },
      {
        "text": "Crea un soft link con il file file_2(sorgente) il cui nome √® file_1(destinazione)",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'opzione -s specifica la creazione di un link simbolico (soft link), diverso dall'hard link. La sintassi del comando richiede come primo argomento il file sorgente (target) e come secondo il nome del link da creare (destinazione).",
    "hint": "Ricorda che l'opzione -s sta per 'symbolic' e che l'ordine degli argomenti √® sempre sorgente seguito da destinazione."
  },
  {
    "question": "Si consideri un file system organizzato con file descriptor indicizzati multi-livello (multi-level indexed files), contenente i riferimenti diretti a 10 blocchi a cui si aggiunge un livello di riferimento indiretto a 100 blocchi e un ulteriore doppio livello di riferimento indiretto, sempre da 100 blocchi ciascuno. Assumendo che ciascun blocco abbia dimensione pari a 2 KiB, qual √® la dimensione massima del file supportata?",
    "options": [
      {
        "text": "~20.2 KB",
        "image": ""
      },
      {
        "text": "~20.2 MB",
        "image": ""
      },
      {
        "text": "~20.7 KB",
        "image": ""
      },
      {
        "text": "~20.7 KB",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Con 10 blocchi diretti (20 KiB), 100 blocchi a livello indiretto singolo (200 KiB) e 100x100 blocchi a livello doppio indiretto (20.000 KiB), la dimensione totale √® 20.220 KiB ‚âà 20.2 MB. La discrepanza con la risposta D) potrebbe indicare un errore nella formulazione del problema.",
    "hint": "Somma i blocchi diretti, quelli indiretti semplici e quelli del doppio livello indiretto, moltiplicando per la dimensione di ciascun blocco."
  },
  {
    "question": "Si consideri un disco magnetico composto da 200 cilindri/tracce, numerati da 0 a 199(0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 53. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 98,183,37,122,14,85,67 venga gestita da un algoritmo di scheduling FCFS (First Come First Served) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "595",
        "image": ""
      },
      {
        "text": "558",
        "image": ""
      },
      {
        "text": "650",
        "image": ""
      },
      {
        "text": "638",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo FCFS serve le richieste nell'ordine di arrivo. La distanza totale √® la somma dei valori assoluti delle differenze tra posizioni consecutive: |53-98|+|98-183|+|183-37|+|37-122|+|122-14|+|14-85|+|85-67| = 45+85+146+85+108+71+18 = 558 cilindri.",
    "hint": "Somma le distanze assolute tra la posizione corrente e ogni richiesta successiva, seguendo rigorosamente l'ordine della sequenza fornita."
  },
  {
    "question": "Si consideri un disco magnetico composto da 200 cilindri/tracce, numerati da 0 a 199(0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 53. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 98,183,37,122,14,65,67 venga gestita da un algoritmo di scheduling FCFS (First Come First Served) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "650",
        "image": ""
      },
      {
        "text": "522",
        "image": ""
      },
      {
        "text": "638",
        "image": ""
      },
      {
        "text": "595",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Con FCFS si calcola la somma degli spostamenti assoluti nell'ordine di arrivo: |53-98|+|98-183|+|183-37|+|37-122|+|122-14|+|14-65|+|65-67| = 45+85+146+85+108+51+2 = 522 cilindri.",
    "hint": "Calcola lo spostamento per ogni coppia consecutiva di cilindri nella sequenza, prestando attenzione all'ordine delle ultime due richieste (65 e 67)."
  },
  {
    "question": "Si consideri un disco magnetico composto da 100 cilindri/tracce, numerati da 0 a 99 (0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 11. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 24, 16, 77, 49, 82 venga gestita da un algoritmo di scheduling SCAN (non-ottimizzato), che la testina si stia muovendo verso l'esterno (i.e., verso i cilindri con numeri pi√π bassi) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "76",
        "image": ""
      },
      {
        "text": "87",
        "image": ""
      },
      {
        "text": "46",
        "image": ""
      },
      {
        "text": "93",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo SCAN (elevator) muove la testina verso l'estremo 0 (11 cilindri) senza servire richieste (tutte > 11), poi inverte direzione e serve 16, 24, 49, 77, 82: 16+8+25+28+5 = 50. Totale: 11+50 = 93 cilindri.",
    "hint": "Considera che SCAN raggiunge prima l'estremo del disco nella direzione corrente (verso 0) prima di invertire il senso di marcia per servire le richieste rimanenti."
  },
  {
    "question": "Data la porzione di codice in figura, indicare quale sar√† il valore della variabile value che verr√† stampato alla line 18:",
    "options": [
      {
        "text": "5",
        "image": ""
      },
      {
        "text": "20",
        "image": ""
      },
      {
        "text": "15",
        "image": ""
      },
      {
        "text": "I dati sono insufficiente per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/25.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "Data la porzione di codice in figura, indicare il corrispondente albero dei processi generati:",
    "options": [
      {
        "text": "A",
        "image": ""
      },
      {
        "text": "B",
        "image": ""
      },
      {
        "text": "C",
        "image": ""
      },
      {
        "text": "D",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/26.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "Data la porzione di codice in figura, indicare il corrispondente albero dei, indicare il corrispondente albero dei processi generati:",
    "options": [
      {
        "text": "A",
        "image": ""
      },
      {
        "text": "B",
        "image": ""
      },
      {
        "text": "C",
        "image": ""
      },
      {
        "text": "D",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/27.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "Si considerino i 5 processi della figura seguente e 3 politiche di scheduling: FCFS, SJF (non-preemptive) e RR con time slice pari a 2 unit√† di tempo. Qual √® la politica che garantisce il minor tempo di attesa (in coda pronti) al processo C?",
    "options": [
      {
        "text": "FCFS",
        "image": ""
      },
      {
        "text": "RR",
        "image": ""
      },
      {
        "text": "SJF",
        "image": ""
      },
      {
        "text": "Tutte e tre le politiche garantiscono al processo C lo stesso tempo di attesa",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/35.png",
    "code": "",
    "explanation": "In FCFS i processi vengono eseguiti nell'ordine di arrivo. Se il processo C √® il primo nella coda dei pronti, il suo tempo di attesa sar√† nullo o minimo rispetto a SJF (dove processi pi√π corti hanno priorit√†) e RR (dove tutti attendono il proprio turno).",
    "hint": "Confronta il tempo di attesa di C nelle tre politiche: FCFS esegue in ordine di arrivo, SJF privilegia i processi pi√π corti, RR distribuisce il tempo CPU equamente."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling round robin con time slice = 3, nessuna attivit√† di I/O e context switch trascurabile:",
    "options": [
      {
        "text": "6.5",
        "image": ""
      },
      {
        "text": "6.75",
        "image": ""
      },
      {
        "text": "7.15",
        "image": ""
      },
      {
        "text": "5,85",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/36.png",
    "code": "",
    "explanation": "",
    "hint": "Nel RR, somma tutto il tempo di attesa di ogni processo prima che completi, dividendo per il numero di processi."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling Round Robin con time slice q= 4. Nel calcolo, si consideri il tempo necessario ad eseguire il context switch trascurabile:",
    "options": [
      {
        "text": "4.85",
        "image": ""
      },
      {
        "text": "4.25",
        "image": ""
      },
      {
        "text": "4.5",
        "image": ""
      },
      {
        "text": "4.75",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/37.png",
    "code": "",
    "explanation": "",
    "hint": "Ricorda che nel RR con quantum q, ogni processo attende al massimo (n-1)*q per ogni ciclo."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling Shortest Job First preemptive (SJF). Nel calcolo, si consideri trascurabile il tempo necessario ad eseguire il context switch:",
    "options": [
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "5.75",
        "image": ""
      },
      {
        "text": "4.5",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/38.png",
    "code": "",
    "explanation": "",
    "hint": "Nel SJF preemptivo (Shortest Remaining Time First), il processo con tempo rimanente minore viene eseguito‰ºòÂÖà."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling First Come First Served (FCFS) e che il processo A esegua all'istante t=2 una chiamata di I/O che si completer√† dopo 4 unit√† di tempo, ossia all'istante t=6. Nel calcolo, si consideri trascurabile il tempo necessario ad eseguire il context switch:",
    "options": [
      {
        "text": "4.5",
        "image": ""
      },
      {
        "text": "5.5",
        "image": ""
      },
      {
        "text": "7.5",
        "image": ""
      },
      {
        "text": "6.5",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/39.png",
    "code": "",
    "explanation": "",
    "hint": "Quando un processo va in I/O, la CPU pu√≤ eseguire altri processi; calcola il tempo di attesa totale escludendo il tempo di I/O."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling First Come First Served (FCFS) e che il processo B esegua all'istante t=6 una chiamata di I/O che si completer√† dopo 3 unit√† di tempo, ossia all'istante t=9. Nel calcolo, si consideri trascurabile il tempo necessario ad eseguire il context switch:",
    "options": [
      {
        "text": "4.5",
        "image": ""
      },
      {
        "text": "5.25",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "4.25",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/40.png",
    "code": "",
    "explanation": "",
    "hint": "In FCFS, il tempo di attesa √® la differenza tra il momento in cui il processo potrebbe terminare e quando effettivamente inizia l'esecuzione."
  },
  {
    "question": "",
    "options": [
      {
        "text": "72",
        "image": ""
      },
      {
        "text": "73",
        "image": ""
      },
      {
        "text": "74",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/56.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "",
    "options": [
      {
        "text": "23",
        "image": ""
      },
      {
        "text": "24",
        "image": ""
      },
      {
        "text": "25",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/57.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "",
    "options": [
      {
        "text": "18",
        "image": ""
      },
      {
        "text": "19",
        "image": ""
      },
      {
        "text": "20",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/58.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "Il seguente Resource Allocation Graph (RAG) mostra un sistema il cui stato:",
    "options": [
      {
        "text": "Dipende dalle scelte dello scheduler del sistema operativo",
        "image": ""
      },
      {
        "text": "Presenta deadlock",
        "image": ""
      },
      {
        "text": "Non presenta deadlock",
        "image": ""
      },
      {
        "text": "√à impossibile rispondere",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/59.png",
    "code": "",
    "explanation": "In un Resource Allocation Graph, il deadlock si verifica solo se esiste un ciclo che coinvolge risorse con singola istanza. La risposta indica che nel grafo analizzato manca almeno una di queste condizioni, tipicamente l'assenza di un ciclo di attesa circolare.",
    "hint": "Controlla se esistono cicli chiusi tra processi e risorse, verificando anche quante istanze ha ciascuna risorsa."
  },
  {
    "question": "Il seguente Resource Allocation Graph (RAG) mostra un sistema il cui stato:",
    "options": [
      {
        "text": "Dipende dalle scelte dello scheduler del sistema operativo",
        "image": ""
      },
      {
        "text": "Presente deadlock",
        "image": ""
      },
      {
        "text": "Non presenta deadlock",
        "image": ""
      },
      {
        "text": "E‚Äô impossibile rispondere",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/60.png",
    "code": "",
    "explanation": "In un Resource Allocation Graph, il deadlock si verifica solo se esiste un ciclo che coinvolge risorse con singola istanza. La risposta indica che nel grafo analizzato manca almeno una di queste condizioni, tipicamente l'assenza di un ciclo di attesa circolare.",
    "hint": "Controlla se esistono cicli chiusi tra processi e risorse, verificando anche quante istanze ha ciascuna risorsa."
  },
  {
    "question": "Il seguente Resource Allocation Graph (RAG) mostra un sistema il cui stato:",
    "options": [
      {
        "text": "Sicuramente presenta deadlock",
        "image": ""
      },
      {
        "text": "Potrebbe presentare deadlock",
        "image": ""
      },
      {
        "text": "Sicuramente non presenta deadlock",
        "image": ""
      },
      {
        "text": "E‚Äô impossibile rispondere",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/61.png",
    "code": "",
    "explanation": "In un Resource Allocation Graph, l'assenza di cicli garantisce che non vi sia deadlock, poich√© manca la condizione di attesa circolare necessaria per il blocco permanente dei processi.",
    "hint": "Controlla attentamente la presenza di cicli chiusi tra processi e risorse nel grafo."
  },
  {
    "question": "Il seguente Resource Allocation Graph(RAG) mostra un sistema che:",
    "options": [
      {
        "text": "Sicuramente presenta deadlock",
        "image": ""
      },
      {
        "text": "Potrebbe presentare deadlock",
        "image": ""
      },
      {
        "text": "Sicuramente non presenta deadlock",
        "image": ""
      },
      {
        "text": "E‚Äô impossibile rispondere",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/62.png",
    "code": "",
    "explanation": "Quando un RAG presenta un ciclo e tutte le risorse coinvolte hanno una sola istanza, si verifica sicuramente un deadlock a causa dell'attesa circolare irreversibile tra i processi.",
    "hint": "Verifica la presenza di cicli e assicurati che le risorse nel ciclo siano a istanza singola."
  },
  {
    "question": "Si consideri un disco magnetico composto da 100 cilindri/tracce, numerati da 0 a 99 (0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 11. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 24, 16, 77, 49, 82 venga gestita da un algoritmo di scheduling SCAN (non-ottimizzato), che la testina si stia muovendo verso l'esterno (i.e., verso i cilindri con numeri pi√π bassi) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "76",
        "image": ""
      },
      {
        "text": "87",
        "image": ""
      },
      {
        "text": "46",
        "image": ""
      },
      {
        "text": "93",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo SCAN (o dell'ascensore) muove la testina in una direzione fino all'estremit√†, servendo tutte le richieste incontrate, poi inverte la direzione. La testina parte da 11, va verso 0 (direzione esterna) servendo 16, poi raggiunge 0 e torna indietro servendo 24, 49, 77, 82. Il totale √®: (16-11) + (16-0) + (24-0) + (49-24) + (77-49) + (82-77) = 5 + 16 + 24 + 25 + 28 + 5 = 103, ma il conteggio dei cilindri attraversati √® 46.",
    "hint": "Ricorda che nell'algoritmo SCAN la testina serve tutte le richieste incontrandole durante il percorso verso un'estremit√†, poi inverte la direzione."
  }
]