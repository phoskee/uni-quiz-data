[
  {
    "question": "Il sistema operativo",
    "options": [
      {
        "text": "Coincide con il kernel",
        "image": ""
      },
      {
        "text": "Costituisce l'interfaccia tra la macchina fisica (hardware) e le applicazioni utente",
        "image": ""
      },
      {
        "text": "√à soggetto alle politiche di scheduling",
        "image": ""
      },
      {
        "text": "Risiede in memoria principale anche in seguito allo shutdown della macchina",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il sistema operativo funge da strato di astrazione che maschera la complessit√† dell'hardware alle applicazioni, gestendo le risorse fisiche e fornendo servizi standardizzati tramite system call. Il kernel rappresenta solo il nucleo del sistema operativo, non l'intero sistema.",
    "hint": "Pensa al ruolo di intermediario tra componenti fisici e software applicativo."
  },
  {
    "question": "In un sistema operativo microkernel",
    "options": [
      {
        "text": "Alcune delle funzionalit√† sono implementate in spazio utente anzich√© all'interno del kernel",
        "image": ""
      },
      {
        "text": "I processi utente possono interagire direttamente con il sistema,evitando l'uso di system call",
        "image": ""
      },
      {
        "text": "La comunicazione tra le varie componenti del sistema √® pi√π efficiente",
        "image": ""
      },
      {
        "text": "Non sono previsti meccanismi di protezione  ",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'architettura microkernel sposta i servizi non essenziali (come driver e file system) nello spazio utente come processi server, mantenendo nel kernel solo le funzionalit√† fondamentali come la gestione dei processi e della memoria. Questo aumenta modularit√† e affidabilit√†.",
    "hint": "Considera cosa significa 'micro' in termini di codice privilegiato e modularit√†."
  },
  {
    "question": "In un sistema operativo strutturato secondo un approccio microkernel",
    "options": [
      {
        "text": "Non necessita di avere due modalit√† di utilizzo della CPU (user vs.kernel mode)",
        "image": ""
      },
      {
        "text": "Non necessita di meccanismi di comunicazione tra porzioni diverse del sistema operativo",
        "image": ""
      },
      {
        "text": "E' pi√π efficiente di un sistema monolitico",
        "image": ""
      },
      {
        "text": "Ad eccezione delle funzionalit√† fondamentali, implementa tutto il resto in spazio utente",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il microkernel implementa solo i meccanismi essenziali (scheduling base, IPC, gestione memoria fisica) in modalit√† kernel, mentre i servizi di alto livello (file system, driver, politiche di scheduling) vengono eseguiti come processi utente. Questo contrasta con i kernel monolitici.",
    "hint": "Rifletti sulla distinzione tra meccanismi fondamentali e servizi di alto livello."
  },
  {
    "question": "L'insieme di istruzioni del livello macchina:",
    "options": [
      {
        "text": "Sono composte da un codice operativo e da zero o pi√π operandi",
        "image": ""
      },
      {
        "text": "Sono definite da uno specifico linguaggio macchina",
        "image": ""
      },
      {
        "text": "Sono un'astrazione dell'architettura hardware",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Le istruzioni macchina sono effettivamente composte da codice operativo e operandi (A), definite dall'Instruction Set Architecture specifica del processore (B), e rappresentano l'interfaccia software all'hardware - un'astrazione che nasconde i dettagli fisici dell'architettura (C).",
    "hint": "Analizza la struttura binaria e il livello di astrazione dell'ISA."
  },
  {
    "question": "I registri interni della CPU e la cache sono unit√† di memoria:",
    "options": [
      {
        "text": "Non volatili",
        "image": ""
      },
      {
        "text": "Gestite interamente dall'architettura a livello hardware",
        "image": ""
      },
      {
        "text": "Gestite interamente dal sistema operativo",
        "image": ""
      },
      {
        "text": "Molto economiche e altamente performanti",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Registri e cache sono gestiti automaticamente dall'hardware della CPU (unit√† di controllo per i registri, controller cache per la cache), trasparentemente al software. Il sistema operativo gestisce solo la memoria principale e virtuale, non queste unit√† di memoria interne alla CPU.",
    "hint": "Distingui tra memoria gestita automaticamente dall'hardware e quella gestita dal software."
  },
  {
    "question": "La transizione da user a kernel mode avviene quando:",
    "options": [
      {
        "text": "Un programma esegue una chiamata di funzione",
        "image": ""
      },
      {
        "text": "Si avvia il computer (bootstrap)",
        "image": ""
      },
      {
        "text": "Si esegue la prima istruzione di un programma",
        "image": ""
      },
      {
        "text": "Scade il quanto di tempo assegnato al processo in esecuzione",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Quando scade il quanto di tempo, il timer hardware genera un interrupt che forza la CPU a passare in kernel mode per eseguire l'interrupt handler e invocare lo scheduler. Questo √® un esempio tipico di transizione da user a kernel mode tramite interrupt, necessaria per gestire la multiprogrammazione.",
    "hint": "Considera cosa accade quando il timer di sistema segnala che un processo ha esaurito il suo tempo di CPU."
  },
  {
    "question": "Il device controller di un dispositivo di I/O:",
    "options": [
      {
        "text": "Contiene dei registri che ne indicano lo stato",
        "image": ""
      },
      {
        "text": "Contiene dei registri che ne consentono il controllo da parte della CPU",
        "image": ""
      },
      {
        "text": "Contiene dei registri per lo scambio di dati con la CPU",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il device controller contiene registri di stato (per segnalare condizioni come busy o error), registri di controllo (per ricevere comandi dalla CPU) e registri dati (per il trasferimento effettivo delle informazioni), svolgendo cos√¨ tutte e tre le funzioni descritte nelle opzioni precedenti.",
    "hint": "Pensa ai tre tipi fondamentali di interazione necessari tra CPU e dispositivo: verificare lo stato, impartire comandi e scambiare dati."
  },
  {
    "question": "Le chiamate di sistema:",
    "options": [
      {
        "text": "Sono sempre bloccanti",
        "image": ""
      },
      {
        "text": "Causano la terminazione del processo in corso e l'avvio di un nuovo processo",
        "image": ""
      },
      {
        "text": "Devono essere implementate in spazio utente",
        "image": ""
      },
      {
        "text": "Devono essere implementate in spazio kernel",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Le chiamate di sistema sono l'interfaccia tra programmi utente e servizi del sistema operativo; poich√© richiedono accesso privilegiato a risorse protette e hardware, devono essere implementate in kernel space (modalit√† kernel) dove tali operazioni sono consentite.",
    "hint": "Rifletti su quale spazio di esecuzione dispone dei privilegi necessari per accedere alle risorse protette del sistema."
  },
  {
    "question": "Una chiamata di sistema bloccante",
    "options": [
      {
        "text": "Sposta in coda pronti (ready) il processo che la esegue",
        "image": ""
      },
      {
        "text": "Interrompe definitivamente il processo che la esegue",
        "image": ""
      },
      {
        "text": "Interrompe temporaneamente il processo che la esegue",
        "image": ""
      },
      {
        "text": "Necessit√† che il processo che la esegue ne verifichi periodicamente l'esito (polling)",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Una chiamata bloccante sospende il processo chiamante fino al completamento dell'operazione richiesta (es. I/O), spostandolo in stato di attesa (waiting); una volta completata l'operazione, il processo pu√≤ riprendere l'esecuzione, rendendo l'interruzione solo temporanea.",
    "hint": "Distingui tra la terminazione definitiva di un processo e il suo sospendersi in attesa di un evento esterno."
  },
  {
    "question": "Il system call handler:",
    "options": [
      {
        "text": "√à invocato dallo scheduler del sistema operativo",
        "image": ""
      },
      {
        "text": "Viene invocato alla scadenza del quanto temporale",
        "image": ""
      },
      {
        "text": "Viene eseguito in spazio utente",
        "image": ""
      },
      {
        "text": "Gestisce le chiamate di sistema tramite la system call table",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il system call handler √® una routine del kernel che riceve il numero della chiamata di sistema, lo utilizza come indice nella system call table (tabella di dispatch) per individuare la funzione kernel appropriata, ed esegue quella funzione per servire la richiesta.",
    "hint": "Considera come il sistema operativo determina quale specifica funzione kernel eseguire quando riceve una richiesta generica tramite trap."
  },
  {
    "question": " Il codice generico del system call handler:",
    "options": [
      {
        "text": "Viene eseguito in spazio utente",
        "image": ""
      },
      {
        "text": "√à indicizzato tramite la interrupt vector table (IVT)",
        "image": ""
      },
      {
        "text": "Viene invocato alla scadenza del quanto temporale",
        "image": ""
      },
      {
        "text": "Viene invocato dallo scheduler del sistema operativo",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Le system call vengono attivate tramite interrupt software (trap), e l'IVT contiene gli indirizzi dei gestori per ogni tipo di interrupt. Il processore usa il numero dell'interrupt per indicizzare l'IVT e saltare al codice del system call handler in modalit√† kernel.",
    "hint": "Come fa la CPU a trovare l'indirizzo del codice da eseguire quando avviene un'interruzione software?"
  },
  {
    "question": "L'interrupt vector table(IVT):",
    "options": [
      {
        "text": "Si aggiorna dinamicamente ad ogni interruzione",
        "image": ""
      },
      {
        "text": "E' una struttura dati che contiene puntatori ai vari gestori(handler) delle interruzioni",
        "image": ""
      },
      {
        "text": "E' una struttura dati che √® associata a ciascun processo",
        "image": ""
      },
      {
        "text": "E' una struttura dati che contiene puntatori a codici di errori",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'IVT √® una tabella globale del sistema, solitamente allocata in memoria protetta, che associa a ciascun numero di interrupt (hardware o software) l'indirizzo del relativo gestore. Non √® dinamica n√© legata ai singoli processi.",
    "hint": "Pensa a una rubrica telefonica che collega un numero a un indirizzo specifico."
  },
  {
    "question": "La system-call table:",
    "options": [
      {
        "text": "Contiene tante entry quanto sono le chiamate di sistema supportate",
        "image": ""
      },
      {
        "text": "Contiene tante entry quante sono le interruzioni supportare",
        "image": ""
      },
      {
        "text": "Contiene tante entry quanti sono i dispositivi di I/O presenti nel sistema",
        "image": ""
      },
      {
        "text": "Contiene tante entry quanti sono i processi in esecuzione",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La system-call table √® una struttura dati del kernel che mappa ogni numero di system call univoco all'indirizzo della funzione kernel che la implementa. Pertanto, il numero di entry corrisponde esattamente al numero di servizi di sistema disponibili.",
    "hint": "Ogni numero di system call identifica una specifica funzionalit√† offerta dal sistema operativo."
  },
  {
    "question": "La system-call table √® una struttura dati gestita:",
    "options": [
      {
        "text": "Dai dispositivi di I/O",
        "image": ""
      },
      {
        "text": "Dal processo utente",
        "image": ""
      },
      {
        "text": "Sia dal kernel del sistema operativo che dal processo utente",
        "image": ""
      },
      {
        "text": "Dal kernel del sistema operativo",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La system-call table risiede nello spazio di indirizzamento del kernel ed √® accessibile solo in modalit√† privilegiata. I processi utente possono solo invocarla tramite interrupt, ma non modificarla, garantendo sicurezza e integrit√† del sistema.",
    "hint": "Chi pu√≤ modificare le strutture interne del sistema operativo?"
  },
  {
    "question": "Se si cambia l'implementazione di una chiamata di sistema esistente:",
    "options": [
      {
        "text": "E' sempre necessario modificare il codice utente che ne fa uso",
        "image": ""
      },
      {
        "text": "Non √® mai necessario modificare il codice utente che ne fa uso",
        "image": ""
      },
      {
        "text": "Non √® necessario modificare il codice utente che ne fa uso, a patto che cambi anche l'interfaccia (API) della chiamata di sistema",
        "image": ""
      },
      {
        "text": "Non √® necessario modificare il codice utente che ne fa uso, a patto che non cambi anche l‚Äôinterfaccia (API) della chiamata di sistema",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Le system call forniscono un'interfaccia stabile (API) che nasconde l'implementazione interna. Se l'interfaccia (parametri e comportamento atteso) resta invariata, il codice utente non necessita di modifiche grazie al principio di incapsulamento.",
    "hint": "Distingui tra ci√≤ che un servizio fa (implementazione) e come lo si richiede (interfaccia)."
  },
  {
    "question": "Un processore impiega 5 cicli di clock per eseguire un'istruzione (CPI = 5), ossia per completare l'intero ciclo fetch-decode-execute. Assumendo che la frequenza di clock del processore sia pari a 5 MHz, quante istruzioni √® in grado di eseguire in un secondo? (Si ricordi che 1 MHz = 1*10^6 cicli al secondo)",
    "options": [
      {
        "text": "1*10^3",
        "image": ""
      },
      {
        "text": "Decido di NON rispondere a questa domanda",
        "image": ""
      },
      {
        "text": "25*10^3",
        "image": ""
      },
      {
        "text": "1*10^6",
        "image": ""
      },
      {
        "text": "25*10^6",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La frequenza di clock indica i cicli al secondo (5√ó10‚Å∂). Dividendo per il CPI (5 cicli/istruzione) si ottiene il throughput: 10‚Å∂ istruzioni al secondo.",
    "hint": "Ricorda che il numero di istruzioni al secondo si calcola dividendo la frequenza di clock per il CPI."
  },
  {
    "question": "Data una CPU multicore con ùëö unit√†(cores), il numero di processi/thread che ad un certo istante si trovano nella ‚Äúcoda‚Äù di esecuzione(running):",
    "options": [
      {
        "text": "Pu√≤ essere superiore a ùëö",
        "image": ""
      },
      {
        "text": "E‚Äô esattamente pari a ùëö",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "E' al massimo pari a ùëö",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "In un sistema multicore con m core, solo m thread possono essere in esecuzione fisica (running) contemporaneamente, uno per core. Gli altri sono in ready o altri stati.",
    "hint": "Ogni core pu√≤ eseguire al pi√π un thread alla volta in modalit√† running."
  },
  {
    "question": "La creazione di un nuovo processo da parte di un processo avviene tramite:",
    "options": [
      {
        "text": "Una chiamata di sistema",
        "image": ""
      },
      {
        "text": "Una chiamata di funzione",
        "image": ""
      },
      {
        "text": "L'invio di un interruzione",
        "image": ""
      },
      {
        "text": "Nessuna delle risposte precedenti √® corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La creazione di un processo (es. fork() in Unix/Linux) richiede privilegi del kernel per allocare risorse e PCB, quindi deve avvenire tramite system call.",
    "hint": "L'operazione richiede l'intervento del kernel per gestire le risorse del nuovo processo."
  },
  {
    "question": "Il sistema operativo tiene traccia dello stato di un processo tramite:",
    "options": [
      {
        "text": "Un'apposita area dedicata e protetta della memoria principale",
        "image": ""
      },
      {
        "text": "Un apposito registro interno della CPU",
        "image": ""
      },
      {
        "text": "Un'apposita area dedicata e protetta della memoria cache",
        "image": ""
      },
      {
        "text": "Un apposito campo all'interno del process control block (PCB)",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il PCB √® la struttura dati del kernel che contiene tutte le informazioni su un processo, incluso il suo stato corrente (ready, running, waiting, etc.).",
    "hint": "Cerca la struttura dati che rappresenta il 'biglietto da visita' di un processo per il sistema operativo."
  },
  {
    "question": "Un processo in esecuzione sulla CPU passa in stato ready quando:",
    "options": [
      {
        "text": "Riceve un segnale di interruzione da parte di un dispositivo di I/O",
        "image": ""
      },
      {
        "text": "Fa richiesta di input da parte dell‚Äôutente",
        "image": ""
      },
      {
        "text": "Fa richiesta di una pagina che non √® presente in memoria principale",
        "image": ""
      },
      {
        "text": "Esegue una chiamata di funzione",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Quando arriva un interrupt (es. da I/O), il processo corrente viene preempted (interrotto) e rimesso in coda ready per permettere al kernel di gestire l'interrupt o dare spazio ad altri processi.",
    "hint": "Un interrupt esterno pu√≤ forzare il rilascio della CPU da parte del processo corrente."
  },
  {
    "question": "Un processo in esecuzione sulla CPU passa in stato waiting quando:",
    "options": [
      {
        "text": "Riceve un segnale da parte di un dispositivo di I/O",
        "image": ""
      },
      {
        "text": "Termina il quanto di tempo ad esso assegnato",
        "image": ""
      },
      {
        "text": "Apre una connessione di rete (ad es., un socket TCP)",
        "image": ""
      },
      {
        "text": "Esegue una chiamata di funzione",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'apertura di un socket TCP √® un'operazione di I/O che richiede l'instaurazione della connessione (handshake), durante la quale il processo deve attendere l'evento esterno e quindi passa dallo stato running a waiting (blocked). Le chiamate di sistema bloccanti trasferiscono il controllo al kernel e sospendono il processo fino al completamento dell'operazione.",
    "hint": "Pensa a quali operazioni richiedono attesa attiva del processo per eventi esterni."
  },
  {
    "question": "Un processo in esecuzione sulla CPU passa in stato waiting quando:",
    "options": [
      {
        "text": "Fa richiesta di input da parte dell'utente",
        "image": ""
      },
      {
        "text": "Esegue una chiamata di funzione",
        "image": ""
      },
      {
        "text": "Termina il quanto di tempo ad esso assegnato",
        "image": ""
      },
      {
        "text": "Riceve un segnale di interruzione da parte di un dispositivo di I/O",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La richiesta di input da tastiera √® un'operazione di I/O sincrona che blocca il processo finch√© l'utente non fornisce i dati, causando la transizione dallo stato running a waiting. Il processo rimane sospeso fino al completamento dell'operazione di input.",
    "hint": "Considera quali azioni richiedono attesa di dati esterni non immediatamente disponibili."
  },
  {
    "question": "Un processo in esecuzione sulla CPU passa in stato waiting quando:",
    "options": [
      {
        "text": "Termina il quanto di tempo ad esso assegnato",
        "image": ""
      },
      {
        "text": "L'utente trascina il dispositivo di puntamento(e.g. mouse)",
        "image": ""
      },
      {
        "text": "Esegue una chiamata di funzione",
        "image": ""
      },
      {
        "text": "Riceve un segnale di interruzione da parte di un dispositivo di I/O",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'attesa di eventi di input da dispositivi periferici come il mouse √® un'operazione di I/O bloccante; il processo passa in stato waiting finch√© non si verifica l'evento di trascinamento richiesto. Questo √® coerente con il modello a stati dove le operazioni di I/O sincrone causano transizioni al stato blocked.",
    "hint": "Pensa alle operazioni che richiedono interazione umana attraverso periferiche di input."
  },
  {
    "question": "Quanti processi saranno presenti nel sistema a seguito di queste chiamata: pid_1 = fork(); pid_2 = fork(); pid_3 = fork();?",
    "options": [
      {
        "text": "8",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "3",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Ogni chiamata fork() duplica tutti i processi esistenti che la eseguono. Con tre fork() consecutive, il numero di processi cresce esponenzialmente secondo 2^n, dove n √® il numero di fork. Quindi 2^3 = 8 processi totali (incluso il processo originale).",
    "hint": "Ricorda che ogni fork() raddoppia il numero di processi esistenti, non aggiunge solo uno."
  },
  {
    "question": "I processi CPU-bound che non eseguono richieste di I/O:",
    "options": [
      {
        "text": "Hanno una priorit√† alta",
        "image": ""
      },
      {
        "text": "Hanno una priorit√† bassa",
        "image": ""
      },
      {
        "text": "Sono processi mediamente brevi",
        "image": ""
      },
      {
        "text": "Possono non rilasciare mai la CPU volontariamente",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "I processi CPU-bound eseguono calcoli intensivi senza operazioni di I/O che causerebbero il rilascio volontario della CPU. In assenza di meccanismi di preemption o time-out, o semplicemente per loro natura computazionale, possono monopolizzare il processore senza mai cedere il controllo spontaneamente.",
    "hint": "Considera cosa causa tipicamente il rilascio volontario della CPU da parte di un processo."
  },
  {
    "question": "Lo scheduler della CPU si attiva:",
    "options": [
      {
        "text": "Quando un processo tenta di eseguire una scrittura su disco",
        "image": ""
      },
      {
        "text": "Quando il codice di un programma esegue una divisione per zero",
        "image": ""
      },
      {
        "text": "Quando scade il quanto di tempo",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Lo scheduler della CPU viene invocato ogni volta che un processo rilascia il processore, sia volontariamente (per I/O o terminazione) che involontariamente (per interrupt del timer o eccezioni). La scrittura su disco causa un passaggio allo stato waiting, la divisione per zero genera un trap/exception, e la scadenza del quanto produce un interrupt: tutti questi eventi richiedono una nuova decisione di scheduling.",
    "hint": "Pensa a tutti gli eventi che possono far interrompere l'esecuzione di un processo, sia per richieste volontarie che per eventi esterni."
  },
  {
    "question": "Lo scheduling preemptive(basato su time slice o quanto temporale):",
    "options": [
      {
        "text": "Da la priorit√† ai processi CPU-bound",
        "image": ""
      },
      {
        "text": "Si attiva solamente alla scadenza del quanto temporale(time slice)",
        "image": ""
      },
      {
        "text": "Si attiva solamente a fronte di una chiamata di sistema",
        "image": ""
      },
      {
        "text": "Fornisce un limite superiore al tempo di CPU assegnato a ciascun processo",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il time slice (quanto temporale) rappresenta la massima quantit√† di tempo di CPU che un processo pu√≤ utilizzare continuativamente prima di essere forzatamente sospeso (preempted). Questo meccanismo garantisce fairness limitando il tempo di attesa per gli altri processi, indipendentemente dalla durata del burst CPU del processo in esecuzione.",
    "hint": "Considera cosa rappresenta numericamente il quanto di tempo rispetto alla durata dell'esecuzione continua di un processo."
  },
  {
    "question": "In un sistema uniprocessore (single core) time-sharing in cui i processi in esecuzione sono tutti puramente CPU-bound:",
    "options": [
      {
        "text": "L'impiego dei multi-threading consente di migliorare la latenza del sistema",
        "image": ""
      },
      {
        "text": "L'impiego del multi-threading consente di diminuire il tempo di completamente di ciascun processo",
        "image": ""
      },
      {
        "text": "L'impiego del multi-threading consente di migliorare il throughput del sistema",
        "image": ""
      },
      {
        "text": "L'impiego dei multi-threading non costituisce alcun vantaggio",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Su un sistema single-core con processi CPU-bound, i thread non possono eseguire parallelamente ma solo in modo interleaved, introducendo overhead di context switch senza benefici. Poich√© i processi non effettuano operazioni di I/O, non c'√® possibilit√† di mascherare la latenza tramite sovrapposizione di attivit√†.",
    "hint": "Rifletti su quanti thread possono effettivamente essere in esecuzione simultanea su un singolo core e cosa succede quando non ci sono operazioni di I/O da attendere."
  },
  {
    "question": "In caso di scheduling preemptive, lo scheduler interviene:",
    "options": [
      {
        "text": "Quando un processo passa dallo stato running allo stato waiting",
        "image": ""
      },
      {
        "text": "Quando un processo passa dallo stato running allo stato ready",
        "image": ""
      },
      {
        "text": "Quando un processo passa dallo stato waiting allo stato ready",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Nello scheduling preemptive, lo scheduler deve intervenire ad ogni cambio di stato che modifichi l'insieme dei processi pronti per l'esecuzione: quando un processo si blocca per I/O (running‚Üíwaiting), quando viene preempted per scadenza quanto (running‚Üíready), o quando un processo sbloccato ha priorit√† maggiore (waiting‚Üíready con possibile preemption).",
    "hint": "Ricorda che ogni transizione di stato che modifica l'insieme dei processi eseguibili richiede una ricalibrazione della decisione di scheduling."
  },
  {
    "question": "Se un processo arriva nella coda dei pronti all'istante t.0 = 2 e termina all'istante t.f = 15, il suo tempo di turnaround equivale a",
    "options": [
      {
        "text": "13",
        "image": ""
      },
      {
        "text": "2",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "15",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il tempo di turnaround (o tempo di ritorno) √® definito come l'intervallo temporale complessivo tra l'arrivo del processo nel sistema (istante t‚ÇÄ) e il suo completamento (istante t_f), calcolato come t_f - t‚ÇÄ. Nel caso specifico: 15 - 2 = 13 unit√† temporali.",
    "hint": "Ricorda la definizione formale di turnaround time come differenza tra tempo di completamento e tempo di arrivo."
  },
  {
    "question": "Se un processo arriva nella coda dei pronti all‚Äôistante ùë°0 = 3 e termina all‚Äôistante ùë°ùëì = 25, il tempo di attesa equivale a",
    "options": [
      {
        "text": "3",
        "image": ""
      },
      {
        "text": "22",
        "image": ""
      },
      {
        "text": "25",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il tempo di attesa √® il tempo trascorso in coda dei pronti prima dell'esecuzione, mentre conoscendo solo t0 e tf si pu√≤ calcolare solo il tempo di turnaround (tf - t0). Senza sapere quando il processo ha effettivamente iniziato l'esecuzione o la durata dei suoi burst di CPU, non √® possibile determinare il tempo di attesa.",
    "hint": "Distingui tra tempo di turnaround e tempo di attesa: quali informazioni servono per calcolare quest'ultimo?"
  },
  {
    "question": "I thread di uno stesso processo condividono:",
    "options": [
      {
        "text": "Lo stack",
        "image": ""
      },
      {
        "text": "Le variabili globali",
        "image": ""
      },
      {
        "text": "I valori dei registri della CPU",
        "image": ""
      },
      {
        "text": "Nessuna delle informazioni elencate sopra",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "I thread di uno stesso processo condividono lo spazio degli indirizzi, quindi variabili globali e heap, ma mantengono stack e registri della CPU separati per garantire flussi di esecuzione indipendenti.",
    "hint": "Pensa a cosa distingue i thread dai processi riguardo alla memoria: cosa √® condiviso e cosa √® privato?"
  },
  {
    "question": "Lo user thread:",
    "options": [
      {
        "text": "Necessita del supporto di una opportuna thread table a livello kernel",
        "image": ""
      },
      {
        "text": "E' la pi√π piccola unit√† schedulabile sulla CPU dal sistema operativo",
        "image": ""
      },
      {
        "text": "E' gestito in spazio utente tramite un'apposita libreria",
        "image": ""
      },
      {
        "text": "Coincide sempre con uno ed un solo kernel thread",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Gli user thread sono implementati interamente in spazio utente tramite librerie specifiche (come pthread), senza che il kernel sia consapevole della loro esistenza; il sistema operativo vede solo il processo come un'unica entit√†.",
    "hint": "Considera dove risiede la 'thread table' per gli user thread rispetto ai kernel thread."
  },
  {
    "question": "Nel modello di thread mapping cosiddetto one-to-one:",
    "options": [
      {
        "text": "Consente di gestire i thread tramite un'apposita libreria a livello utente",
        "image": ""
      },
      {
        "text": "Pu√≤ essere implementato solo su sistemi multiprocessore",
        "image": ""
      },
      {
        "text": "Causa il blocco di tutti i thread di un processo se anche uno solo di questi thread esegue una chiamata di sistema bloccante",
        "image": ""
      },
      {
        "text": "Consente di gestire i thread a livello del kernel del sistema operativo",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Nel modello one-to-one ogni user thread √® mappato su un distinto kernel thread, permettendo al sistema operativo di gestire direttamente lo scheduling, la sincronizzazione e le chiamate di sistema di ogni singolo thread.",
    "hint": "In questo modello, chi crea e gestisce effettivamente i thread: la libreria utente o il kernel?"
  },
  {
    "question": "Nel modello di thread mapping cosiddetto many-to-one:",
    "options": [
      {
        "text": "Molti user thread possono essere distribuiti su pi√π CPU (se presenti)",
        "image": ""
      },
      {
        "text": "L'effetto di una chiamata bloccante da parte di uno user thread non blocca gli altri thread da cui √® composto il processo",
        "image": ""
      },
      {
        "text": "Molti user thread sono mappati su un singolo kernel thread",
        "image": ""
      },
      {
        "text": "Molti kernel thread sono mappati su un singolo user thread",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nel modello many-to-one molti thread a livello utente condividono un unico kernel thread; questo √® efficiente ma comporta che una chiamata bloccante di un user thread blocchi tutti gli altri thread del processo.",
    "hint": "Quanti kernel thread sono visibili al sistema operativo quando un processo ha molti user thread in questo modello?"
  },
  {
    "question": "Il modello di thread mapping considerato many-to-many",
    "options": [
      {
        "text": "Non prevede alcun limite al numero di kernel thread",
        "image": ""
      },
      {
        "text": "Pu√≤ essere implementato solo su sistemi multiprocessore",
        "image": ""
      },
      {
        "text": "Causa il blocco di tutti i thread di un processo se anche uno solo di questi thread esegue una chiamata di sistema bloccante",
        "image": ""
      },
      {
        "text": "E' il compromesso tra un'implementazione dei thread puramente user level e una puramente kernel level",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il modello many-to-many mappa molti thread utente su un numero minore o uguale di thread kernel, combinando l'efficienza della gestione in spazio utente con la capacit√† di sfruttare il vero parallelismo su multi-core. Rappresenta una soluzione intermedia che evita i problemi di blocco del modello many-to-one e l'overhead del modello one-to-one.",
    "hint": "Considera come questo modello bilanci flessibilit√† ed efficienza rispetto ai modelli puramente user-level o kernel-level."
  },
  {
    "question": "Si parla di parallelismo quando:",
    "options": [
      {
        "text": "Vengono eseguiti processi single-threaded su CPU multicore",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi multi-threaded su CPU single core",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi multi-threaded su CPU multicore",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il parallelismo richiede l'esecuzione simultanea di pi√π istruzioni, possibile solo quando vi sono multiple unit√† di esecuzione hardware (core) e sufficienti thread per utilizzarle. Su CPU single-core o con processi single-threaded si pu√≤ avere solo concorrenza (interleaving), non parallelismo reale.",
    "hint": "Rifletti su quale requisito hardware √® indispensabile per l'esecuzione simultanea piuttosto che interallacciata."
  },
  {
    "question": "Si parla di concorrenza quando:",
    "options": [
      {
        "text": "Vengono eseguiti processi multi-threaded su CPU single core",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi single-threaded su CPU single core",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi single-threaded su CPU multicore",
        "image": ""
      },
      {
        "text": "Vengono eseguiti processi multi-threaded su CPU multicore",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La concorrenza si riferisce alla capacit√† di gestire multiple esecuzioni che progrediscono nel tempo attraverso l'interleaving, tipico dei sistemi single-core dove il sistema operativo alterna rapidamente l'esecuzione dei thread. Non richiede hardware multi-core, basta la capacit√† di time-sharing del sistema operativo.",
    "hint": "Pensa alla differenza tra esecuzione interallacciata nel tempo e esecuzione simultanea nello spazio."
  },
  {
    "question": "La comunicazione tra thread dello stesso processo rispetto a quella tra processi diversi:",
    "options": [
      {
        "text": "√à pi√π lenta poich√© i thread sono gestiti da librerie di alto livello",
        "image": ""
      },
      {
        "text": "√à pi√π veloce poich√© i thread non eseguono context switch",
        "image": ""
      },
      {
        "text": "√à pi√π veloce poich√© i thread condividono lo stesso spazio di indirizzamento",
        "image": ""
      },
      {
        "text": "Non c'√® alcuna differenza sostanziale in termini di performance",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "I thread di uno stesso processo condividono lo spazio di indirizzamento e le risorse, permettendo lo scambio di dati tramite variabili condivise senza costose system call o meccanismi IPC come pipe o message passing. I processi diversi invece richiedono context switch in modalit√† kernel e copia dei dati tra spazi di indirizzamento isolati.",
    "hint": "Considera quali risorse di memoria sono condivise tra thread ma isolate tra processi diversi."
  },
  {
    "question": "Il kernel thread:",
    "options": [
      {
        "text": "Coincide sempre con uno ed un solo user thread",
        "image": ""
      },
      {
        "text": "√à gestito in spazio utente tramite un'apposita libreria",
        "image": ""
      },
      {
        "text": "√à la pi√π piccola unit√† schedulabile sulla CPU dal sistema operativo",
        "image": ""
      },
      {
        "text": "√à il termine con cui si identificano i processi propri del sistema operativo (i.e., non i processi utente)",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il kernel thread √® l'entit√† di esecuzione riconosciuta dallo scheduler del sistema operativo, che ne gestisce il ciclo di vita, lo stato e la dispatching sulla CPU. Rappresenta l'unit√† minima di esecuzione che il kernel pu√≤ schedulare indipendentemente, indipendentemente dal mapping con i thread utente.",
    "hint": "Concentrati sulla relazione tra lo scheduler del sistema operativo e l'unit√† di esecuzione nello spazio kernel."
  },
  {
    "question": "L'uso di una primitiva di sincronizzazione lock prevede che:",
    "options": [
      {
        "text": "La lock sia inizialmente libera",
        "image": ""
      },
      {
        "text": "La lock venga acquisita prima dell'ingresso nella sezione critica",
        "image": ""
      },
      {
        "text": "La lock venga rilasciata dopo l'uscita dalla sezione critica",
        "image": ""
      },
      {
        "text": "Tutte le condizioni precedenti devono essere verificate",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Per garantire la corretta sincronizzazione, una lock deve essere inizialmente libera per permettere il primo accesso, acquisita prima della sezione critica per garantire mutua esclusione e rilasciata dopo per consentire l'accesso ad altri processi. Queste tre condizioni sono fondamentali per evitare deadlock o violazioni della mutua esclusione.",
    "hint": "Considera il ciclo di vita completo di una lock: inizializzazione, uso nella sezione critica e rilascio."
  },
  {
    "question": "L'acquisizione di una lock:",
    "options": [
      {
        "text": "Deve avvenire in modo atomico, evitando che lo scheduler interrompa l'acquisizione",
        "image": ""
      },
      {
        "text": "Necessita obbligatoriamente del supporto di istruzioni hardware atomiche",
        "image": ""
      },
      {
        "text": "Necessita obbligatoriamente che il sistema operativo disabiliti le interruzioni",
        "image": ""
      },
      {
        "text": "Nessuna delle risposte precedenti √® corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'atomicit√† dell'acquisizione √® essenziale per evitare race condition durante l'operazione stessa: se l'acquisizione fosse interrompibile, due processi potrebbero leggere contemporaneamente che la lock √® libera e acquisirla entrambi. Non √® obbligatorio usare istruzioni hardware specifiche o disabilitare interruzioni, esistono anche soluzioni software puramente algoritmiche.",
    "hint": "Pensa a cosa succederebbe se due thread leggessero il valore della lock nello stesso istante prima che uno la modifichi."
  },
  {
    "question": "Un semaforo pu√≤ essere utilizzato per:",
    "options": [
      {
        "text": "Forzare le politiche di scheduling tra processi/thread",
        "image": ""
      },
      {
        "text": "Accedere al codice del kernel",
        "image": ""
      },
      {
        "text": "Lo scambio di messaggi tra processi/thread",
        "image": ""
      },
      {
        "text": "Gestire le interruzioni che giungono alla CPU",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "I semafori sono strumenti di sincronizzazione che permettono di controllare l'ordine di esecuzione e l'accesso a risorse condivise tra processi/thread, implementando politiche di scheduling e coordinamento. Non gestiscono direttamente interruzioni hardware, accesso al kernel o scambio di messaggi con dati.",
    "hint": "Ricorda che i semafori regolano l'accesso a risorse tramite contatori e code di attesa."
  },
  {
    "question": "L'invocazione del metodo wait() su un semaforo il cui valore √® pari a 2:",
    "options": [
      {
        "text": "Lascia invariato il valore del semaforo a 2 e fa proseguire il processo che ha eseguito l'invocazione (al netto delle politiche di scheduling)",
        "image": ""
      },
      {
        "text": "Decrementa il valore del semaforo a 1 e blocca il processo che ha eseguito l'invocazione",
        "image": ""
      },
      {
        "text": "Incrementa il valore del semaforo a 3 e fa proseguire il processo che ha eseguito l'invocazione (al netto delle politiche di scheduling)",
        "image": ""
      },
      {
        "text": "Decrementa il valore del semaforo a 1 e fa proseguire il processo che ha eseguito l'invocazione (al netto delle politiche di scheduling)",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'operazione wait() decrementa il valore del semaforo se questo √® maggiore di zero. Con valore 2, il decremento porta a 1 (rimanendo positivo) e il processo prosegue senza bloccarsi. Il blocco avviene solo quando il valore diventa zero o negativo, a seconda dell'implementazione specifica.",
    "hint": "Ricorda la regola: se il valore √® positivo, wait decrementa e il processo continua; se √® zero o negativo, il processo si blocca."
  },
  {
    "question": "L'istruzione test-and-set:",
    "options": [
      {
        "text": "√à un'istruzione atomica che consente di implementare le primitive di sincronizzazione",
        "image": ""
      },
      {
        "text": "√à un'istruzione atomica che consente di disabilitare le interruzioni",
        "image": ""
      },
      {
        "text": "√à un'istruzione atomica che consente di aggiornare i valori di pi√π registri simultaneamente",
        "image": ""
      },
      {
        "text": "√à un'istruzione atomica che consente di resettare il valore di un semaforo",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Test-and-set √® un'istruzione hardware atomica che legge una variabile e la imposta a 1 in un'unica operazione indivisibile. √à utilizzata come primitiva di base per costruire meccanismi di sincronizzazione software come gli spin-lock, garantendo che solo un processo alla volta possa acquisire la lock.",
    "hint": "Pensa a come un'operazione atomica di lettura-scrittura possa implementare una variabile di lock binaria."
  },
  {
    "question": "La differenza tra deadlock e starvation risiede nel fatto che:",
    "options": [
      {
        "text": "Si riferiscono a codice utente e codice di sistema (rispettivamente)",
        "image": ""
      },
      {
        "text": "Nel caso di starvation tutto il sistema √® completamente bloccato",
        "image": ""
      },
      {
        "text": "Non vi √® alcuna differenza",
        "image": ""
      },
      {
        "text": "Nel caso di deadlock tutto il sistema √® completamente bloccato",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Il deadlock √® una condizione di blocco circolare permanente tra processi che attendono risorse detenute reciprocamente, impedendo a tutti di proseguire. La starvation invece riguarda un singolo processo che viene rimandato indefinitamente mentre altri procedono, senza bloccare l'intero sistema.",
    "hint": "Considera la differenza tra un blocco totale circolare e un'attesa indefinita per un singolo processo escluso."
  },
  {
    "question": "Con il termine address binding si intende:",
    "options": [
      {
        "text": "Il processo di traduzione da indirizzi logici a indirizzi fisici",
        "image": ""
      },
      {
        "text": "Il processo di inizializzazione delle variabili globali di un programma",
        "image": ""
      },
      {
        "text": "Il processo di collegamento tra il codice compilato ed eventuali librerie esterne",
        "image": ""
      },
      {
        "text": "Nessuna delle risposte precedenti √® corretta",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'address binding √® il meccanismo che associa gli indirizzi logici (virtuali) generati dal programma agli indirizzi fisici della memoria RAM, permettendo la rilocazione e la protezione. Pu√≤ avvenire in fasi diverse: compile time, load time o execution time.",
    "hint": "Pensa al momento in cui gli indirizzi generati dal compilatore vengono mappati alle locazioni effettive della memoria fisica."
  },
  {
    "question": "Lo swapping consente di:",
    "options": [
      {
        "text": "Implementare la rilocazione dinamica del codice di un processo",
        "image": ""
      },
      {
        "text": "Risolvere il problema della frammentazione esterna",
        "image": ""
      },
      {
        "text": "Trasferire temporaneamente su disco i processi che non sono attualmente in esecuzione",
        "image": ""
      },
      {
        "text": "Scambiare le aree di memoria occupate da due o pi√π processi",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Lo swapping (o roll-out/roll-in) sposta temporaneamente interi processi dalla memoria principale al disco di backing store quando devono essere sospesi, e li ricarica quando diventano pronti per l'esecuzione. Questo aumenta il grado di multiprogrammazione oltre la capacit√† fisica della RAM.",
    "hint": "Ricorda che questa tecnica riguarda il trasferimento di processi completi tra RAM e disco per gestire la sovrapposizione temporale."
  },
  {
    "question": "La gestione 'paginata' della memoria (paging):",
    "options": [
      {
        "text": "Prevede che lo spazio di indirizzamento logico di un processo sia non-contiguo e suddiviso in blocchi di dimensioni fissate (pages)",
        "image": ""
      },
      {
        "text": "Non richiede alcun supporto hardware per essere implementata in modo efficiente",
        "image": ""
      },
      {
        "text": "Prevede che lo spazio di indirizzamento fisico di un processo sia non-contiguo e suddiviso in blocchi di dimensioni fissate (frames)",
        "image": ""
      },
      {
        "text": "Risolve il problema della frammentazione interna",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nel paging, la memoria fisica √® suddivisa in blocchi di dimensione fissa chiamati frame, mentre lo spazio logico del processo √® suddiviso in pagine della stessa dimensione. Le pagine possono essere allocate in frame qualsiasi, anche non contigui, eliminando la frammentazione esterna.",
    "hint": "Distingui attentamente tra l'organizzazione della memoria fisica (frames) e quella dello spazio logico del processo (pages)."
  },
  {
    "question": "La cache TLB (Translation Look-aside Buffer)",
    "options": [
      {
        "text": "E' condivisa tra tutti i processi del sistema",
        "image": ""
      },
      {
        "text": "Consente una traduzione mediamente pi√π rapida degli indirizzi logici",
        "image": ""
      },
      {
        "text": "Contiene un sottoinsieme delle entry della page table",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La TLB √® una cache associativa speciale che memorizza le traduzioni di indirizzi recentemente utilizzate (entry della page table), riducendo il tempo di accesso alla memoria. √à condivisa tra i processi del sistema e viene tipicamente svuotata o aggiornata ad ogni cambio di contesto.",
    "hint": "Considera tutte le caratteristiche di questa cache hardware dedicata alla traduzione veloce degli indirizzi."
  },
  {
    "question": "La dimensione (i.e., il numero di entry) della page table:",
    "options": [
      {
        "text": "√à direttamente proporzionale alla dimensione (fissata) delle pagine",
        "image": ""
      },
      {
        "text": "Si adatta a seconda delle richieste di accesso alla memoria di ciascun processo",
        "image": ""
      },
      {
        "text": "Dipende dalla dimensione (fissata) delle pagine",
        "image": ""
      },
      {
        "text": "Varia dinamicamente a seconda del processo",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il numero di entry della page table √® determinato dalla divisione dello spazio di indirizzamento virtuale per la dimensione della pagina. Pertanto, la dimensione della tabella dipende direttamente dalla grandezza fissata delle pagine, anche se la relazione specifica √® inversamente proporzionale.",
    "hint": "Considera come viene calcolato il numero di pagine necessarie per coprire l'intero spazio degli indirizzi virtuali."
  },
  {
    "question": "La dimensione (i.e., il numero di entry) della page table:",
    "options": [
      {
        "text": "Varia dinamicamente a seconda del processo",
        "image": ""
      },
      {
        "text": "E' direttamente proporzionale alla dimensione (fissata)",
        "image": ""
      },
      {
        "text": "E' inversamente proporzionale alla dimensione (fissata) delle pagine",
        "image": ""
      },
      {
        "text": "Si adatta a seconda delle richieste di accesso alla memoria di ciascun processo",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La page table richiede una entry per ogni pagina dello spazio virtuale. Poich√© il numero totale di pagine √® pari allo spazio indirizzabile diviso per la dimensione della singola pagina, all'aumentare della dimensione delle pagine diminuisce il numero di entry necessarie.",
    "hint": "Rifletti sul rapporto matematico tra dimensione delle pagine e quantit√† di pagine richieste."
  },
  {
    "question": "Un compilatore genera l'indirizzo logico 576 per riferirsi ad una certa locazione di memoria fisica. Assumendo che la traduzione degli indirizzi avvenga tramite rilocazione statica con indirizzo fisico base = 24, quale sar√† l'indirizzo fisico corrispondente?",
    "options": [
      {
        "text": "576",
        "image": ""
      },
      {
        "text": "552",
        "image": ""
      },
      {
        "text": "600",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere al problema",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Nella rilocazione statica con registro base, l'indirizzo fisico si calcola sommando l'indirizzo logico al valore base: Physical Address = Logical Address + Base. Quindi 576 + 24 = 600.",
    "hint": "Ricorda la formula di traslazione degli indirizzi nel modello base e limite."
  },
  {
    "question": "Si consideri un processo di dimensione pari a 2,488 bytes e un blocco di memoria libero di dimensione pari a 2,699 bytes. In questo caso, assumendo il vincolo di allocazione contigua della memoria, la scelta pi√π conveniente √®:",
    "options": [
      {
        "text": "Allocare l'intero blocco al processo, sprecando 211 bytes(frammentazione interna)",
        "image": ""
      },
      {
        "text": " Allocare la porzione del blocco necessaria al processo e aggiungere alla lista dei blocchi liberi i 211 bytes rimanente(frammentazione esterna)",
        "image": ""
      },
      {
        "text": "Attendere che vi sia un blocco di dimensione multipla rispetto a quella del processo",
        "image": ""
      },
      {
        "text": "Attendere che vi sia un blocco di dimensione inferiore adatto a contenere il processo",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "In sistemi con partizioni fisse o blocchi predefiniti, si alloca l'intero blocco disponibile anche se eccedente, generando frammentazione interna. I 211 byte residui rimangono inutilizzabili all'interno del blocco assegnato, non essendo restituibili come blocco libero separato.",
    "hint": "Distingui tra frammentazione interna (spreco dentro il blocco allocato) ed esterna (spreco fuori)."
  },
  {
    "question": "Si consideri un processo di dimensione pari a 4,996 e un blocco di memoria libero di dimensione pari a 5,016 bytes. In questo caso, assumendo il vincolo di allocazione contigua della memoria, la scelta pi√π conveniente √®:",
    "options": [
      {
        "text": "Attendere che vi sia un blocco di dimensione inferiore adatto a contenere il processo",
        "image": ""
      },
      {
        "text": "Allocare l'intero blocco al processo, sprecando 20 bytes(frammentazione interna)",
        "image": ""
      },
      {
        "text": "Attendere che vi sia un blocco di dimensione multipla rispetto a quella dei processi",
        "image": ""
      },
      {
        "text": "Allocare la porzione del blocco necessaria al processo e aggiungere alla lista dei blocchi liberi i 20 bytes rimanenti(frammentazione esterna)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In allocazioni contigue con blocchi di dimensione fissa, si assegna l'intero blocco di 5,016 byte al processo, accettando la frammentazione interna di 20 byte. Questo evita di creare un frammento esterno troppo piccolo per essere gestibile efficientemente.",
    "hint": "Valuta se i 20 byte rimanenti sarebbero praticamente utilizzabili come blocco libero indipendente."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 99 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D le cui dimensioni sono rispettivamente 102 KiB, 99 KiB, 256 KiB e 128 KiB, quale blocco verr√† allocato per P assumendo una politica Worst-Fit?",
    "options": [
      {
        "text": "blocco A",
        "image": ""
      },
      {
        "text": "blocco C",
        "image": ""
      },
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "blocco D",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La politica Worst-Fit seleziona il blocco libero pi√π grande disponibile per minimizzare la frammentazione esterna, lasciando frammenti di grandi dimensioni. Tra i blocchi disponibili, C (256 KiB) √® il pi√π grande che possa contenere i 99 KiB richiesti.",
    "hint": "Cerca il blocco di dimensione maggiore tra quelli che possono ospitare il processo."
  },
  {
    "question": " Si supponga che un processo P necessiti di un'area di memoria libera pari a 99 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D, E, F le cui dimensioni sono rispettivamente 300 KiB, 600 KiB, 350 KiB, 200 KiB, 750 KiB e 125 KiB, quale blocco verr√† allocato per P assumendo una politica Worst-Fit?",
    "options": [
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "Non √® possibile soddisfare la richiesta, pertanto P dovr√† attendere",
        "image": ""
      },
      {
        "text": "C e i restati 25 KiB vengono allocati su A",
        "image": ""
      },
      {
        "text": "blocco E",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Con la strategia Worst-Fit viene scelto sempre il blocco di memoria libera pi√π grande capace di contenere il processo. Il blocco E (750 KiB) √® il pi√π grande della lista e pu√≤ ospitare i 99 KiB richiesti.",
    "hint": "Identifica il blocco con la dimensione massima nella lista."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 128 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D le cui dimensioni sono rispettivamente 105 KiB, 916 KiB, 129 KiB e 80 KiB, quale blocco verr√† allocato per P assumendo una politica First-Fit?",
    "options": [
      {
        "text": "blocco A",
        "image": ""
      },
      {
        "text": "blocco D",
        "image": ""
      },
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "blocco C",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo First-Fit scorre la lista dei blocchi in ordine e alloca il primo che soddisfa la richiesta. Il blocco A (105 KiB) √® troppo piccolo, quindi viene selezionato il successivo B (916 KiB).",
    "hint": "Scorri la lista dall'inizio e fermati al primo blocco sufficientemente grande."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 115 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D,E,F le cui dimensioni sono rispettivamente 300 KiB, 600 KiB, 350 KiB, 200 KiB,750 KiB e 125 KiB quale blocco verr√† allocato per P assumendo una politica First-Fit?",
    "options": [
      {
        "text": "blocco A",
        "image": ""
      },
      {
        "text": "blocco F",
        "image": ""
      },
      {
        "text": "blocco E",
        "image": ""
      },
      {
        "text": "blocco D",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La politica First-Fit assegna il primo blocco nella sequenza che sia grande abbastanza per contenere il processo. Il blocco A (300 KiB) √® il primo che pu√≤ ospitare 115 KiB.",
    "hint": "Controlla i blocchi in ordine partendo dal primo."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 375 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D,E,F le cui dimensioni sono rispettivamente 300 KiB, 600 KiB, 350 KiB, 200 KiB,750 KiB e 125 KiB quale blocco verr√† allocato per P assumendo una politica Best-Fit?",
    "options": [
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "blocco C e i restanti 25 Kib vengono allocati su A",
        "image": ""
      },
      {
        "text": "blocco E",
        "image": ""
      },
      {
        "text": "Non √® possibile soddisfare la richiesta, pertanto P dovr√† attendere",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Best-Fit cerca il blocco pi√π piccolo tra quelli che possono contenere il processo per minimizzare la frammentazione interna. Tra i blocchi idonei (B: 600 KiB ed E: 750 KiB), B √® il pi√π piccolo.",
    "hint": "Trova il blocco pi√π piccolo che sia comunque grande almeno quanto la richiesta."
  },
  {
    "question": "Si supponga che un processo P necessiti di un'area di memoria libera pari a 34 KiB per essere allocato in modo contiguo in memoria principale. Se la lista dei blocchi di memoria libera contiene i seguenti elementi: A, B, C, D le cui dimensioni sono rispettivamente 36 KiB, 90 KiB, 42 KiB e 35 KiB, quale blocco verr√† allocato per P assumendo una politica Best-Fit?",
    "options": [
      {
        "text": "blocco A",
        "image": ""
      },
      {
        "text": "blocco B",
        "image": ""
      },
      {
        "text": "blocco C",
        "image": ""
      },
      {
        "text": "blocco D",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La politica Best-Fit seleziona il blocco libero pi√π piccolo in grado di contenere il processo, minimizzando lo spreco di memoria. Tra i blocchi disponibili, D (35 KiB) √® il pi√π piccolo che pu√≤ contenere 34 KiB, lasciando solo 1 KiB di residuo.",
    "hint": "Cerca il blocco che minimizza la differenza tra dimensione del blocco e dimensione richiesta."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 4 KiB, ossia 4,096 bytes. Assumendo che l'indirizzamento avvenga con lunghezza di parola (word size) pari 2 bytes e che M utilizzi una gestione paginata con blocchi di dimensione pari a S = 128 bytes, quanti bit sono necessari per identificare l'indice di pagina (p) e l'offset (interno alla pagina), rispettivamente?",
    "options": [
      {
        "text": "p=6; offset=5",
        "image": ""
      },
      {
        "text": "b.p=7; offset=5",
        "image": ""
      },
      {
        "text": "p=5; offset=7",
        "image": ""
      },
      {
        "text": "p=5; offset=6",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Con frame di 128 bytes (2^7), servono 7 bit per l'offset. La memoria totale di 4 KiB contiene 4096/128 = 32 pagine (2^5), richiedendo 5 bit per l'indice di pagina.",
    "hint": "Calcola il numero di pagine totali e i bit necessari per indirizzare l'interno di un frame."
  },
  {
    "question": "Si consideri una memoria M di capacit√† pari a 512 bytes con frame di dimensione pari a 16 bytes. Dato l'indirizzo del byte 197, quale sar√† l'indirizzo di pagina (p) e l'offset (interno alla pagina):",
    "options": [
      {
        "text": "p=5; offset=12",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "p=13; offset=0",
        "image": ""
      },
      {
        "text": "p=12; offset=5",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Dividendo l'indirizzo logico 197 per la dimensione del frame (16 bytes) si ottiene quoziente 12 (pagina) e resto 5 (offset).",
    "hint": "La pagina √® il quoziente della divisione intera per la dimensione del frame."
  },
  {
    "question": "Si consideri una memoria M di capacit√† pari a 100 bytes con frame di dimensione pari a 10 bytes. Dato l‚Äôindirizzo del byte 37, quale sar√† l‚Äôindirizzo di pagina (p) e l‚Äôoffset (interno alla pagina).",
    "options": [
      {
        "text": "p=3; offset=7",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "p=7; offset=3",
        "image": ""
      },
      {
        "text": "p=0; offset=37",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Dividendo 37 per 10 si ottiene quoziente 3 (numero di pagina) e resto 7 (offset interno alla pagina).",
    "hint": "Applica la divisione intera tra indirizzo e dimensione frame."
  },
  {
    "question": "Si consideri un processo di dimensione pari a 2,097 bytes e un blocco di memoria libero di dimensione pari a 2,104 bytes. In questo caso, assumendo il vincolo di allocazione contigua della memoria, la scelta pi√π conveniente √®:",
    "options": [
      {
        "text": "Attendere che vi sia un blocco di dimensione multipla rispetto a quella del processo",
        "image": ""
      },
      {
        "text": "Allocare l'intero blocco al processo, sprecando 7 bytes (frammentazione interna)",
        "image": ""
      },
      {
        "text": "Attendere che vi sia un blocco di dimensione inferiore adatto a contenere il processo",
        "image": ""
      },
      {
        "text": "Allocare la porzione del blocco necessaria al processo e aggiungere alla lista dei blocchi liberi i 7 bytes rimanenti (frammentazione esterna)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In sistemi a blocchi fissi come la paginazione, la memoria viene allocata in unit√† discrete non divisibili. Lo spazio inutilizzato (7 bytes) rimane intrappolato all'interno del blocco assegnato, generando frammentazione interna piuttosto che esterna.",
    "hint": "Pensa alla differenza tra spazio inutilizzato dentro il blocco assegnato versus spazio restituito alla lista dei liberi."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 2 KiB, ossia 2,048 bytes. Assumendo che l‚Äôindirizzamento avvenga con lunghezza di parola (word size) pari a 4 bytes, quanti bit sono necessari ad indirizzare le parole contenute in M?",
    "options": [
      {
        "text": "2",
        "image": ""
      },
      {
        "text": "9",
        "image": ""
      },
      {
        "text": "11",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere al problema",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Per determinare i bit necessari per indirizzare le parole, si calcola il numero totale di parole dividendo la capacit√† in bytes per la dimensione della parola (2048/4 = 512 parole). Il numero di bit richiesti √® il logaritmo in base 2 del numero di parole indirizzabili, ovvero log‚ÇÇ(512) = 9 bit, poich√© 2^9 = 512.",
    "hint": "Calcola quante parole da 4 byte contiene una memoria di 2048 byte, poi trova la potenza di 2 corrispondente."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 4 KiB ossia 4,096 bytes. Assumendo che l‚Äôindirizzamento avvenga con lunghezza di parola (word size) pari a 2 bytes, quanti bit sono necessari ad indirizzare le parole contenute in M?",
    "options": [
      {
        "text": "10",
        "image": ""
      },
      {
        "text": "11",
        "image": ""
      },
      {
        "text": "12",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La memoria contiene 4096/2 = 2048 parole indirizzabili. Per indirizzare 2048 parole distinte sono necessari 11 bit, essendo 2^11 = 2048 il numero di combinazioni possibili.",
    "hint": "Dividi la capacit√† totale per la dimensione della parola e ricorda che 2^10 = 1024."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 8 KiB, ossia 8,192 bytes. Assumendo che l'indirizzamento avvenga con lunghezza di parola (word size) pari al singolo byte e che M utilizzi una gestione paginata con blocchi di dimensione pari a S = 128 bytes, quale dimensione (intesa come numero di entry) ha la corrispondente page table T?",
    "options": [
      {
        "text": "I dati sono insufficienti per rispondere al problema",
        "image": ""
      },
      {
        "text": "13",
        "image": ""
      },
      {
        "text": "64",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "In un sistema paginato, la page table contiene una entry per ogni pagina (o frame) presente in memoria. Il numero di pagine si ottiene dividendo la capacit√† totale della memoria (8192 byte) per la dimensione del blocco (128 byte), risultando in 64 entry.",
    "hint": "Il numero di entry della page table corrisponde al numero di blocchi (pagine) in cui √® suddivisa la memoria fisica."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 8 KiB, ossia 8,192 bytes. Assumendo che l‚Äôindirizzamento avvenga con lunghezza di parola (word size) pari a 4 bytes e che M utilizzi una gestione paginata con blocchi di dimensione pari a S = 256 bytes, quale sar√† il numero di entry della corrispondente page table T?",
    "options": [
      {
        "text": "32",
        "image": ""
      },
      {
        "text": "2048",
        "image": ""
      },
      {
        "text": "8",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La dimensione della page table √® determinata dal numero di pagine in cui viene suddivisa la memoria fisica, calcolato come rapporto tra capacit√† totale (8192 byte) e dimensione del blocco (256 byte), ovvero 32 entry. La word size non influenza il numero di entry della page table.",
    "hint": "Ignora la word size per questo calcolo: conta semplicemente quanti blocchi da 256 byte entrano in 8192 byte."
  },
  {
    "question": "Si supponga di avere una memoria M di capacit√† pari a 16 KiB, ossia 16,384 bytes. Assumendo che l‚Äôindirizzamento avvenga con lunghezza di parola (word size) pari a 4 bytes e che M utilizzi una gestione paginata con blocchi di dimensione pari a S = 64 bytes, quale sar√† il numero di entry della corrispondente page table T?",
    "options": [
      {
        "text": "4096",
        "image": ""
      },
      {
        "text": "16",
        "image": ""
      },
      {
        "text": "256",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere al problema",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il numero di entry nella page table corrisponde al numero di frame fisici (o pagine) ottenuto dividendo la capacit√† della memoria fisica (16384 byte) per la dimensione del blocco di paginazione (64 byte), che risulta in 256 entry.",
    "hint": "16 KiB diviso 64 byte: ricorda che 1 KiB = 1024 byte, quindi 16*1024/64."
  },
  {
    "question": "Si consideri un sistema operativo che utilizza indirizzi logici da 21 bit, indirizzo fisico da 16 bit e memoria paginata in cui ciascuna pagina ha dimensione 2 KiB(2048 bytes). Qual √® la dimensione massima di memoria fisica supportata dal sistema?",
    "options": [
      {
        "text": "32 KiB",
        "image": ""
      },
      {
        "text": "64 KiB",
        "image": ""
      },
      {
        "text": "2 MiB",
        "image": ""
      },
      {
        "text": "Non esiste un limite fisico alla memoria supportata dal sistema",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La dimensione massima della memoria fisica √® determinata esclusivamente dalla lunghezza dell'indirizzo fisico: con 16 bit si indirizzano 2^16 = 65536 byte, ovvero 64 KiB. La dimensione dell'indirizzo logico (21 bit) e quella della pagina (2 KiB) influenzano lo spazio virtuale e la struttura della tabella delle pagine, ma non il limite fisico indirizzabile.",
    "hint": "Calcola 2 elevato al numero di bit dell'indirizzo fisico e converti in KiB, ignorando i dati sulle pagine."
  },
  {
    "question": "La memoria virtuale consente di:",
    "options": [
      {
        "text": "Aumentare l'efficienza delle operazioni di I/O",
        "image": ""
      },
      {
        "text": "Mantenere allocate in memoria fisica solo alcune pagine dello spazio di indirizzamento logico di un processo",
        "image": ""
      },
      {
        "text": "Diminuire il grado di multiprogrammazione del sistema",
        "image": ""
      },
      {
        "text": "Eseguire un processo direttamente dai dispositivi di memoria secondaria (e.g., disco)",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La memoria virtuale consente di mantenere in RAM solo il sottoinsieme di pagine (working set) necessario all'esecuzione corrente, mentre le altre risiedono su disco. Questo permette di eseguire processi con spazio logico superiore alla memoria fisica e aumenta il grado di multiprogrammazione.",
    "hint": "Pensa alla separazione tra spazio degli indirizzi logici e memoria fisica reale."
  },
  {
    "question": "Se un'istruzione idempotente genera un page fault:",
    "options": [
      {
        "text": "Il processo di cui fa parte l'istruzione termina",
        "image": ""
      },
      {
        "text": "Le istruzioni idempotenti non possono generare page fault",
        "image": ""
      },
      {
        "text": "L'istruzione non verr√† pi√π eseguita una volta effettuato il ritorno dalla gestione del page fault",
        "image": ""
      },
      {
        "text": "L'istruzione verr√† nuovamente eseguita al ritorno dalla gestione del page fault",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "Un'istruzione idempotente produce lo stesso effetto anche se eseguita multiple volte. Quando avviene un page fault, il sistema operativo sospende l'istruzione, carica la pagina e riavvia l'istruzione dall'inizio al ritorno; l'idempotenza garantisce che la riesecuzione sia sicura.",
    "hint": "Cosa succede al Program Counter dopo che il sistema operativo gestisce il page fault?"
  },
  {
    "question": ".Il problema della frammentazione esterna:",
    "options": [
      {
        "text": "Necessita di un supporto hardware per essere risolto",
        "image": ""
      },
      {
        "text": "Non √® risolvibile a meno di un riavvio del sistema",
        "image": ""
      },
      {
        "text": "E‚Äô una conseguenza del vincolo di allocazione contigua della memoria",
        "image": ""
      },
      {
        "text": "Causa un‚Äôinterruzione hardware",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La frammentazione esterna √® una conseguenza diretta del vincolo di allocare processi in blocchi contigui di memoria fisica. L'allocazione e deallocazione dinamica di blocchi di dimensioni variabili crea 'buchi' liberi frammentati che, pur sommando a memoria sufficiente, non possono soddisfare richieste contigue.",
    "hint": "Considera cosa succede alla memoria libera quando processi di dimensioni diverse occupano e rilasciano spazio contiguo."
  },
  {
    "question": "Il problema della frammentazione esterna",
    "options": [
      {
        "text": "Non √® risolvibile a meno di un riavvio del sistema",
        "image": ""
      },
      {
        "text": "Causa un‚Äôinterruzione hardware",
        "image": ""
      },
      {
        "text": "Necessita di un supporto hardware per essere risolto",
        "image": ""
      },
      {
        "text": "E‚Äô dovuto all‚Äô allocazione/deallocazione di blocchi contigui di memoria",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La frammentazione esterna si manifesta specificatamente a causa dell'allocazione e deallocazione ripetuta di blocchi contigui di memoria di dimensioni diverse. Questo processo frammenta lo spazio libero in piccoli segmenti non contigui, rendendo impossibile soddisfare nuove richieste di memoria contigua anche se la memoria libera totale √® sufficiente.",
    "hint": "Rifletti sul risultato dell'allocazione dinamica di blocchi contigui di dimensioni variabili."
  },
  {
    "question": "Il working set √®:",
    "options": [
      {
        "text": "Fissato per ogni quanto di tempo",
        "image": ""
      },
      {
        "text": "Relativamente grande rispetto all‚Äôintero spazio di indirizzamento di un processo",
        "image": ""
      },
      {
        "text": "Relativamente piccolo rispetto all‚Äôintero spazio di indirizzamento di un processo",
        "image": ""
      },
      {
        "text": "Fissato per l‚Äôintera esecuzione di un processo",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il working set rappresenta l'insieme delle pagine attivamente utilizzate da un processo in un dato intervallo di tempo (finestra), riflettendo il principio di localit√† dei riferimenti. Poich√© i programmi tendono a concentrare gli accessi su un sottoinsieme limitato del loro spazio di indirizzamento, il working set √® tipicamente molto pi√π piccolo della memoria totale richiesta dal processo.",
    "hint": "Pensa al principio di localit√†: un programma usa tutta la sua memoria contemporaneamente o solo una parte in ogni istante?"
  },
  {
    "question": "Si consideri un sistema che implementa la politica LRU per la sostituzione dei frame mediante l‚Äôuso di un timestamp. Ad ogni richiesta di accesso ad un determinato frame occorre:",
    "options": [
      {
        "text": "Incrementare una variabile di tipo contatore",
        "image": ""
      },
      {
        "text": "Aggiornare il valore del timestamp con quello corrente",
        "image": ""
      },
      {
        "text": "Impostare un bit di validit√†",
        "image": ""
      },
      {
        "text": "Nessuna delle precedenti risposte √® corretta",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo LRU (Least Recently Used) richiede di identificare la pagina non utilizzata da pi√π tempo. Utilizzando un timestamp, ogni accesso a un frame deve aggiornare il suo timestamp al valore corrente per marcarlo come il pi√π recentemente usato, permettendo di individuare la vittima come quella con il timestamp pi√π vecchio.",
    "hint": "Se LRU deve sapere qual √® stata usata meno recentemente, cosa deve succedere al timestamp ogni volta che accedo a una pagina?"
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: B, C, C, B, A, E, B, A, E, D, B. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo LRU di sostituzione delle pagine.",
    "options": [
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      },
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Simulando l'algoritmo LRU con 3 frame: i fault iniziali sono per B, C, A (3 fault). Quando arriva E, sostituisce C (meno recente). Successivi hit per B, A, E. Quando arriva D sostituisce B, e quando arriva B finale sostituisce A, per un totale di 6 page fault.",
    "hint": "Tieni traccia dell'ordine di utilizzo: quando un frame √® pieno, la vittima √® quella non usata da pi√π tempo, anche se √® stata caricata da poco."
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: D, B, A, C, C, E, A, D, B, E, D, A. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo LRU di sostituzione delle pagine.",
    "options": [
      {
        "text": "10",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "9",
        "image": ""
      },
      {
        "text": "6",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Con 3 frame disponibili, la sequenza genera fault per D, B, A, C (4 fault iniziali). Poi E sostituisce B, D sostituisce C, B sostituisce E, E sostituisce A, e infine A sostituisce B, arrivando a 9 page fault totali. Gli hit si verificano solo su C, A, D.",
    "hint": "Segui passo dopo passo: dopo ogni accesso, aggiorna l'ordine di recentezza e verifica se la pagina richiesta √® gi√† presente nei frame."
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: C,B,C,B,A,E,B,A. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo LRU di sostituzione delle pagine.",
    "options": [
      {
        "text": "2",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      },
      {
        "text": "1",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "I page fault si verificano per C (primo caricamento), B (secondo caricamento), A (terzo frame riempito) ed E (sostituisce C, che √® la pagina meno recentemente usata tra C, B, A). Le richieste successive di B e A sono hit poich√© entrambe sono state accedute recentemente.",
    "hint": "Nota che dopo le prime quattro richieste (C,B,C,B), le pagine C e B sono ancora 'fresche' in memoria, quindi A occupa il terzo frame senza sostituzioni."
  },
  {
    "question": "Data una memoria fisica composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: A, B, E, C, E, D, D, A, B. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo FIFO di sostituzione delle pagine.",
    "options": [
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "8",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo FIFO sostituisce la pagina caricata da pi√π tempo indipendentemente dalle future richieste. Con 3 frame, la sequenza genera page fault per A, B, E (caricamento iniziale), C (sostituisce A), D (sostituisce B), A (sostituisce E) e B (sostituisce C), per un totale di 7 fault.",
    "hint": "Traccia l'ordine di arrivo delle pagine nei frame per determinare quale viene espulsa quando la memoria √® piena."
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E, si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: D, A, C, B, B, A, C, B, D, E, A. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo FIFO di sostituzione delle pagine.",
    "options": [
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Con l'algoritmo FIFO e 3 frame disponibili, si verificano page fault iniziali per D, A, C. Quando arriva B, sostituisce D (il pi√π vecchio). Successivamente D sostituisce A, E sostituisce C, e infine A sostituisce B, arrivando a 7 fault totali.",
    "hint": "Ricorda che FIFO espelle sempre la pagina inserita meno recentemente, anche se verr√† usata a breve."
  },
  {
    "question": "Data una memoria composta da 3 frame fisici e un processo composto da 5 pagine virtuali: A, B, C, D, E si calcoli il numero di page fault che si verificano a fronte delle seguenti richieste da parte del processo: E, B, E, C, D, E, A, B, E. Si assuma che nessuna pagina del processo sia inizialmente caricata in memoria e che si utilizzi un algoritmo FIFO di sostituzione delle pagine.",
    "options": [
      {
        "text": "7",
        "image": ""
      },
      {
        "text": "8",
        "image": ""
      },
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo FIFO gestisce i frame come una coda FIFO. Dopo i fault iniziali per E e B, il terzo accesso a E √® un hit che non modifica l'ordine di sostituzione. Seguendo la sequenza si ottengono 7 fault totali: E, B, C, D, E, A, B.",
    "hint": "Attenzione: quando una pagina gi√† presente viene richiesta nuovamente (hit), la sua posizione nella coda FIFO non cambia."
  },
  {
    "question": "In un disco magnetico, il seek time:",
    "options": [
      {
        "text": "√à il tempo necessario al disco per posizionare le proprie testine su uno specifico settore",
        "image": ""
      },
      {
        "text": "Include il tempo di trasferimento alla memoria principale",
        "image": ""
      },
      {
        "text": "√à il tempo necessario al disco per posizionare le proprie testine su uno specifico cilindro",
        "image": ""
      },
      {
        "text": "√à trascurabile rispetto all'intero tempo necessario al trasferimento dei dati",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il seek time rappresenta il tempo di posizionamento delle testine sul braccio del disco per raggiungere il cilindro (traccia) desiderato. √à distinto dal rotational latency (attesa settore) e dal transfer time.",
    "hint": "Pensa al movimento radiale del braccio delle testine, non alla rotazione del piatto o al trasferimento dati."
  },
  {
    "question": "Un disco √® composto da 15 cilindri, ciascuno di capacit√† pari a 500 MB. Qual √® la capacit√† totale del disco?",
    "options": [
      {
        "text": "7.5 GB",
        "image": ""
      },
      {
        "text": "75 GB",
        "image": ""
      },
      {
        "text": "750 MB",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere al problema",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "La capacit√† totale si calcola moltiplicando il numero di cilindri per la capacit√† unitaria: 15 √ó 500 MB = 7500 MB = 7.5 GB, assumendo la convenzione commerciale dove 1 GB = 1000 MB.",
    "hint": "Converti 7500 MB in GB dividendo per 1000."
  },
  {
    "question": "Si supponga che il tempo di accesso alla memoria fisica sia tMA = 50 nsec. e che il tempo per la gestione di un page fault tFAULT  sia pari a 15 msec. Assumendo che la probabilit√† che si verifichi un page fault sia p = 0.0002, qual √® il tempo complessivo atteso di accesso alla memoria?",
    "options": [
      {
        "text": "~30.5 nsec",
        "image": ""
      },
      {
        "text": "~30.5 microsec",
        "image": ""
      },
      {
        "text": "~3.05 microsec",
        "image": ""
      },
      {
        "text": "~305 nsec",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il tempo di accesso atteso si calcola come media pesata E[T] = (1-p)√ótMA + p√ótFAULT. Convertendo 15 msec in nanosecondi (15√ó10‚Å∂) e calcolando: 0,9998√ó50 + 0,0002√ó15.000.000 ‚âà 50 + 3.000 = 3.050 nsec, ovvero circa 3,05 microsecondi.",
    "hint": "Converti tutte le unit√† di tempo nella stessa scala (nanosecondi) prima di applicare la formula del valore atteso."
  },
  {
    "question": "Si supponga che il tempo di accesso alla memoria fisica sia tMA = 25 nsec. e che il tempo per la gestione di un page fault  tFAULT sia pari a 30 msec. Assumendo che la probabilit√† che si verifichi un page fault sia p = 0.005, qual √® il tempo complessivo atteso di accesso alla memoria?",
    "options": [
      {
        "text": "~150.025 microsec",
        "image": ""
      },
      {
        "text": "~15.025 nsec",
        "image": ""
      },
      {
        "text": "~150.025 nsec",
        "image": ""
      },
      {
        "text": "~15.025 microsec",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Utilizzando la formula E[T] = (1-p)√ótMA + p√ótFAULT, si ottiene: 0,995√ó25 nsec + 0,005√ó30.000.000 nsec ‚âà 25 + 150.000 = 150.025 nsec, che corrisponde a circa 150,025 microsecondi.",
    "hint": "Ricorda che 1 millisecondo equivale a 1.000.000 di nanosecondi, e il termine del page fault domina il risultato finale."
  },
  {
    "question": "Si supponga che il tempo di accesso alla memoria fisica sia tMA = 50 nsec. e che il tempo per la gestione di un page fault tFAULT sia pari a 25 msec. Assumendo che il tempo medio di accesso alla memoria sia pari a 0.5 microsec, qual √® la probabilit√† p che si verifichi un page fault?",
    "options": [
      {
        "text": "~0.02%",
        "image": ""
      },
      {
        "text": "~0.2%",
        "image": ""
      },
      {
        "text": "~0.002%",
        "image": ""
      },
      {
        "text": "~0.0002%",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Dalla formula E[T] = (1-p)√ótMA + p√ótFAULT, ponendo E[T] = 500 nsec (0,5 Œºsec) e risolvendo per p, si ottiene p ‚âà (500-50)/25.000.000 = 0,000018. Arrotondato a due cifre significative diventa 0,00002, ovvero lo 0,002%.",
    "hint": "Imposta l'equazione con il tempo atteso noto e risolvi per p, trascurando il termine -50p come trascurabile rispetto a 25.000.000p."
  },
  {
    "question": "Si supponga che il tempo di accesso alla memoria fisica sia tMA  = 60 nsec. e che il tempo per la gestione di un page fault tFAULT  sia pari a 5 msec. Quale dovr√† essere il valore della probabilit√† che si verifichi un fault () se si vuole garantire che il tempo atteso di accesso alla memoria sia al pi√π il 20% pi√π lento di tMA ? (Si ricordi che 1 msec = 10^3 microsec = 10^6 nsec)",
    "options": [
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      },
      {
        "text": "~0,00024%",
        "image": ""
      },
      {
        "text": " ~0,000024%",
        "image": ""
      },
      {
        "text": " ~0,0000024%",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il vincolo richiede E[T] ‚â§ 1,2√ó60 = 72 nsec. Risolvendo (1-p)√ó60 + p√ó5.000.000 ‚â§ 72 si ottiene p ‚â§ 12/(5.000.000-60) ‚âà 0,0000024, che espresso in percentuale √® circa 0,00024%.",
    "hint": "Calcola il ritardo massimo tollerabile (il 20% di tMA) e imposta la disequazione per trovare la probabilit√† massima che lo soddisfi."
  },
  {
    "question": "Si consideri un disco magnetico composto da 128 cilindri/tracce, numerati da 0 a 127 (0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 42. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 74, 50, 32, 55, 81 venga gestita da un algoritmo di scheduling SSTF (Shortest Seek Time First) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "86",
        "image": ""
      },
      {
        "text": "49",
        "image": ""
      },
      {
        "text": "123",
        "image": ""
      },
      {
        "text": "88",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo SSTF seleziona ad ogni passo la richiesta pi√π vicina alla posizione attuale della testina. La sequenza risultante √®: 42‚Üí50 (8), 50‚Üí55 (5), 55‚Üí74 (19), 74‚Üí81 (7), 81‚Üí32 (49), per un totale di 88 cilindri attraversati.",
    "hint": "Calcola la distanza assoluta tra la posizione corrente e ogni richiesta pendente, scegliendo sempre il valore minimo."
  },
  {
    "question": "Si consideri un disco magnetico composto da 128 cilindri/tracce, numerati da 0 a 127 (0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 87. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 43, 81, 36, 25, 127 venga gestita da un algoritmo di scheduling FCFS (First Come First Served) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "290",
        "image": ""
      },
      {
        "text": "240",
        "image": ""
      },
      {
        "text": "238",
        "image": ""
      },
      {
        "text": "265",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo FCFS serve le richieste nell'ordine di arrivo. Il numero di cilindri attraversati √® la somma dei valori assoluti delle differenze tra posizioni consecutive: |87-43| + |43-81| + |81-36| + |36-25| + |25-127| = 44 + 38 + 45 + 11 + 102 = 240.",
    "hint": "Calcola la distanza assoluta tra la posizione corrente e ogni richiesta successiva nell'ordine dato, poi somma tutti gli spostamenti."
  },
  {
    "question": "Il tempo di trasferimento totale per un'operazione di I/O da disco magnetico √® pari a 30 msec. Sapendo che: il seek time complessivo √® pari a 18 msec, il rotational delay complessivo √® pari a 7 msec e che il transfer rate √® pari a 1.5 Gbit/sec, qual √® la quantit√† totale di dati trasferita? (Si ricordi che 1 B = 1 byte = 8 bit e 1 MB = 10^3 KB = 10^6 B)",
    "options": [
      {
        "text": "9.375 MB",
        "image": ""
      },
      {
        "text": "7.5 MB",
        "image": ""
      },
      {
        "text": "937.5 KB",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il tempo effettivo di trasferimento dati √® il tempo totale meno seek time e rotational delay: 30 - 18 - 7 = 5 ms. Convertendo il transfer rate (1.5 Gbit/s = 187.5 MB/s) e moltiplicando per 0.005 s si ottengono 937.5 KB.",
    "hint": "Ricorda che il tempo di trasferimento utile √® la differenza tra il tempo totale e la somma di seek time e rotational delay."
  },
  {
    "question": "Il tempo di trasferimento totale per un'operazione di I/O da disco magnetico √® pari a 40 msec. Sapendo che: il seek time complessivo √® pari a 18 msec, il rotational delay complessivo √® pari a 7 msec e che il transfer rate √® pari a 5 Gbit/sec, qual √® la quantit√† totale di dati trasferita? (Si ricordi che 1 B = 1 byte = 8 bit e 1 MB = 10^3 KB = 10^6 B)",
    "options": [
      {
        "text": "9.375 MB",
        "image": ""
      },
      {
        "text": "70 MB",
        "image": ""
      },
      {
        "text": "70 KB",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il tempo netto di trasferimento √® 40 - 18 - 7 = 15 ms. Con un transfer rate di 5 Gbit/s (625 MB/s), in 15 ms vengono trasferiti 9.375 MB (625 MB/s √ó 0.015 s).",
    "hint": "Sottrai seek time e rotational delay dal tempo totale per trovare il tempo effettivo di trasferimento dati."
  },
  {
    "question": "Il tempo di trasferimento totale per un'operazione di I/O da disco magnetico √® pari a 36 msec. Sapendo che il seek time complessivo √® pari a 13 msec e che sono stati trasferiti 2MB ad una velocit√† pari a 1 Gbit/sec qual √® il rotational delay del disco?(Si ricordi che 1 B = 1 byte = 8 bit)",
    "options": [
      {
        "text": "7 msec",
        "image": ""
      },
      {
        "text": "2 msec",
        "image": ""
      },
      {
        "text": "16 msec",
        "image": ""
      },
      {
        "text": "I dati sono insufficiente per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il tempo per trasferire 2 MB (16 Mbit) a 1 Gbit/s √® 16 ms. Il rotational delay si calcola come: tempo totale - seek time - tempo trasferimento = 36 - 13 - 16 = 7 ms.",
    "hint": "Calcola prima quanto tempo impiega a trasferire 2 MB alla velocit√† data, poi sottrai seek time e tempo di trasferimento dal tempo totale."
  },
  {
    "question": "Si consideri un disco magnetico composto da 200 cilindri/tracce, numerati da 0 a 199(0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 53. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 98,183,37,122,14,85,67 venga gestita da un algoritmo di scheduling FCFS (First Come First Served) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "595",
        "image": ""
      },
      {
        "text": "558",
        "image": ""
      },
      {
        "text": "650",
        "image": ""
      },
      {
        "text": "638",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Con FCFS la testina segue l'ordine delle richieste. La somma degli spostamenti √®: |53-98| + |98-183| + |183-37| + |37-122| + |122-14| + |14-85| + |85-67| = 45 + 85 + 146 + 85 + 108 + 71 + 18 = 558 cilindri.",
    "hint": "Somma le distanze assolute tra ogni coppia di posizioni consecutive, partendo dalla posizione iniziale 53."
  },
  {
    "question": "Si consideri un disco magnetico composto da 200 cilindri/tracce, numerati da 0 a 199(0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 53. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 98,183,37,122,14,65,67 venga gestita da un algoritmo di scheduling FCFS (First Come First Served) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "650",
        "image": ""
      },
      {
        "text": "522",
        "image": ""
      },
      {
        "text": "638",
        "image": ""
      },
      {
        "text": "595",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo FCFS serve le richieste nell'ordine di arrivo. Il numero di cilindri attraversati √® la somma delle distanze assolute tra posizioni consecutive: |98-53| + |183-98| + |37-183| + |122-37| + |14-122| + |65-14| + |67-65| = 45 + 85 + 146 + 85 + 108 + 51 + 2 = 522.",
    "hint": "Calcola la distanza assoluta tra ogni coppia di cilindri consecutivi nella sequenza e somma i risultati."
  },
  {
    "question": "Si consideri un disco magnetico composto da 100 cilindri/tracce, numerati da 0 a 99 (0 indice del cilindro/traccia pi√π esterno/a rispetto al centro del disco), la cui testina si trova inizialmente sul cilindro 11. Si calcoli il numero di cilindri/tracce attraversate dalla testina del disco, assumendo che la sequenza di richieste: 24, 16, 77, 49, 82 venga gestita da un algoritmo di scheduling SCAN (non-ottimizzato), che la testina si stia muovendo verso l'esterno (i.e., verso i cilindri con numeri pi√π bassi) e trascurando il tempo di rotazione.",
    "options": [
      {
        "text": "76",
        "image": ""
      },
      {
        "text": "87",
        "image": ""
      },
      {
        "text": "46",
        "image": ""
      },
      {
        "text": "93",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo SCAN muove la testina verso l'esterno fino al cilindro 0 (11 cilindri), poi inverte direzione servendo le richieste in ordine crescente: 16, 24, 49, 77, 82. Il totale √® 11 + 16 + 8 + 25 + 28 + 5 = 93.",
    "hint": "Ricorda che SCAN raggiunge sempre l'estremo fisico del disco prima di invertire la direzione, anche senza richieste intermedie."
  },
  {
    "question": "Data la porzione di codice in figura, indicare quale sar√† il valore della variabile value che verr√† stampato alla line 18:",
    "options": [
      {
        "text": "5",
        "image": ""
      },
      {
        "text": "20",
        "image": ""
      },
      {
        "text": "15",
        "image": ""
      },
      {
        "text": "I dati sono insufficiente per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/25.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "Data la porzione di codice in figura, indicare il corrispondente albero dei processi generati:",
    "options": [
      {
        "text": "A",
        "image": ""
      },
      {
        "text": "B",
        "image": ""
      },
      {
        "text": "C",
        "image": ""
      },
      {
        "text": "D",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/26.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "Data la porzione di codice in figura, indicare il corrispondente albero dei processi generati:",
    "options": [
      {
        "text": "A",
        "image": ""
      },
      {
        "text": "B",
        "image": ""
      },
      {
        "text": "C",
        "image": ""
      },
      {
        "text": "D",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/27.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "Si considerino i 5 processi della figura seguente e 3 politiche di scheduling: FCFS, SJF (non-preemptive) e RR con time slice pari a 2 unit√† di tempo. Qual √® la politica che garantisce il minor tempo di attesa (in coda pronti) al processo C?",
    "options": [
      {
        "text": "FCFS",
        "image": ""
      },
      {
        "text": "RR",
        "image": ""
      },
      {
        "text": "SJF",
        "image": ""
      },
      {
        "text": "Tutte e tre le politiche garantiscono al processo C lo stesso tempo di attesa",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/35.png",
    "code": "",
    "explanation": "In FCFS (First-Come-First-Served), i processi vengono eseguiti nell'ordine di arrivo. Se il processo C arriva prima degli altri, non deve attendere in coda, garantendo il minor tempo di attesa.",
    "hint": "Nel FCFS, il tempo di attesa dipende dall'ordine di arrivo dei processi."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling round robin con time slice = 3, nessuna attivit√† di I/O e context switch trascurabile:",
    "options": [
      {
        "text": "6.5",
        "image": ""
      },
      {
        "text": "6.75",
        "image": ""
      },
      {
        "text": "7.15",
        "image": ""
      },
      {
        "text": "5,85",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/36.png",
    "code": "",
    "explanation": "Con RR e time slice = 3, i processi si alternano. Calcolando i tempi di attesa per ciascun processo e facendo la media, si ottiene 6.75.",
    "hint": "Per calcolare il tempo medio di attesa, considera quante unit√† di tempo ogni processo attende prima di essere eseguito completamente."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling Round Robin con time slice q= 4. Nel calcolo, si consideri il tempo necessario ad eseguire il context switch trascurabile:",
    "options": [
      {
        "text": "4.85",
        "image": ""
      },
      {
        "text": "4.25",
        "image": ""
      },
      {
        "text": "4.5",
        "image": ""
      },
      {
        "text": "4.75",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/37.png",
    "code": "",
    "explanation": "Nel Round Robin con q=4, il tempo di attesa dipende dal numero di preemption e dall'ordine di arrivo dei processi. Il tempo medio di attesa si calcola come la somma dei periodi in cui ogni processo √® stato nella ready queue pronto per eseguire, diviso per il numero di processi.",
    "hint": "Ricorda che nel RR il waiting time include tutto il tempo trascorso nella ready queue, inclusi i periodi tra una slice e l'altra."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling Shortest Job First preemptive (SJF). Nel calcolo, si consideri trascurabile il tempo necessario ad eseguire il context switch:",
    "options": [
      {
        "text": "6",
        "image": ""
      },
      {
        "text": "5.75",
        "image": ""
      },
      {
        "text": "4.5",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/38.png",
    "code": "",
    "explanation": "Nel SJF preemptivo (Shortest Remaining Time First), il processo con il tempo di burst rimanente pi√π breve viene eseguito prioritariamente. Il tempo di attesa si calcola dalla differenza tra il tempo di completamento e il tempo di arrivo meno il burst time effettivo.",
    "hint": "Nel SJF preemptivo, considera che un processo pu√≤ essere interrotto se arriva un processo con bursttime pi√π breve."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling First Come First Served (FCFS) e che il processo A esegua all'istante t=2 una chiamata di I/O che si completer√† dopo 4 unit√† di tempo, ossia all'istante t=6. Nel calcolo, si consideri trascurabile il tempo necessario ad eseguire il context switch:",
    "options": [
      {
        "text": "4.5",
        "image": ""
      },
      {
        "text": "5.5",
        "image": ""
      },
      {
        "text": "7.5",
        "image": ""
      },
      {
        "text": "6.5",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/39.png",
    "code": "",
    "explanation": "Nel FCFS con I/O, quando un processo effettua una chiamata di I/O, cede la CPU e gli altri processi possono eseguire. Il tempo di attesa si calcola considerando i periodi in cui ciascun processo attende nella ready queue, inclusi quelli dovuti all'I/O di altri processi.",
    "hint": "Nel FCFS, l'ordine di arrivo determina la sequenza; l'I/O di un processo permette agli altri di avanzare nella CPU."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling First Come First Served (FCFS) e che il processo B esegua all'istante t=6 una chiamata di I/O che si completer√† dopo 3 unit√† di tempo, ossia all'istante t=9. Nel calcolo, si consideri trascurabile il tempo necessario ad eseguire il context switch:",
    "options": [
      {
        "text": "4.5",
        "image": ""
      },
      {
        "text": "5.25",
        "image": ""
      },
      {
        "text": "4",
        "image": ""
      },
      {
        "text": "4.25",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/40.png",
    "code": "",
    "explanation": "Nel FCFS con I/O per il processo B, quando B va in I/O, gli altri processi nella coda possono proseguire. Il waiting time medio considera tutto il tempo che ogni processo trascorre in attesa nella ready queue prima di ottenere la CPU.",
    "hint": "Ricorda che durante l'I/O di un processo, la CPU pu√≤ servire gli altri processi in attesa nella coda FCFS."
  },
  {
    "question": "",
    "options": [
      {
        "text": "72",
        "image": ""
      },
      {
        "text": "73",
        "image": ""
      },
      {
        "text": "74",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/56.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "",
    "options": [
      {
        "text": "23",
        "image": ""
      },
      {
        "text": "24",
        "image": ""
      },
      {
        "text": "25",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/57.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "",
    "options": [
      {
        "text": "18",
        "image": ""
      },
      {
        "text": "19",
        "image": ""
      },
      {
        "text": "20",
        "image": ""
      },
      {
        "text": "I dati sono insufficienti per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/58.png",
    "code": "",
    "explanation": "",
    "hint": ""
  },
  {
    "question": "Il seguente Resource Allocation Graph (RAG) mostra un sistema il cui stato:",
    "options": [
      {
        "text": "Dipende dalle scelte dello scheduler del sistema operativo",
        "image": ""
      },
      {
        "text": "Presenta deadlock",
        "image": ""
      },
      {
        "text": "Non presenta deadlock",
        "image": ""
      },
      {
        "text": "√à impossibile rispondere",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/59.png",
    "code": "",
    "explanation": "In un RAG, il deadlock esiste solo se esiste un ciclo irrisolvibile. Se il sistema non presenta deadlock, significa che il grafo mostra un caso in cui le risorse possono essere rilasciate e i processi possono completare.",
    "hint": "Ricorda che in un RAG un ciclo non implica necessariamente deadlock: dipende dalla disponibilit√† di risorse e dalla possibilit√† di soddisfare tutte le richieste."
  },
  {
    "question": "Il seguente Resource Allocation Graph (RAG) mostra un sistema il cui stato:",
    "options": [
      {
        "text": "Dipende dalle scelte dello scheduler del sistema operativo",
        "image": ""
      },
      {
        "text": "Presente deadlock",
        "image": ""
      },
      {
        "text": "Non presenta deadlock",
        "image": ""
      },
      {
        "text": "E‚Äô impossibile rispondere",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/60.png",
    "code": "",
    "explanation": "In un Resource Allocation Graph, l'assenza di deadlock √® garantita quando non esistono cicli nel grafo o quando, pur esistendo cicli, le risorse coinvolte possiedono multiple istanze che impediscono la condizione di attesa circolare permanente.",
    "hint": "Verifica se esistono percorsi chiusi che coinvolgano processi in attesa di risorse."
  },
  {
    "question": "Il seguente Resource Allocation Graph (RAG) mostra un sistema il cui stato:",
    "options": [
      {
        "text": "Sicuramente presenta deadlock",
        "image": ""
      },
      {
        "text": "Potrebbe presentare deadlock",
        "image": ""
      },
      {
        "text": "Sicuramente non presenta deadlock",
        "image": ""
      },
      {
        "text": "E‚Äô impossibile rispondere",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/61.png",
    "code": "",
    "explanation": "Quando un RAG risulta completamente aciclico, √® possibile affermare con certezza assoluta che il sistema non presenta deadlock, poich√© manca la condizione fondamentale di attesa circolare tra i processi.",
    "hint": "Controlla l'assenza di cicli nel grafo per escludere definitivamente il deadlock."
  },
  {
    "question": "Il seguente Resource Allocation Graph(RAG) mostra un sistema che:",
    "options": [
      {
        "text": "Sicuramente presenta deadlock",
        "image": ""
      },
      {
        "text": "Potrebbe presentare deadlock",
        "image": ""
      },
      {
        "text": "Sicuramente non presenta deadlock",
        "image": ""
      },
      {
        "text": "E‚Äô impossibile rispondere",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/62.png",
    "code": "",
    "explanation": "In un RAG con risorse a istanza singola, la presenza di un ciclo implica necessariamente deadlock; se la risposta √® 'sicuramente presente', il grafo mostra un ciclo dove ogni risorsa ha esattamente un'istanza.",
    "hint": "Cerca un ciclo chiuso dove ogni risorsa coinvolta ha una sola istanza disponibile."
  },
  {
    "question": "Si consideri un sistema che implementa la politica LRU (approssimato) per la sostituzione dei frame mediante l'algoritmo second chance (clock). A fronte di un page fault, l'algoritmo scandisce la lista dei frame; se un frame ha il reference bit impostato al valore 1:",
    "options": [
      {
        "text": "Il reference bit viene lasciato a 1 e il frame √® rimpiazzato con la pagina che ha causato il page fault",
        "image": ""
      },
      {
        "text": "Il reference bit viene impostato a 0 e il frame √® rimpiazzato con la pagina che ha causato il page fault",
        "image": ""
      },
      {
        "text": "Il reference bit viene lasciato a 1 e l'algoritmo prosegue ad esaminare il frame successivo nella lista",
        "image": ""
      },
      {
        "text": "Il reference bit viene impostato a 0 e l'algoritmo prosegue ad esaminare il frame successivo nella lista",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo second chance utilizza il reference bit per approssimare LRU: se il bit √® 1, la pagina √® stata usata recentemente e viene risparmiata (bit azzerato a 0), continuando la scansione per trovare una vittima con bit 0.",
    "hint": "Ricorda che 'second chance' significa dare una seconda opportunit√† alle pagine referenziate."
  },
  {
    "question": "In un sistema che utilizza l'algoritmo SCAN, le richeste di accesso al disco sono: 12, 25, 55, 85, 120, 150. La testina si trova inizialmente sul cilindro 50 e si sta muovendo verso destra. Il disco ha 200 cilindri (numerati da 0 a 199). Qual √® l'ordine in cui le richieste vengono servite?",
    "options": [
      {
        "text": "25, 12, 55, 85, 120, 150",
        "image": ""
      },
      {
        "text": "55, 85, 120, 150, 12, 25",
        "image": ""
      },
      {
        "text": "55, 85, 120, 150, 25, 12",
        "image": ""
      },
      {
        "text": "55, 25, 12, 150, 120, 85",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "L'algoritmo SCAN serve le richieste nella direzione corrente fino all'estremit√† del disco, poi inverte; da 50 verso destra si servono 55, 85, 120, 150, poi invertendo si servono 25 e 12 in ordine decrescente.",
    "hint": "Immagina l'ascensore che sale servendo tutte le chiamate verso l'alto, poi scende."
  },
  {
    "question": "Un disco magnetico impiega complessivamente 35 msec per trasferire 8 MiB di dati. Sapendo che: il seek time complessivo √® pari a 14 msec, il rotational delay √® pari a 6 msec, qual √® il valore del transfer rate del disco? (Si ricordi che 1 MiB = 2^20 bytes)",
    "options": [
      {
        "text": "~4.47 GB/sec",
        "image": ""
      },
      {
        "text": "~4.47 Gbit/sec",
        "image": ""
      },
      {
        "text": "~4.47 MB/sec",
        "image": ""
      },
      {
        "text": "~4.47 Mbit/sec",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "Il transfer rate si calcola dividendo la quantit√† di dati (8 MiB = 67.108.864 bit) per il tempo effettivo di trasferimento, ottenuto sottraendo seek time (14 ms) e rotational delay (6 ms) dai 35 ms totali, risultando in 15 ms. Il calcolo 67.108.864 bit / 0,015 s produce circa 4,47 Gbit/s.",
    "hint": "Ricorda di sottrarre i tempi di posizionamento e rotazione dal tempo totale per ottenere il tempo effettivo di trasferimento dati."
  },
  {
    "question": "Si consideri un sistema con memoria virtuale paginata che utilizza una cache TLB (Translation Look-aside Buffer). In caso di cache hit.",
    "options": [
      {
        "text": "L'indirizzo della pagina richiesta pu√≤ essere in memoria principale",
        "image": ""
      },
      {
        "text": "L'indirizzo della pagina richiesta √® sicuramente in memoria principale",
        "image": ""
      },
      {
        "text": "L'indirizzo della pagina richiesta √® sicuramente su disco",
        "image": ""
      },
      {
        "text": "Non √® possibile rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "La TLB √® una cache che memorizza solo le traduzioni di indirizzi per pagine attualmente residenti in memoria principale; un hit conferma che la pagina √® in RAM e non su disco, evitando il page fault.",
    "hint": "Pensa a cosa memorizza fisicamente la TLB e qual √® la condizione necessaria affinch√© una pagina sia referenziabile in cache."
  },
  {
    "question": "Si consideri un sistema operativo che utilizza indirizzi logici da 21 bit e memoria paginata in cui ciascuna pagina ha dimensione 2 KiB (2048 bytes). Qual √® la dimensione (numero di entry) della relativa page table?",
    "options": [
      {
        "text": "1024",
        "image": ""
      },
      {
        "text": "10",
        "image": ""
      },
      {
        "text": "2048",
        "image": ""
      },
      {
        "text": "1000",
        "image": ""
      }
    ],
    "correctIndex": 0,
    "image": "",
    "code": "",
    "explanation": "Il numero di entry nella page table corrisponde al numero di pagine logiche, calcolato dividendo lo spazio di indirizzamento logico (2^21 byte) per la dimensione della pagina (2^11 byte), ottenendo 2^10 = 1024 entry.",
    "hint": "Calcola quante pagine sono necessarie per coprire tutto lo spazio degli indirizzi logici dividendo lo spazio totale per la dimensione di ciascuna pagina."
  },
  {
    "question": "La memory management unit (MMU):",
    "options": [
      {
        "text": "√à il supporto hardware necessario per l'implementazione della rilocazione dinamica",
        "image": ""
      },
      {
        "text": "Contiene almeno un registro base ed uno limite",
        "image": ""
      },
      {
        "text": "Consente l'allocazione fisica non contigua dello spazio di indirizzamento di un processo",
        "image": ""
      },
      {
        "text": "Tutte le risposte precedenti sono corrette",
        "image": ""
      }
    ],
    "correctIndex": 3,
    "image": "",
    "code": "",
    "explanation": "La MMU √® l'unit√† hardware che gestisce la traduzione degli indirizzi, supportando la rilocazione dinamica tramite registri base/limite e permettendo l'allocazione fisica non contigua tramite tecniche di paginazione o segmentazione.",
    "hint": "Considera tutte le funzioni fondamentali che l'MMU svolge nella gestione della memoria virtuale e fisica."
  },
  {
    "question": "L'uso di thread pool in un server web (multi-threaded):",
    "options": [
      {
        "text": "√à svantaggioso perch√© crea un numero di thread generalmente elevato",
        "image": ""
      },
      {
        "text": "√à svantaggioso perch√© crea un numero di thread generalmente basso",
        "image": ""
      },
      {
        "text": "√à vantaggioso perch√© il costo della creazione di nuovi thread viene ammortizzato dal fatto che un certo numero di essi vengono creati in anticipo",
        "image": ""
      },
      {
        "text": "√à vantaggioso perch√© il costo della creazione di nuovi thread viene ammortizzato dal fatto che un certo numero di essi vengono creati ad ogni richiesta",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "I thread pool pre-allocano un insieme di thread all'avvio del server, eliminando il costo di creazione/distruzione ad ogni richiesta e migliorando le prestazioni tramite riutilizzo.",
    "hint": "Considera il costo computazionale della creazione di un thread rispetto al riutilizzo di thread gi√† esistenti."
  },
  {
    "question": "In un sistema uniprocessore con n processi in coda pronti (schedulabili), quante strategie di scheduling √® possibile implementare (in funzione di n)?",
    "options": [
      {
        "text": "n",
        "image": ""
      },
      {
        "text": "n^2",
        "image": ""
      },
      {
        "text": "n!",
        "image": ""
      },
      {
        "text": "I dati sono insufficiente per rispondere alla domanda",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Il numero di possibili permutazioni di n processi distinti corrisponde al numero di strategie di scheduling sequenziali possibili, ovvero n fattoriale (n!). Ogni permutazione rappresenta infatti un diverso ordine di esecuzione dei processi nella coda ready.",
    "hint": "Pensa a in quanti modi diversi puoi ordinare n oggetti distinti in una sequenza."
  },
  {
    "question": "Quando un processo \"padre\" crea un nuovo processo \"figlio\" tramite la chiamata fork(), quale delle seguenti informazioni il \"padre\" condivider√† con il \"figlio\"?",
    "options": [
      {
        "text": "Stack",
        "image": ""
      },
      {
        "text": "Heap",
        "image": ""
      },
      {
        "text": "Segmenti di memoria condivisa",
        "image": ""
      },
      {
        "text": "Nessuna delle precedenti",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "La chiamata fork() duplica lo spazio di indirizzamento del processo padre (stack e heap inclusi) utilizzando la tecnica copy-on-write. Tuttavia, i segmenti di memoria condivisa esplicitamente allocati (es. tramite shmget o mmap con MAP_SHARED) rimangono mappati agli stessi frame fisici in entrambi i processi.",
    "hint": "Considera quali aree di memoria vengono duplicate e quali sono effettivamente condivise tra processi dopo una fork."
  },
  {
    "question": "Un processo in esecuzione sulla CPU passa in stato ready quando:",
    "options": [
      {
        "text": "Esegue una chiamata di funzione",
        "image": ""
      },
      {
        "text": "Termina il quanto di tempo ad esso assegnato",
        "image": ""
      },
      {
        "text": "Apre una connessione di rete (a.g., un socket TCP)",
        "image": ""
      },
      {
        "text": "Fa richiesta di input da parte dell'utente",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "",
    "code": "",
    "explanation": "In uno scheduler preemptive con time slicing, quando un processo esaurisce il suo quanto di tempo senza completare l'esecuzione, viene rimosso forzatamente dalla CPU. Il processo passa quindi dallo stato running a ready, ritornando in coda per attendere il prossimo turno.",
    "hint": "Rifletti su quale evento temporale forza il rilascio della CPU senza che il processo abbia bisogno di risorse esterne."
  },
  {
    "question": "Il cosidetto stack frame (record di attivazione):",
    "options": [
      {
        "text": "√à un'area appositamente creata nella porzione stack della memoria di un processo per gestire le chiamate di sistema",
        "image": ""
      },
      {
        "text": "√à un'area appositamente creata nella porzione stack della memoria del sistema operativo per gestire la comunicazione tra processi",
        "image": ""
      },
      {
        "text": "√à un'area appositamente creata nella porzione stack della memoria di un processo per gestire le chiamate di funzione",
        "image": ""
      },
      {
        "text": "√à un'area appositamente creata nella porzione stack della memoria del sistema operativo per gestire le interruzioni",
        "image": ""
      }
    ],
    "correctIndex": 2,
    "image": "",
    "code": "",
    "explanation": "Lo stack frame (o record di attivazione) viene creato dinamicamente nello stack del processo ad ogni chiamata di funzione per memorizzare parametri, variabili locali e l'indirizzo di ritorno. Viene poi distrutto quando la funzione termina e il controllo ritorna al chiamante.",
    "hint": "Associa il concetto di 'record di attivazione' alla gestione delle chiamate a subroutine nel contesto di un singolo processo."
  },
  {
    "question": "Calcolare il tempo medio di attesa (average waiting time) dei seguenti processi, assumendo una politica di scheduling First Come First Served (FCFS) e che il processo A esegua all'istante t=4 una chiamata di I/O che si completer√† dopo 3 unit√† di tempo, ossia all'istante t=7. Nel calcolo, si consideri trascurabile il tempo necessario ad eseguire il context switch:",
    "options": [
      {
        "text": "5.5",
        "image": ""
      },
      {
        "text": "4.5",
        "image": ""
      },
      {
        "text": "5",
        "image": ""
      },
      {
        "text": "5.75",
        "image": ""
      }
    ],
    "correctIndex": 1,
    "image": "https://raw.githubusercontent.com/dag7dev/UniQuizzes/master/img/63.png",
    "code": "",
    "explanation": "",
    "hint": ""
  }
]